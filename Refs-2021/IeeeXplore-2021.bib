@INPROCEEDINGS{9667928,
author={Islam, Siam and Saha, Popin and Chowdhury, Touhidul and Sorowar, Asif and Rab, Raqeebir},
booktitle={2021 5th International Conference on Electrical Engineering and Information Communication Technology (ICEEICT)},
title={Non-invasive Deception Detection in Videos Using Machine Learning Techniques},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Deception detection has important clinical and legal implica-tions. Detecting deception is very effective in criminal investiga-tions, finding fake news, jurisprudence, law enforcement, and national security. Still, a reliable and Noninvasive deception technique is in progress. Deception detection using visual data is one of the most explored topics for burgeoning researchers. Several studies have been conducted on detecting deception using visual data. But most of them are based on courtroom trial data or mock criminal scenarios. In this paper, we have explored factual data set to identify deception from the subject’s natural response to truth and lie by analyzing Facial Action Units (FAU). Firstly, we selected apex frames of a video sequence and incepted all possible feature sets. Secondly, we analyzed the result of five machine learning classifiers on selected important features for detecting deception. We observed that Support Vector Machine with Radial Basis Function kernel (SVM-RBF), outperformed among all with 61.54% cross-validated accuracy.},
keywords={Support vector machines;Visualization;Transient response;Law enforcement;Video sequences;Neural networks;Feature extraction;deception detection;machine learning;apex frame;facial action units},
doi={10.1109/ICEEICT53905.2021.9667928},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9423197,
author={Ngô, Lê Minh and Wang, Wei and Mandira, Burak and Karaoğlu, Sezer and Bouma, Henri and Dibeklioğlu, Hamdi and Gevers, Theo},
booktitle={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)},
title={Identity Unbiased Deception Detection by 2D-to-3D Face Reconstruction},
year={2021},
volume={},
number={},
pages={145-154},
abstract={Deception is a common phenomenon in society, both in our private and professional lives. However, humans are notoriously bad at accurate deception detection. Based on the literature, human accuracy of distinguishing between lies and truthful statements is 54% on average, in other words, it is slightly better than a random guess. While people do not much care about this issue, in high-stakes situations such as interrogations for series crimes and for evaluating the testimonies in court cases, accurate deception detection methods are highly desirable. To achieve a reliable, covert, and non-invasive deception detection, we propose a novel method that disentangles facial expression and head pose related features using 2D-to-3D face reconstruction technique from a video sequence and uses them to learn characteristics of deceptive behavior. We evaluate the proposed method on the Real-Life Trial (RLT) dataset that contains high-stakes deceits recorded in courtrooms. Our results show that the proposed method (with an accuracy of 68%) improves the state of the art. Besides, a new dataset has been collected, for the first time, for low-stake deceit detection. In addition, we compare high-stake deceit detection methods on the newly collected low-stake deceits.},
keywords={Video sequences;Pipelines;Feature extraction;Real-time systems;Magnetic heads;Reliability;Convolutional neural networks},
doi={10.1109/WACV48630.2021.00019},
ISSN={2642-9381},
month={Jan},}
@INPROCEEDINGS{9742465,
author={Fan, Jiewen and Shen, Xunbin},
booktitle={2021 2nd International Conference on Information Science and Education (ICISE-IE)},
title={New progress in the paradigm of elicited deception : Application of human-computer interaction in deception detection},
year={2021},
volume={},
number={},
pages={1558-1562},
abstract={Deception is common in our lives, and over the past few decades. There has been a great deal of scientific interest in the field of deception and deception detection. The question of whether microexpressions can detect deception is controversial, but the introduction of iBorderCtrl at EU borders in recent years seems to have answered the question. IBorderCtrl uses human-computer interaction technology to identify people at the border when they are visiting. In view of this, human-computer interaction may be one of the future research trends of face recognition, micro-expression recognition and deception detection. In general, there are still few types of research on micro-expression deception detection in the world. In particular, there is little systematic information about how to induce deception states. This work is an important work for micro-expression deception detection. Therefore, this paper first reviews the research on deception detection and how to induce deception state in the last twenty years. Then the application of human-computer interaction in deception detection is discussed and a new prospect of the combination of human-computer interaction and deception detection is proposed.},
keywords={Human computer interaction;Information science;Systematics;Face recognition;Maintenance engineering;Market research;Stability analysis;Deception detection;Induce deception;Paradigm;Human-computer interaction},
doi={10.1109/ICISE-IE53922.2021.00345},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9623077,
author={Fernandes, Sinead V. and Ullah, Muhammad S.},
booktitle={2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)},
title={Development of Spectral Speech Features for Deception Detection Using Neural Networks},
year={2021},
volume={},
number={},
pages={0198-0203},
abstract={Analysis of stress in speech signals offers a noninvasive alternative to detect deception. The aim of this study is to investigate and synthesize by exploring the spectral energy features namely delta energy and difference energy for deception detection from speech signals. The results are compared with innovative delta and time-difference cepstrum features. Extractions of the proposed speech features are based on the perception of human speech and the psychoacoustic masking property. To classify deceptive and truthful speech, spectral energy in twenty - one (21) bands of frequencies on a Bark scale is used. The reference speech signals for the database are garnered by using the track record of a blameworthy person throughout a police investigation. Two neural networks such as (1) the Levenberg-Marquardt (LM) algorithm and (2) the Long Short-Term Memory (LSTM) algorithm are used in the MATLAB environment to observe the performance and test the results. Simulation results indicate that the delta and time-difference energy are critical features to classify deceptive speech from truthful speech.},
keywords={Psychoacoustics;Databases;Simulation;Feature extraction;Mobile communication;Mathematical models;Psychoacoustic models;Artificial Neural Network;Deception Detection;Delta Energy;Difference Energy;Spectral Energy Features},
doi={10.1109/IEMCON53756.2021.9623077},
ISSN={2644-3163},
month={Oct},}
@ARTICLE{9442753,
author={Fernandes, Sinead V. and Ullah, Muhammad S.},
journal={IEEE Access},
title={Use of Machine Learning for Deception Detection From Spectral and Cepstral Features of Speech Signals},
year={2021},
volume={9},
number={},
pages={78925-78935},
abstract={In this research, four unique nonlinear speech features are extracted and analyzed to study the dissimilarity pattern between when the speaker is being deceitful and truthful based on how human speech is perceived. The speaker was under stress in a police interrogation where two ground truth and two deceitful responses were recorded during three different times of the day. Using the audio recordings from all three sessions, the cepstral features and spectral energy features are extracted. Cepstral features are the Mel frequency cepstrum coefficient, from where the delta cepstrum and the time-difference cepstrum features are developed. On the other hand, the spectral energy features are the energy of Bark band energy from where the delta energy and the time-difference energy features are developed. The Levenberg-Marquardt classification method and the long short-term memory classification method are then applied to evaluate the accuracy of detecting deception based on the nine unique training and testing combinations of the three different sessions and their extracted cepstrum and spectral energy features. In addition, the principal component analysis is applied to reduce the dimensionality from the extracted features for further improvement. The projected principal components of the four types of features showed improved accuracy in order to distinguish between truthful and deceptive speech pattern. After incorporating with principal component analysis, the long short-term memory classification method with time-difference spectral energy feature shows the highest recognition rate compared to Levenberg-Marquardt algorithm with other cepstral and spectral features.},
keywords={Feature extraction;Speech recognition;Cepstrum;Mel frequency cepstral coefficient;Support vector machines;Principal component analysis;Law enforcement;Cepstral features;deception detection;machine learning;principal component analysis;spectral features;speech analysis},
doi={10.1109/ACCESS.2021.3084200},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9413550,
author={Mathur, Leena and Matarić, Maja J.},
booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Unsupervised Audio-Visual Subspace Alignment for High-Stakes Deception Detection},
year={2021},
volume={},
number={},
pages={2255-2259},
abstract={Automated systems that detect deception in high-stakes situations can enhance societal well-being across medical, social work, and legal domains. Existing models for detecting high-stakes deception in videos have been supervised, but labeled datasets to train models can rarely be collected for most real-world applications. To address this problem, we propose the first multimodal unsupervised transfer learning approach that detects real-world, high-stakes deception in videos with-out using high-stakes labels. Our subspace-alignment (SA) approach adapts audio-visual representations of deception in lab-controlled low-stakes scenarios to detect deception in real-world, high-stakes situations. Our best unsupervised SA models outperform models without SA, outperform human ability, and perform comparably to a number of existing supervised models. Our research demonstrates the potential for introducing subspace-based transfer learning to model high-stakes deception and other social behaviors in real-world contexts with a scarcity of labeled behavioral data.},
keywords={Adaptation models;Law;Conferences;Transfer learning;Signal processing;Data models;Acoustics;transfer learning;deception detection},
doi={10.1109/ICASSP39728.2021.9413550},
ISSN={2379-190X},
month={June},}
@INPROCEEDINGS{9667050,
author={Mathur, Leena and Matarić, Maja J},
booktitle={2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)},
title={Affect-Aware Deep Belief Network Representations for Multimodal Unsupervised Deception Detection},
year={2021},
volume={},
number={},
pages={1-8},
abstract={Automated systems that detect the social behavior of deception can enhance human well-being across medical, social work, and legal domains. Labeled datasets to train supervised deception detection models can rarely be collected for real-world, high -stakes contexts. To address this challenge, we propose the first unsupervised approach for detecting realworld, high-stakes deception in videos without requiring labels. This paper presents our novel approach for affect-aware unsupervised Deep Belief Networks (DBN) to learn discriminative representations of deceptive and truthful behavior. Drawing on psychology theories that link affect and deception, we experimented with unimodal and multimodal DBN-based approaches trained on facial valence, facial arousal, audio, and visual features. In addition to using facial affect as a feature on which DBN models are trained, we also introduce a DBN training procedure that uses facial affect as an aligner of audio-visual representations. We conducted classification experiments with unsupervised Gaussian Mixture Model clustering to evaluate our approaches. Our best unsupervised approach (trained on facial valence and visual features) achieved an AVC of 80%, outperforming human ability and performing comparably to fully-supervised models. Our results motivate future work on unsupervised, affect-aware computational approaches for detecting deception and other social behaviors in the wild.},
keywords={Training;Visualization;Law;Psychology;Machine learning;Gesture recognition;Feature extraction},
doi={10.1109/FG52635.2021.9667050},
ISSN={},
month={Dec},}
@ARTICLE{9310253,
author={Kamboj, Manvi and Hessler, Christian and Asnani, Priyanka and Riani, Kais and Abouelenien, Mohamed},
journal={IEEE MultiMedia},
title={Multimodal Political Deception Detection},
year={2021},
volume={28},
number={1},
pages={94-102},
abstract={Political statements are carefully crafted to garner public support for a particular ideology. These statements are often biased and sometimes misleading. Separating fact from fiction has proven to be a difficult task, generally accomplished by cross-checking political statements against an impartial and trustworthy news source. In this article, we make three contributions. First, we compile a novel multimodal dataset, which consists of 180 videos with accompanying audio recordings and transcripts, featuring 88 politicians categorized by political party. To our knowledge, this is the second multimodal deception detection dataset from real-life data and the first in the political field. Second, we extract features from the linguistic, visual, and acoustic modalities to develop a system capable of discriminating between truthful and deceptive political statements. Finally, we perform an extensive analysis on different multimodal features to identify the behavioral patterns used by politicians when it comes to deception.},
keywords={Feature extraction;Videos;Linguistics;Visualization;Psychology;Task analysis},
doi={10.1109/MMUL.2020.3048044},
ISSN={1941-0166},
month={Jan},}
@INPROCEEDINGS{9484409,
author={Speth, Jeremy and Vance, Nathan and Czajka, Adam and Bowyer, Kevin W. and Wright, Diane and Flynn, Patrick},
booktitle={2021 IEEE International Joint Conference on Biometrics (IJCB)},
title={Deception Detection and Remote Physiological Monitoring: A Dataset and Baseline Experimental Results},
year={2021},
volume={},
number={},
pages={1-8},
abstract={We present the Deception Detection and Physiological Monitoring (DDPM) dataset and initial baseline results on this dataset. Our application context is an interview scenario in which the interviewee attempts to deceive the interviewer on selected responses. The interviewee is recorded in RGB, near-infrared, and long-wave infrared, along with cardiac pulse, blood oxygenation, and audio. After collection, data were annotated for interviewer/interviewee, curated, ground-truthed, and organized into train / test parts for a set of canonical deception detection experiments. Baseline experiments found random accuracy for micro-expressions as an indicator of deception, but that saccades can give a statistically significant response. We also estimated subject heart rates from face videos (remotely) with a mean absolute error as low as 3.16 bpm. The database contains almost 13 hours of recordings of 70 subjects, and over 8 million visible-light, near-infrared, and thermal video frames, along with appropriate meta, audio and pulse oximeter data. To our knowledge, this is the only collection offering recordings of five modalities in an interview scenario that can be used in both deception detection and remote photoplethysmography research.},
keywords={Pulse oximeter;Protocols;Photoplethysmography;Sensors;Synchronization;Reliability;Biomedical monitoring},
doi={10.1109/IJCB52358.2021.9484409},
ISSN={2474-9699},
month={Aug},}
@INPROCEEDINGS{9624738,
author={Lim, Jaewan and Zhou, Lina and Zhang, Dongsong},
booktitle={2021 IEEE International Conference on Intelligence and Security Informatics (ISI)},
title={Verbal Deception Cue Training for the Detection of Phishing Emails},
year={2021},
volume={},
number={},
pages={1-3},
abstract={Training on cues to deception is one of the promising ways of addressing humans’ poor performance in deception detection. However, the effect of training may be subject to the context of deception and the design of training. This study aims to investigate the effect of verbal cue training on the performance of phishing email detection by comparing different designs of training and examining the effect of topic familiarity. Based on the results of a lab experiment, we not only confirm the effect of training but also provide suggestions on how to design training to better facilitate the detection of phishing emails. In addition, our results also discover the effect of topic familiarity on phishing detection. The findings of this study have significant implications for the mitigation and intervention of online deception.},
keywords={Training;Phishing;Conferences;Electronic mail;Security;Copper;Informatics;deception cues;training;phishing;deception detection;familiarity},
doi={10.1109/ISI53945.2021.9624738},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9587698,
author={Raj, Chahat and Meel, Priyanka},
booktitle={2021 2nd Global Conference for Advancement in Technology (GCAT)},
title={Microblogs Deception Detection using BERT and Multiscale CNNs},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Online news consumption has rapidly increased, and so has the proliferation of false information. People worldwide have mainly become dependent on social media networks to intake news about the happenings around them. Also, the data is profoundly contaminated with wrong information that harms society in uncountable ways. It is of huge importance to be able to identify a false message. The research society is contributing to solving the problem by developing machine learning and deep learning algorithms. With misinformation spreading ubiquitously, various data modalities have emerged that become carriers of such false news. Research trend is advancing towards multi-modal fake news detection to authenticate text, images, and videos on the web. Existing studies have elaborated on the successful use of RNNs and CNNs. Being a new NLP technique, BERT has been used by a limited number of studies, while multiscale CNNs have not been explored yet to apply fake news detection. This research proposes a novel framework using BERT and multiscale CNNs to perform multi-modal fake news classification and achieve results higher than the existing state-of-the-art techniques.},
keywords={Visualization;Machine learning algorithms;Social networking (online);Blogs;Bit error rate;Neural networks;Predictive models;Fake News;Misinformation;Multimodal;BERT;Convolutional Neural Networks},
doi={10.1109/GCAT52182.2021.9587698},
ISSN={},
month={Oct},}
@ARTICLE{9446553,
author={Karnati, Mohan and Seal, Ayan and Yazidi, Anis and Krejcar, Ondrej},
journal={IEEE Transactions on Cognitive and Developmental Systems},
title={LieNet: A Deep Convolution Neural Networks Framework for Detecting Deception},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Nowadays, automatic deception detection has received considerable attention in the machine learning community owing to this research interest to its vast applications in the fields of social media, interviews, law enforcement, and the military. In this study, a novel deep convolution neural network (DCNN) named LieNet is proposed to precisely detect the multi-scale variations of deception automatically. Our approach is a combination of contact and non-contact-based approaches. First, 20 frames from each video are fetched and concatenated to form a single image. Moreover, an audio signal is extracted from video and treated as image input by plotting the signal into two dimensional (2D) plane. Furthermore, 13 channels of EEG signals are plotted into 2D plane and concatenated to generate an image. Second, the LieNet model extracts features from each modality separately. Third, scores are estimated using a softmax classifier for all the modalities. Finally, three scores are combined using score level fusion to obtain a score, which gives support in favor of either deception or truth. The LieNet is validated on the “Bag-of-Lies (BoL)”“, Real-life (RL) trail”, and “Miami University Deception Detection (MU3D)" databases by considering four evaluation indexes viz., accuracy, precision, recall, and F1-score. Experimental outcomes depict that the LieNet defeats an initial work on Set-A and Set-B of the BoL database with average accuracies of 95.91% and 96.04% respectively. The accuracies obtained by the LieNet are 97% and 98% on RL trail and MU3D databases respectively.},
keywords={Electroencephalography;Feature extraction;Databases;Visualization;Faces;Interviews;Convolution;Deception detection;multi-modal database;deep covolutional neural network;softmax classifier;score level fusion.},
doi={10.1109/TCDS.2021.3086011},
ISSN={2379-8939},
month={},}
@INPROCEEDINGS{9738794,
author={Rajagulasingam, Christina and Taylor, Jacqui},
booktitle={2021 APWG Symposium on Electronic Crime Research (eCrime)},
title={The roles of self-control, need for cognition, impulsivity and viewing time in deception detection using a realistic e-mail phishing task},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Phishing attacks manipulate people into giving away personal information, which can lead to detrimental consequences for individuals and organizations. This study aimed to understand how viewing time and traits relating to cognition influenced participant’s ability to detect phishing e-mails. One hundred and twenty-two undergraduate students participated in an online survey which collected measures of impulsivity, need for cognition, self-control, time spent viewing e-mails and correct detection of phishing. There were no significant correlations between correct phishing detection and traits relating to cognition. However, viewing time was a significant factor where the more time individuals spent viewing e-mails the greater their accuracy in both perception of phishing e-mails and intention to correctly respond to phishing e-mails. The findings suggest that individual psychological differences have little influence on deception detection, supporting some of the previous research on the lack of effects relating to personality differences. In practical terms, individuals should be advised to spend more time viewing e-mails than they usually would, in order to increase their ability to detect phishing e-mails.},
keywords={Correlation;Atmospheric measurements;Phishing;Psychology;Organizations;Particle measurements;Cognition;phishing;online deception;need for cognition;self-control;impulsivity;viewing time;persuasion},
doi={10.1109/eCrime54498.2021.9738794},
ISSN={2159-1245},
month={Dec},}
@INPROCEEDINGS{9691309,
author={Fahmy, Gamal},
booktitle={2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC)},
title={Detection of Micro Movements of Facial Muscles in Facial Videos},
year={2021},
volume={},
number={},
pages={1-4},
abstract={During the last decade there has been many efforts by researchers to investigate the micro motion magnification from different types of videos. This was mainly due to its impact in many computer vision applications. In this paper we present how to detect these micro movements in natural face videos using basic band pass filtering. We then propose to utilize Complex Wavelets to magnify detected micro movements and make then visible. This proposed technique when applied on natural face videos can reveal different muscle movements which would indicate many different symptoms and expressions. Our proposed technique can be utilized in Forensic science, automatic deception detection, medical diagnose and psychotherapy. Several experiments on a large Face video database are reported along with results analysis and comparisons with similar literature techniques.},
keywords={Computer vision;Filtering;Databases;Forensics;Surgery;Muscles;Facial muscles},
doi={10.1109/JAC-ECC54461.2021.9691309},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9694118,
author={Wall, Julie},
booktitle={2021 Tenth International Conference on Intelligent Computing and Information Systems (ICICIS)},
title={Keynote Speech 4: A Conversational AI Approach to Detecting Deception and Tackling Insurance Fraud},
year={2021},
volume={},
number={},
pages={31-31},
abstract={Summary form only given. The complete presentation was not made available for publication as part of the conference proceedings. This talk will present a real-world case study in the insurance domain that exploits speech and language to produce an explainable pipeline that identifies and justifies the behavioural elements of a fraudulent claim during a telephone report of an insured loss. To detect the behavioural features of speech for deception detection, we have curated a robust set of acoustic and linguistic markers that potentially indicate deception in a conversation. Statistical measures and machine learning were used to identify these linguistic markers in the right context. The explainable pipeline means that the output of the decision-making element of the system provides transparent decision explainability, overcoming the “black-box” challenge of traditional AI systems. This patent-pending technology, made possible through the support of funding from UK Research and Innovation (UKRI), is now part of a real-world commercial system, called LexiQal. This talk will outline the LexiQal approach to address the need for an efficient data-driven deep learning transparent approach (Explainable AI) to call analytics, an automated approach to forensic statement analysis, where there is a need to interpret the context of the spoken utterances accurately.},
keywords={Speech processing;Pipelines;Linguistics;Insurance;Deep learning;Transformers;Telephone sets},
doi={10.1109/ICICIS52592.2021.9694118},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9659279,
author={Chu, Ruimin and Sharmin Rahman, Jessica and Caldwell, Sabrina and Zhu, Xuanying and Gedeon, Tom},
booktitle={2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
title={Detecting Lies: Finding the Degree of Falsehood from Observers’ Physiological Responses},
year={2021},
volume={},
number={},
pages={1959-1965},
abstract={Lying is a common act in daily life and may have various degrees of falsehood. Deception detection has always been a fascinating area of research in which many studies have been conducted using subjects’ facial, verbal or bodily cues to spot potential deceit. However, none of the studies have investigated the physiological responses of observers in response to misleading statements with various degrees of falsehood. In this paper, we investigated this problem by first conducting designed experiments to collect participants’ physiological signals while they were watching stimulus videos with various falsehood levels. Then, the data was analysed using machine learning or deep learning models. Various challenges including relatively small amounts of training data and imbalanced classes have been addressed by implementing data augmentation. The results show that deep learning models, such as ResNet and VAE-LSTM, can predict the degree of falsehood with an F1-measure up to 0.83 from observers’ reactions when compared to the stimuli ground truth. This was attained when the model was trained with the most useful physiological signal in this study, Electrodermal Activity (EDA). This result indicates that observers’ physiological signals can be used as an indicator to determine the degree of falsehood for misleading statements. In the future, this system may be applied to provide an objective evaluation for deception detection.},
keywords={Deep learning;Analytical models;Conferences;Training data;Predictive models;Observers;Physiology},
doi={10.1109/SMC52423.2021.9659279},
ISSN={2577-1655},
month={Oct},}
@ARTICLE{9343823,
author={Jiang, Tao and Li, Jian Ping and Haq, Amin Ul and Saboor, Abdus and Ali, Amjad},
journal={IEEE Access},
title={A Novel Stacking Approach for Accurate Detection of Fake News},
year={2021},
volume={9},
number={},
pages={22626-22639},
abstract={With the increasing popularity of social media, people has changed the way they access news. News online has become the major source of information for people. However, much information appearing on the Internet is dubious and even intended to mislead. Some fake news are so similar to the real ones that it is difficult for human to identify them. Therefore, automated fake news detection tools like machine learning and deep learning models have become an essential requirement. In this paper, we evaluated the performance of five machine learning models and three deep learning models on two fake and real news datasets of different size with hold out cross validation. We also used term frequency, term frequency-inverse document frequency and embedding techniques to obtain text representation for machine learning and deep learning models respectively. To evaluate models' performance, we used accuracy, precision, recall and F1-score as the evaluation metrics and a corrected version of McNemar's test to determine if models' performance is significantly different. Then, we proposed our novel stacking model which achieved testing accuracy of 99.94% and 96.05 % respectively on the ISOT dataset and KDnugget dataset. Furthermore, the performance of our proposed method is high as compared to baseline methods. Thus, we highly recommend it for fake news detection.},
keywords={Support vector machines;Machine learning;Social networking (online);Deep learning;Feature extraction;Stacking;Neural networks;Deception detection;deep learning;fake news;machine learning;McNemar’s test;performance evaluation;stacking},
doi={10.1109/ACCESS.2021.3056079},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9640733,
author={Pranathi, P. and Lakshmi, C. and Suneetha, M.},
booktitle={2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)},
title={A Review on Various Facial Expression Recognition Techniques},
year={2021},
volume={},
number={},
pages={1246-1254},
abstract={In present days, Facial Expression Acknowledgment (FER) has now become an unbelievable issue in contemporary science study. Facial expression, a vital mode of communication of human emotions, has been studied throughout the world in the fields of Driver Protection, human computer interaction (HCI), deception detection, health care, monitoring etc. Generative Adverse Networks (GANs), with various gestures, can create more one-to-one faces that can be used to improve data base. Facial expression recognition is one of the most effective naturalizing and instant means for people to convey their feelings and intentions. FER is a common research subject which has brought a range of computational vision tasks, such as image generation, video generation, super resolution reconstruction and image translation. Happiness, sorrow, surprise, disgust, fear and rage all constitute six universal facial expressions. Other things such as eye change, breathing and combing the variance in expression will underline all the emotion above. A face recognition device is a behavior request for the identification or authentication of an individual automatically from a digital picture or from a video source. This analysis paper helps to explain methods, strategies and challenges in the real time FER climate, which discuss and examine problems and challenges. This paper finally concludes the latest developments and addresses the problems facing the FER process and the potential of future growth.},
keywords={Human computer interaction;Support vector machines;Face recognition;Speech recognition;Streaming media;Speech enhancement;Feature extraction;Facial Expression Recognition;Image;Machine learning;deep learning;optimization},
doi={10.1109/I-SMAC52330.2021.9640733},
ISSN={2768-0673},
month={Nov},}
@ARTICLE{9330624,
author={Wang, Hanwen and Qi, Yu and Yu, Hang and Wang, Yueming and Liu, Cong and Hu, Guoping and Pan, Gang},
journal={IEEE Transactions on Cognitive and Developmental Systems},
title={RCIT: An RSVP-Based Concealed Information Test Framework Using EEG Signals},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Concealed information detection has a strong connection with human cognition. Existing deception detection approaches such as polygraph testing usually exploit psychophysiological changes. However, they often suffer from low accuracy and attacking-by-training. Compared with conventional physiological responses, electroencephalogram (EEG) directly reflects activity responses in the brain, thus can be potentially more accurate in deception detection. In this paper, we propose an EEG-based concealed information detection framework. In this framework, different test trials are designed to evoke effective brain responses corresponding to concealed information while keeping the subject focused. Meanwhile, we employ rapid serial visual presentation (RSVP) for deception detection. Our framework presents the stimuli on the fringe of awareness, making it not easy to take the countermeasures. Furthermore, we develop a method based on neural network to detect brain responses. Experimental results with 10 subjects show that, our approach can effectively detect concealed information with an accuracy of 87.13%.},
keywords={Probes;Electroencephalography;Visualization;Biomedical monitoring;Task analysis;Stress;Faces;Concealed information detection;electroencephalogram;rapid serial visual presentation;neural networks.},
doi={10.1109/TCDS.2021.3053455},
ISSN={2379-8939},
month={},}