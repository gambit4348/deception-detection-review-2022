
@ARTICLE{Sharma2020,
author={Sharma, S. and Jain, A.},
title={Role of sentiment analysis in social media security and analytics},
journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
year={2020},
volume={10},
number={5},
doi={10.1002/widm.1366},
art_number={e1366},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082465539&doi=10.1002%2fwidm.1366&partnerID=40&md5=be6548ab58ac0c7e7c64b2cb57c577fd},
affiliation={USICT, Guru Gobind Singh Indraprastha University, Delhi, India},
abstract={Social media, in recent times, has with eased an explosion of data with so many social media platforms available to interact and express opinions freely. This has led to easy access to the privacy of social media users which raise broader security concerns and issues. The present paper provides an overview of various sentiment analysis approaches and techniques for social media security and analytics. The multiple security application domains like deception detection, anomaly detection, risk management, and disaster relief have been identified where sentiment analysis is used for social media security. An in-depth study on security issues related to data provenance, distrust, e-commerce security, consumer security breaches, market surveillance, credibility, and risk assessment in social media have been presented. A comparison of various techniques, methodologies, dataset, and application domain where sentiment analysis is used has been discussed. The present work discusses the results of different machine learning techniques based on the performance metrics that have been used for the implementation of sentiment analysis in the respective security domains. It identifies the various gaps, issues, and the recent advancements in the field and presents a line of work that needs to be carried forward in future. This article is categorized under: Commercial, Legal, and Ethical Issues > Security and Privacy Technologies > Machine Learning Technologies > Prediction. © 2020 Wiley Periodicals, Inc.},
author_keywords={machine learning techniques;  sentiment analysis;  social media analytics;  social media security},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Crockett2020,
author={Crockett, K. and O'Shea, J. and Khan, W.},
title={Automated Deception Detection of Males and Females from Non-Verbal Facial Micro-Gestures},
journal={Proceedings of the International Joint Conference on Neural Networks},
year={2020},
doi={10.1109/IJCNN48605.2020.9207684},
art_number={9207684},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093825941&doi=10.1109%2fIJCNN48605.2020.9207684&partnerID=40&md5=f35ebf390161d6137180f7286a854f32},
affiliation={Manchester Metropolitan University, Department of Computing and Mathematics, Manchester, M1 5GD, United Kingdom; Liverpool John Moores University, Department of Computer Science, Byrom Street, Liverpool, L3 3AF, United Kingdom},
abstract={Gender bias within Artificial intelligence driven systems is currently a hot topic and is one of a number of areas where the data used to train, validate and test machine learning algorithms is under more scrutiny than ever before. In this paper we investigate if there is a difference between the nonverbal cues to deception generated by males and females through the use of an automated deception detection system. The system uses hierarchical neural networks to extract 36 channels of non-verbal head and facial behaviors whilst male and female participants are engaged in either a deceptive or truthful roleplaying task. An Image Vector dataset, comprising of 86584 vectors, is collated which uses a fixed sliding window slot of 1 second to record deceptive or truthful slots. Experiments were conducted on three variants of the dataset, all males, all females and mixed in order to examine if the differences in cues generated by males and females lead to differences in the accuracies of machine learning algorithms which classify their behavior. Results showed differences in nonverbal cues between males and females, with both genders at a disadvantage when treated by classifiers trained on both genders rather than classifiers specifically trained for each gender. However, there was no striking disadvantageous effect beyond the influence of their relative frequency of occurrence in the dataset. © 2020 IEEE.},
author_keywords={deception detection;  gender;  machine learning;  micro-gestures},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Khan20201,
author={Khan, W. and Hussain, A. and Kuru, K. and Al-Askar, H.},
title={Pupil localisation and eye centre estimation using machine learning and computer vision},
journal={Sensors (Switzerland)},
year={2020},
volume={20},
number={13},
pages={1-18},
doi={10.3390/s20133785},
art_number={3785},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087442183&doi=10.3390%2fs20133785&partnerID=40&md5=e09aa8b9fc7e23ff1f7e6b7a9a1d0f99},
affiliation={Computer Science Department, Liverpool John Moores University, Liverpool, L33AF, United Kingdom; School of Engineering, University of Central Lancashire, Preston, PR12HE, United Kingdom; Computer Science Department, College of Engineering and Computer Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, 11942, Saudi Arabia},
abstract={Various methods have been used to estimate the pupil location within an image or a real-time video frame in many fields. However, these methods lack the performance specifically in low-resolution images and varying background conditions. We propose a coarse-to-fine pupil localisation method using a composite of machine learning and image processing algorithms. First, a pre-trained model is employed for the facial landmark identification to extract the desired eye frames within the input image. Then, we use multi-stage convolution to find the optimal horizontal and vertical coordinates of the pupil within the identified eye frames. For this purpose, we define an adaptive kernel to deal with the varying resolution and size of input images. Furthermore, a dynamic threshold is calculated recursively for reliable identification of the best-matched candidate. We evaluated our method using various statistical and standard metrics along with a standardised distance metric that we introduce for the first time in this study. The proposed method outperforms previous works in terms of accuracy and reliability when benchmarked on multiple standard datasets. The work has diverse artificial intelligence and industrial applications including human computer interfaces, emotion recognition, psychological profiling, healthcare, and automated deception detection. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={Deep eye;  Eye centre localisation;  Eye gaze;  Facial analysis;  Image convolution;  Iris detection;  Machine intelligence;  Pupil detection;  Pupil segmentation},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Gutierrez-Espinoza20201320,
author={Gutierrez-Espinoza, L. and Abri, F. and Siami Namin, A. and Jones, K.S. and Sears, D.R.W.},
title={Ensemble Learning for Detecting Fake Reviews},
journal={Proceedings - 2020 IEEE 44th Annual Computers, Software, and Applications Conference, COMPSAC 2020},
year={2020},
pages={1320-1325},
doi={10.1109/COMPSAC48688.2020.00-73},
art_number={9202657},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094120717&doi=10.1109%2fCOMPSAC48688.2020.00-73&partnerID=40&md5=c9977034aa3f2df482d1240c154f3306},
affiliation={Department of Computer Science; Department of Psychological Sciences; Performing Arts Research Lab Texas Tech University, United States},
abstract={Customers represent their satisfactions of consuming products by sharing their experiences through the utilization of online reviews. Several machine learning-based approaches can automatically detect deceptive and fake reviews. Recently, there have been studies reporting the performance of ensemble learning-based approaches in comparison to conventional machine learning techniques. Motivated by the recent trends in ensemble learning, this paper evaluates the performance of ensemble learning-based approaches to identify bogus online information. The application of a number of ensemble learning-based approaches to a collection of fake restaurant reviews that we developed show that these ensemble learning-based approaches detect deceptive information better than conventional machine learning algorithms. © 2020 IEEE.},
author_keywords={deception detection;  Ensemble learning},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dodia2020637,
author={Dodia, S. and Edla, D.R. and Bablani, A. and Cheruku, R.},
title={Lie detection using extreme learning machine: A concealed information test based on short-time Fourier transform and binary bat optimization using a novel fitness function},
journal={Computational Intelligence},
year={2020},
volume={36},
number={2},
pages={637-658},
doi={10.1111/coin.12256},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075715615&doi=10.1111%2fcoin.12256&partnerID=40&md5=dce8908030129e008e6543a1fa821076},
affiliation={Department of Computer Science and Engineering, National Institute of Technology, Goa, India; Department of CSE, National Institute of Technology, Warangal, Telangana, India},
abstract={Lie detection is one of the major challenges that is being faced by the forensic sciences. Identification of lie on the basis of a person's mental behavior is a tedious task. Brain-computer interface is one such medium which provides a solution to this problem by displaying visual stimuli and recording subject's brain responses. A P300 response is elicited whenever a person comes across a familiar stimuli in a series of rare stimuli. This P300 response is used for the lie detection method. In the proposed concealed information test, acquired signals are preprocessed to discard noise. Then, short-time Fourier transform method is applied to extract features from the preprocessed electroencephalogram signals. To avoid the curse of dimensionality and to reduce computational overhead, binary bat algorithm is applied, which helps in choosing optimal subset of features. The obtained set of features is given as an input to the extreme learning machine classifier for training of guilty and innocent samples. The performance of the system is assessed using 10-fold cross-validation. The resultant accuracy obtained from the proposed lie detection system is 88.3%. The system has provided efficient results in contrast with most of the state-of-the-art lie detection methods. © 2019 Wiley Periodicals, Inc.},
author_keywords={binary bat;  brain-computer interface;  concealed information test;  electroencephalogram;  extreme learning machine;  short-time Fourier transform},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ardulov20208074,
author={Ardulov, V. and Durante, Z. and Williams, S. and Lyon, T. and Narayanan, S.},
title={Identifying Truthful Language in Child Interviews},
journal={ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
year={2020},
volume={2020-May},
pages={8074-8078},
doi={10.1109/ICASSP40776.2020.9053386},
art_number={9053386},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089211470&doi=10.1109%2fICASSP40776.2020.9053386&partnerID=40&md5=e30184e76aba9f24aa91fb755116a0b9},
affiliation={University of Southern California, Signal Analysis and Interpretation Lab, Los Angeles, CA, United States; University of Southern California, Gould School of Law, Los Angeles, CA, United States},
abstract={When a child is suspected to be the victim or sole witness of a crime, the manner in which information is gathered from the child becomes critical. A child forensic interview is the guided conversation that a legal expert conducts to elicit reliable information from a child. To help substantiate child testimony, it is important to discern characteristics of truthful and deceptive behavior in these interviews. The work presented uses various machine learning algorithms to identify differences in the speech of children when they are lying or being truthful, particularly when they have been asked by a confederate to deceive an interviewer. Results show that vocabulary and psycho-linguistic norms of a child's language use, in response to directed questions, provide substantial information to outperform human adults in detecting truthful statements. © 2020 IEEE.},
author_keywords={Behavioral Signal Processing;  Child Forensic Interview;  Deception Detection},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lai2020,
author={Lai, V. and Liu, H. and Tan, C.},
title={"Why is 'Chicago' deceptive?" Towards Building Model-Driven Tutorials for Humans},
journal={Conference on Human Factors in Computing Systems - Proceedings},
year={2020},
doi={10.1145/3313831.3376873},
art_number={3376873},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091294383&doi=10.1145%2f3313831.3376873&partnerID=40&md5=bada1e25bc2db2592f9d239ab6280ada},
affiliation={University of Colorado Boulder, Boulder, CO, United States},
abstract={To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a train- ing phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI. © 2020 ACM.},
author_keywords={deception detection;  explanations;  interpretable machine learning;  tutorials},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{vanDitmarsch2020466,
author={van Ditmarsch, H. and Hendriks, P. and Verbrugge, R.},
title={Editors’ Review and Introduction: Lying in Logic, Language, and Cognition},
journal={Topics in Cognitive Science},
year={2020},
volume={12},
number={2},
pages={466-484},
doi={10.1111/tops.12492},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081301983&doi=10.1111%2ftops.12492&partnerID=40&md5=494a6a5dadaa35754a784d0c19f198f4},
affiliation={CNRS, LORIA, University of Lorraine, France; Rijksuniversiteit Groningen, Netherlands},
abstract={We describe some recent trends in research on lying from a multidisciplinary perspective, including logic, philosophy, linguistics, psychology, cognitive science, behavioral economics, and artificial intelligence. Furthermore, we outline the seven contributions to this special issue of topiCS. © 2020 Cognitive Science Society, Inc},
author_keywords={Cognitive load;  Cognitive resources;  Deception;  Lie detection;  Lying;  Theory of mind},
document_type={Article},
source={Scopus},
}

@ARTICLE{Thakur2020,
author={Thakur, S. and Dharavath, R. and Edla, D.R.},
title={Spark and Rule-KNN based scalable machine learning framework for EEG deceit identification},
journal={Biomedical Signal Processing and Control},
year={2020},
volume={58},
doi={10.1016/j.bspc.2020.101886},
art_number={101886},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079317663&doi=10.1016%2fj.bspc.2020.101886&partnerID=40&md5=29f60031b0af8fca34f85fc220bc18c8},
affiliation={Department of Computer Science and Engineering, Indian Institute of Technology(ISM), Dhanbad, 826004, India; Department of Computer Science and Engineering, National Institute of Technology Goa, India},
abstract={Brain computer interface (BCI) provides communication between the computer and the brain. It is the combination of hardware and software which provides non-muscular channel to send the various messages to control the computer. BCI is useful in various medical applications such as patients with neuromuscular injuries, locked-in syndrome (LiS) etc. BCI is not only useful in medical applications, but also useful in lie detection, entertainment, etc. In this paper, spark and rule-KNN based scalable framework has been presented using BCI with the EEG data collected on 20 subjects in which 10 are acted as innocent and 10 are acted as guilty. Using BCI P300, Deceit identification Test (DIT) is performed. To perform DIT, we classify the P300 signals which have a positive peak of 300 ms–1000 ms in one stimulus start. Data processing is performed with band pass filter to cut the frequency ranges and features are extracted using non-parametric weighted feature extraction followed by rule based discriminant classification. For training and testing, the data ratio selected as 80:20 and achieved the accuracy 92.46 %. Proposed framework provides better results in comparison with existing models presented in literature. Hence this model is accurate, scalable and fault tolerant. © 2020 Elsevier Ltd},
author_keywords={Apache spark;  Brain computer interface;  EEG data analysis;  Non-parametric;  Weighted feature extraction},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Pasquali2020392,
author={Pasquali, D. and Aroyo, A.M. and Gonzalez-Billandon, J. and Rea, F. and Sandini, G. and Sciutti, A.},
title={Your eyes never lie: A robot magician can tell if you are lying},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2020},
pages={392-394},
doi={10.1145/3371382.3378253},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083227683&doi=10.1145%2f3371382.3378253&partnerID=40&md5=80896e7fb50b33d9c3b08ac82f389c95},
affiliation={DIBRIS, Università di Genova, Opera Pia 13, Genova, 16145, Italy; RBCS, Istituto Italiano di Tecnologia, Enrico Melen 83, Genova, 16152, Italy; ICT, Istituto Italiano di Tecnologia, Enrico Melen 83, Genova, 16152, Italy; CONTACT, Istituto Italiano di Tecnologia, Enrico Melen 83, Genova, 16152, Italy},
abstract={Detecting lies in a real-world scenario is an important skill for a humanoid robot that aims to act as a teacher, a therapist, or a caregiver. In these contexts, it is essential to detect lies while preserving the pleasantness of the social interaction and the informality of the relation. This study investigates whether pupil dilation related to an increase in cognitive load can be used to swiftly identify a lie in an entertaining scenario. The iCub humanoid robot plays the role of a magician in a card game, telling which card the human partner is lying about. The results show a greater pupil dilation in presence of a false statement even if in front of a robot and without the need of a strictly controlled scenario. We developed a heuristic method (accuracy of 71.4% against 16.6% chance level) and a random forest classifier (precision and recall of 83.3%) to detect the false statement. Additionally, the current work suggests a potential method to assess the lying strategy of the partner. © 2020 ACM.},
author_keywords={Human-robot interaction;  Humanoid robot;  Lie detection;  Machine learning;  Pupillometry},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tortora2020,
author={Tortora, L. and Meynen, G. and Bijlsma, J. and Tronci, E. and Ferracuti, S.},
title={Neuroprediction and A.I. in Forensic Psychiatry and Criminal Justice: A Neurolaw Perspective},
journal={Frontiers in Psychology},
year={2020},
volume={11},
doi={10.3389/fpsyg.2020.00220},
art_number={220},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082651882&doi=10.3389%2ffpsyg.2020.00220&partnerID=40&md5=98bb03f5c6ccee55fc554a09ef2502df},
affiliation={Department of Human Neuroscience, Sapienza University of Rome, Rome, Italy; Willem Pompe Institute for Criminal Law and Criminology/Utrecht Centre for Accountability and Liability Law (UCALL), Utrecht University, Utrecht, Netherlands; Faculty of Humanities, Vrije Universiteit Amsterdam, Amsterdam, Netherlands; Department of Computer Science, Sapienza University of Rome, Rome, Italy},
abstract={Advances in the use of neuroimaging in combination with A.I., and specifically the use of machine learning techniques, have led to the development of brain-reading technologies which, in the nearby future, could have many applications, such as lie detection, neuromarketing or brain-computer interfaces. Some of these could, in principle, also be used in forensic psychiatry. The application of these methods in forensic psychiatry could, for instance, be helpful to increase the accuracy of risk assessment and to identify possible interventions. This technique could be referred to as ‘A.I. neuroprediction,’ and involves identifying potential neurocognitive markers for the prediction of recidivism. However, the future implications of this technique and the role of neuroscience and A.I. in violence risk assessment remain to be established. In this paper, we review and analyze the literature concerning the use of brain-reading A.I. for neuroprediction of violence and rearrest to identify possibilities and challenges in the future use of these techniques in the fields of forensic psychiatry and criminal justice, considering legal implications and ethical issues. The analysis suggests that additional research is required on A.I. neuroprediction techniques, and there is still a great need to understand how they can be implemented in risk assessment in the field of forensic psychiatry. Besides the alluring potential of A.I. neuroprediction, we argue that its use in criminal justice and forensic psychiatry should be subjected to thorough harms/benefits analyses not only when these technologies will be fully available, but also while they are being researched and developed. © Copyright © 2020 Tortora, Meynen, Bijlsma, Tronci and Ferracuti.},
author_keywords={artificial intelligence;  forensic psychiatry;  neurolaw;  neuroprediction;  recidivism;  risk assessment},
document_type={Review},
source={Scopus},
}

@ARTICLE{Saquete2020,
author={Saquete, E. and Tomás, D. and Moreda, P. and Martínez-Barco, P. and Palomar, M.},
title={Fighting post-truth using natural language processing: A review and open challenges},
journal={Expert Systems with Applications},
year={2020},
volume={141},
doi={10.1016/j.eswa.2019.112943},
art_number={112943},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072269918&doi=10.1016%2fj.eswa.2019.112943&partnerID=40&md5=88d022552b153d048a93d6c79c3de6f9},
affiliation={Department of Software and Computing Systems, University of Alicante, Apdo. de Correos 99, Alicante, E-03080, Spain},
abstract={Post-truth is a term that describes a distorting phenomenon that aims to manipulate public opinion and behavior. One of its key engines is the spread of Fake News. Nowadays most news is rapidly disseminated in written language via digital media and social networks. Therefore, to detect fake news it is becoming increasingly necessary to apply Artificial Intelligence (AI) and, more specifically Natural Language Processing (NLP). This paper presents a review of the application of AI to the complex task of automatically detecting fake news. The review begins with a definition and classification of fake news. Considering the complexity of the fake news detection task, a divide-and-conquer methodology was applied to identify a series of subtasks to tackle the problem from a computational perspective. As a result, the following subtasks were identified: deception detection; stance detection; controversy and polarization; automated fact checking; clickbait detection; and, credibility scores. From each subtask, a PRISMA compliant systematic review of the main studies was undertaken, searching Google Scholar. The various approaches and technologies are surveyed, as well as the resources and competitions that have been involved in resolving the different subtasks. The review concludes with a roadmap for addressing the future challenges that have emerged from the analysis of the state of the art, providing a rich source of potential work for the research community going forward. © 2019 Elsevier Ltd},
author_keywords={Applied computing;  Automatic fact-checking;  Clickbait detection;  Credibility;  Deception detection;  Document analysis;  Document capture;  Document management and text processing;  Fake news;  Human language technologies;  Natural language processing;  Post-truth;  Stance detection},
document_type={Review},
source={Scopus},
}

@ARTICLE{Koduru202045,
author={Koduru, A. and Valiveti, H.B. and Budati, A.K.},
title={Feature extraction algorithms to improve the speech emotion recognition rate},
journal={International Journal of Speech Technology},
year={2020},
volume={23},
number={1},
pages={45-55},
doi={10.1007/s10772-020-09672-4},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077977276&doi=10.1007%2fs10772-020-09672-4&partnerID=40&md5=72268ab6bcb3de96d4b698d6f517390e},
affiliation={GRIET, Hyderabad, India},
abstract={In this digitally growing era speech emotion recognition plays significant role in several applications such as Human Computer Interface (HCI), lie detection, automotive system to assist steering, intelligent tutoring system, audio mining, security, Telecommunication, Interaction between a human and machine at home, hospitals, shops etc. Speech is a unique human characteristic used as a tool to communicate and express one’s perspective to others. Speech emotion recognition is extracting the emotions of the speaker from his or her speech signal. Feature extraction, Feature selection and classifier are three main stages of the emotion recognition. The main aim of this work is to improve the speech emotion recognition rate of a system using the different feature extraction algorithms. The work emphasizes on the preprocessing of the received audio samples where the noise from speech samples is removed using filters. In next step, the Mel Frequency Cepstral Coefficients (MFCC), Discrete Wavelet Transform (DWT), pitch, energy and Zero crossing rate (ZCR) algorithms are used for extracting the features. In feature selection stage Global feature algorithm is used to remove redundant information from features and to identify the emotions from extracted features machine learning classification algorithms are used. These feature extraction algorithms are validated for universal emotions comprising Anger, Happiness, Sad and Neutral. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={Discrete wavelet transform;  Emotion recognition;  Feature extraction;  Feature selection;  Mel Frequency Cepstral coefficients;  Preprocessing;  Zero crossing rate},
document_type={Article},
source={Scopus},
}

@ARTICLE{Nikiforos2020177,
author={Nikiforos, M.N. and Vergis, S. and Stylidou, A. and Augoustis, N. and Kermanidis, K.L. and Maragoudakis, M.},
title={Fake News Detection Regarding the Hong Kong Events from Tweets},
journal={IFIP Advances in Information and Communication Technology},
year={2020},
volume={585 IFIP},
pages={177-186},
doi={10.1007/978-3-030-49190-1_16},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086241756&doi=10.1007%2f978-3-030-49190-1_16&partnerID=40&md5=ab976de189ed5bfd08524a2fa474d47d},
affiliation={Department of Informatics, Ionian University, Corfu, Greece; Department of Information and Communication Systems Engineering, University of the Aegean, Samos, Greece},
abstract={The rapid development of network services has led to the exponential growth of online information and the increasing number of social media users. These services are exploited by malicious accounts that spread fake news and propaganda in vast user networks. Consequently, an automated solution for fake news and deception detection is required. This paper introduces a new data set consisting of 2,366 tweets written in English, regarding the Hong Kong events (August, 2019), and a well-defined method for fake news detection that uses both linguistic and network features. Our approach is tested with experiments using 2 machine learning models, achieving high performance compared to previous research. © 2020, IFIP International Federation for Information Processing.},
author_keywords={Deception detection;  Fake news detection;  Linguistic analysis;  Text analysis;  Twitter},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sánchez-Monedero2020,
author={Sánchez-Monedero, J. and Dencik, L.},
title={The politics of deceptive borders: ‘biomarkers of deceit’ and the case of iBorderCtrl},
journal={Information Communication and Society},
year={2020},
doi={10.1080/1369118X.2020.1792530},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088966575&doi=10.1080%2f1369118X.2020.1792530&partnerID=40&md5=387c9e144d46bf72d11837952fdc0db0},
affiliation={School of Journalism, Media and Culture, Cardiff University, Cardiff, United Kingdom},
abstract={This paper critically examines a recently developed proposal for a border control system called iBorderCtrl, designed to detect deception based on facial recognition technology and the measurement of micro-expressions, termed ‘biomarkers of deceit’. Funded under the European Commission’s Horizon 2020 programme, the system is analysed in relation to the wider political economy of ‘emotional AI’ and the history of deception detection technologies. We then move on to interrogate the design of iBorderCtrl using publicly available documents and assess the assumptions and scientific validation underpinning the project design. Finally, drawing on a Bayesian analysis we outline statistical fallacies in the foundational premise of mass screening and argue that it is very unlikely that the model that iBorderCtrl provides for deception detection would work in practice. By interrogating actual systems in this way, we argue that we can begin to question the very premise of the development of data-driven systems, and emotional AI and deception detection in particular, pushing back on the assumption that these systems are fulfilling the tasks they claim to be attending to and instead ask what function such projects carry out in the creation of subjects and management of populations. This function is not merely technical but, rather, we argue, distinctly political and forms part of a mode of governance increasingly shaping life opportunities and fundamental rights. © 2020 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={affective computing;  deception detection;  lie detection;  machine learning;  migration;  Smart borders},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Hu2020402,
author={Hu, S.},
title={Detecting concealed information in text and speech},
journal={ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
year={2020},
pages={402-412},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084035684&partnerID=40&md5=3467ad003a702546ad1246752ca18f15},
affiliation={Cornell University /, Ithaca, NY  14850, United States},
abstract={Motivated by infamous cheating scandals in various industries and political events, we address the problem of detecting concealed information in technical settings. In this work, we explore acoustic-prosodic and linguistic indicators of information concealment by collecting a unique corpus of professionals practicing for oral exams while concealing information. We reveal subtle signs of concealed information in speech and text, compare, and contrast them with those in deception detection literature, thus uncovering the link between concealing information and deception. We then present a series of experiments that automatically detect concealed information from text and speech. We compare the use of acoustic-prosodic, linguistic, and individual feature sets, using different machine learning models. Finally, we present a multi-task learning framework with acoustic, linguistic, and individual features, that outperforms human performance by over 15%. © 2019 Association for Computational Linguistics},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Velichko2020477,
author={Velichko, A. and Budkov, V. and Kagirov, I. and Karpov, A.},
title={Applying Ensemble Learning Techniques and Neural Networks to Deceptive and Truthful Information Detection Task in the Flow of Speech},
journal={Studies in Computational Intelligence},
year={2020},
volume={868},
pages={477-482},
doi={10.1007/978-3-030-32258-8_56},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075583069&doi=10.1007%2f978-3-030-32258-8_56&partnerID=40&md5=3243605d38d072a03247386db717ae41},
affiliation={St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences (SPIIRAS), St. Petersburg, Russian Federation},
abstract={This paper presents the results of experiments on applying ensemble learning techniques and neural networks to a paralinguistic analysis of deceptive and truthful statements in the flow of speech. Based on an analysis and comparison of different approaches to the issue, we propose using a mixture of such methods. The Real-Life Trial Deception Detection Dataset was used for both training and testing. All the experiments were performed using 10-fold cross-validation. Using two-layer neural networks, k-nearest neighbor, random forest for evaluating and principal component analysis methods for preprocessing, results in UAR of 65.0% and 70.0%, in the case of average and majority voting correspondingly. © Springer Nature Switzerland AG 2020.},
author_keywords={Computational paralinguistics;  Deception detection in speech;  Machine learning;  Speech technology},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Velichko202038,
author={Velichko, A. and Karpov, A.},
title={A study of data scarcity problem for automatic detection of deceptive speech utterances},
journal={CEUR Workshop Proceedings},
year={2020},
volume={2552},
pages={38-46},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079799663&partnerID=40&md5=4e383e2e538c817c62be3d91d503a830},
affiliation={St.Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences (SPIIRAS), St.Petersburg, Russian Federation},
abstract={In recent years there have been a lot of interest in the task of contactless automatic detection of deception in speech utterances. This task belongs to the paralinguistic area that studies the models for researching such aspects of speech as emotions, voice characteristics, psychophysiological traits etc. Despite the high relevance of the topic, there still remains the problem of the lack of data containing deceptive information. This paper presents an analysis of methods aimed to deal with the problem. Such over-sampling algorithms as SMOTE and ADASYN were explored. Copyright © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
author_keywords={ADASYN;  Computational Paralinguistics;  Deception Detection in Speech;  Machine Learning;  Oversampling;  SMOTE;  Speech Technology},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Otasowie202061,
author={Otasowie, O.},
title={Application of Machine Learning in Deception Detection},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1230 AISC},
pages={61-76},
doi={10.1007/978-3-030-52243-8_6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088517249&doi=10.1007%2f978-3-030-52243-8_6&partnerID=40&md5=257024aa5d9e2ccacf4e61a807aebf6d},
affiliation={Federal University of Technology, Akure, Nigeria},
abstract={The issue of security is a continuous struggle for all. To address this struggle, it is pertinent to reliably detect deception. To reliably detect deception is a knotty task as no ideal technique has been found for the detection. According to literature, past researches focused on single cue, it was observed that combining cues will significantly be a good indicator of deception that using a single cue. Since no single verbal or non-verbal cue is able to detect deception successfully the research proposes to combine verbal and non-verbal cues for the detection. Therefore, this research aims to develop a neurofuzzy model for classifying extracted verbal and nonverbal features as deceptive or truthful. The proposed system extracted desired features from the dataset of Perez-Rosas. The verbal cues include the voice pitch, jitters, pauses, and speechrate. The PRAAT was used in extracting all the verbal cues. The nonverbal features were extracted using the Active Shape Model (ASM) and the classification Model was designed using Neurofuzzy technique. The work was implemented in 2015a MatLab. The developed model was compared with Support Vector Machine (SVM), K-Nearest Neighbour (KNN) and Decision Tree. Neurofuzzy recorded the best performance with the Nonverbal dataset (percentage score of 97.1%), KNN performed well with the Verbal dataset (percentage score of 90.9%) while Decision Tree performed best with the VerbNon dataset (percentage score of 97.6%). From the comparative analysis it was discovered that Neurofuzzy model work well on Nonverbal dataset to detect deception. The result obtained using only verbal cue was 84.3% while that of nonverbal cue was 97.1% but on VerbNon it yielded 92.5% which is far better than the chance level of 50%. © 2020, Springer Nature Switzerland AG.},
author_keywords={Decision tree;  KNN;  Neurofuzzy;  Nonverbal cues;  SVM;  Verbal cues;  VerbNon cues},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Collins2020562,
author={Collins, B. and Hoang, D.T. and Nguyen, N.T. and Hwang, D.},
title={Fake News Types and Detection Models on Social Media A State-of-the-Art Survey},
journal={Communications in Computer and Information Science},
year={2020},
volume={1178 CCIS},
pages={562-573},
doi={10.1007/978-981-15-3380-8_49},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082108600&doi=10.1007%2f978-981-15-3380-8_49&partnerID=40&md5=26c4568a892d012d600a0bcb9bef745c},
affiliation={Department of Computer Engineering, Yeungnam University, Gyeongsan-si, South Korea; Faculty of Computer Science and Management, Wroclaw University of Science and Technology, Wroclaw, Poland; Faculty of Engineering and Information Technology, Quang Binh University, Đồng Hới, Viet Nam},
abstract={Fake news has gained prominence since the 2016 US presidential election as well as the Brexit referendum. Fake news has abused not only the press but also the democratic rules. Therefore, the need to restrict and eliminate it becomes inevitable. The popularity of fake news on social media has made people unwilling to engage in sharing positive news for fear that the information is false. The main problem with fake news is how quickly it spreads to social media. In this paper, we introduced an overview of the various models in detecting fake news such as Machine learning, Natural Language Processing, Crowd-sourced techniques, Expert fact-checker, as well as Hybrid Expert-Machine. We also do reviews of different types of fake news, which is an essential criterion for detecting fake news. Our findings show that detecting fake news is a challenging but workable task. The techniques that combine people and machines bring very satisfactory results. We also study about open issues of fake news, then propose some potential research tasks for future works. © 2020, Springer Nature Singapore Pte Ltd.},
author_keywords={Deception detection;  Fake news;  Fake news detection},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Monaro2020,
author={Monaro, M. and Zampieri, I. and Sartori, G. and Pietrini, P. and Orrù, G.},
title={The detection of faked identity using unexpected questions and choice reaction times},
journal={Psychological Research},
year={2020},
doi={10.1007/s00426-020-01410-4},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090190812&doi=10.1007%2fs00426-020-01410-4&partnerID=40&md5=8ba5c151f9581670fe7e7ad3dc6b1335},
affiliation={Department of General Psychology, University of Padua, Padua, Italy; IMT School for Advanced Studies, Lucca, Italy; Department of Surgical, Medical and Molecular Pathology and Critical Care Medicine, University of Pisa, Pisa, Italy},
abstract={The identification of faked identities, especially within the Internet environment, still remains a challenging issue both for companies and researchers. Recently, however, latency-based lie detection techniques have been developed to evaluate whether the respondent is the real owner of a certain identity. Among the paradigms applied to this purpose, the technique of asking unexpected questions has proved to be useful to differentiate liars from truth-tellers. The aim of the present study was to assess whether a choice reaction times (RT) paradigm, combined with the unexpected question technique, could efficiently detect identity liars. Results demonstrate that the most informative feature in distinguishing liars from truth-tellers is the Inverse Efficiency Score (IES, an index that combines speed and accuracy) to unexpected questions. Moreover, to focus on the predictive power of the technique, machine-learning models were trained and tested, obtaining an out-of-sample classification accuracy of 90%. Overall, these findings indicate that it is possible to detect liars declaring faked identities by asking unexpected questions and measuring RTs and errors, with an accuracy comparable to that of well-established latency-based techniques, such as mouse and keystroke dynamics recording. © 2020, The Author(s).},
document_type={Article},
source={Scopus},
}

@ARTICLE{Monaro2020494,
author={Monaro, M. and Capuozzo, P. and Ragucci, F. and Maffei, A. and Curci, A. and Scarpazza, C. and Angrilli, A. and Sartori, G.},
title={Using blink rate to detect deception: A study to validate an automatic blink detector and a new dataset of videos from liars and truth-tellers},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2020},
volume={12183 LNCS},
pages={494-509},
doi={10.1007/978-3-030-49065-2_35},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088751838&doi=10.1007%2f978-3-030-49065-2_35&partnerID=40&md5=7aa5efed903b8d4b8998a27df372bf92},
affiliation={University of Padova, Via Venezia 8, Padua, 35131, Italy; Università degli Studi di Bari Aldo Moro, Via Scipione Crisanzio, 42, Bari, 70122, Italy},
abstract={Eye-blink is a sensitive index of cognitive load and some studies have reported that it can be a useful cue for detecting deception. However, it is difficult to apply in the real forensic scenario as very complex techniques to record eye blinking are usually needed (e.g., electrooculography, eye tracker technology). In this paper, we propose a new approach to automatically detect eye blinking based on a computer vision algorithm, which does not require any expensive technology to record data. Results demonstrated that the automatic blink detector reached an accuracy similar to the electrooculogram in detecting the blink rate. Moreover, the automatic blink detector was applied to 68 videos of people who were lying or telling the truth about a past holiday, testing the difference between the two groups in terms of blink rate and response timing. Training machine learning classification models on these features, an accuracy up to 70% in identifying liars and truth-tellers was obtained. © Springer Nature Switzerland AG 2020.},
author_keywords={Automatic blink detector;  Cognitive load;  Deception;  Eye-blink;  Lie detection},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Park202071,
author={Park, H.},
title={A Study on the Faith Score of Telephone Voices Using Machine Learning},
journal={Studies in Computational Intelligence},
year={2020},
volume={847},
pages={71-80},
doi={10.1007/978-3-030-25217-5_6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077126627&doi=10.1007%2f978-3-030-25217-5_6&partnerID=40&md5=8093e9cc0735d467e7e052492835254d},
affiliation={School of Information Technology, Soongsil University, Seoul, South Korea},
abstract={Human voices are one of the easiest ways to communicate information between humans. Voice characteristics may vary from person to person and include voice rate, gentle form and function, pitch tone, language habits, and gender. Human voices are a key element of human communication. In the era of the Fourth Industrial Revolution, the voices are the main means of communication between people and people, between humans and machines, machines and machines. And for that reason, people are trying to communicate their intent clearly to others. In the process, language information and various additional information are included. Information such as emotional state, health status, reliability, presence of lies, changes due to alcohol, etc. These languages and non-linguistic information can be used as a device to assess the lie of telephone voices that appear as various parameters. Especially, it can be obtained by analyzing the relationship between the characteristics of the fundamental frequency (fundamental tone) of the vocal cords and the resonance frequency characteristics of vocal tracks. Previous studies have extracted parameters for false testimony of various telephone voices and conducted this study to evaluate whether a telephone voice is a lie. In this study, we proposed a judge to judge whether a lie is true by using a support vector machine. We propose a personal telephone truth discriminator. © 2020, Springer Nature Switzerland AG.},
author_keywords={Credit evaluation;  Faith score;  Lie detection;  Telephone voice;  Voice analysis},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={FIRE 2019 - Proceedings of the 11th annual meeting of the Forum for Information Retrieval Evaluation},
journal={ACM International Conference Proceeding Series},
year={2019},
page_count={74},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077585162&partnerID=40&md5=bd1971932cf583622ec42b9a440218dc},
abstract={The proceedings contain 15 papers. The topics discussed include: overview of the FIRE 2019 AILA track: artificial intelligence for legal assistance; on the author profiling and deception detection in Arabic shared task at FIRE; IDAT at FIRE2019: overview of the track on irony detection in Arabic tweets; overview of the HASOC track at FIRE 2019: hate speech and offensive content identification in Indo-European languages; a CNN based approach to phrase-labeling through classification of N-grams; authorship clustering using TF-IDF weighted word-embeddings; code-mixed to monolingual translation framework; unsupervised approach for monitoring satire on social media; a hybrid approach to develop the first stemmer in Maithili; and exploring the ideal depth of neural network when predicting question deletion on community question answering.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{MizanurRahman2019338,
author={Mizanur Rahman, Md. and Shome, A. and Chellappan, S. and Alim Al Islam, A.B.M.},
title={How smart your smartphone is in lie detection?},
journal={ACM International Conference Proceeding Series},
year={2019},
pages={338-347},
doi={10.1145/3360774.3360788},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079882090&doi=10.1145%2f3360774.3360788&partnerID=40&md5=1cb06db87571ccae8fe19c1771db3aa7},
affiliation={Bangladesh University of Engineering and Technology, Dhaka, Bangladesh; University of South Florida, Tampa, United States},
abstract={Lying is a (practically) unavoidable component of our day to day interactions with other people, and it includes both oral and textual communications (e.g. text entered via smartphones). Detecting when a person is lying has important applications, especially with the ubiquity of messaging via smart-phones, coupled with rampant increases in (intentional) spread of mis-information today. In this paper, we design a technique to detect whether or not a person's textual inputs when typed via a smartphone indicate lying. To do so, first, we judiciously develop a smartphone based survey that guarantees any participant to provide a mix of true and false responses. While the participant is texting out responses to each question, the smartphone measures readings from its inbuilt inertial sensors, and then computes features like shaking, acceleration, tilt angle, typing speed etc. experienced by it. Subsequently, for each participant (47 in total), we glean the true and false responses using our own experiences with them, and also via informal discussions with each participant. By comparing the responses of each participant, along with the corresponding motion features computed by the smartphone, we implement several machine learning algorithms to detect when a participant is lying, and our accuracy is around 70% in the most stringent leave-one-out evaluation strategy. Later, utilizing findings of our analysis, we develop an architecture for real-time lie detection using smartphones. Yet another user evaluation of our lie detection system yields 84%-90% accuracy in detecting false responses. © 2019 Association for Computing Machinery.},
author_keywords={Android application;  Human-Computer interaction;  Lie detection;  Machine learning;  Ubiquitous Computing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chaturvedi2019876,
author={Chaturvedi, S.K. and Hazra, A. and Bandyopadhyay, A.},
title={Handwriting Behaviour Analysis for deception detection using SVM Classifier in virtualized Environment},
journal={Proceedings of the 2nd International Conference on Smart Systems and Inventive Technology, ICSSIT 2019},
year={2019},
pages={876-880},
doi={10.1109/ICSSIT46314.2019.8987816},
art_number={8987816},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080024087&doi=10.1109%2fICSSIT46314.2019.8987816&partnerID=40&md5=6ec19355521d0a6fff3d3ebdd7c65da9},
affiliation={ICT Services Group, C-DAC Kolkata, Govt. of India, India},
abstract={There are various methods in practice to analyze deception by the law enforcing departments. Analyzing handwritten document is still considered to be one of the reliable methods of detecting deception. Handwritten documents are usual and reliable source of communication even in today's scenario. The handwritten text is considered to reflect human's body mind coordination. Researchers state that human behaviour can be analyzed by studying a person's handwriting. The paper consists of studies and implementation of online Handwritten Behaviour Analysis in proxmox-server virtualization Environment. C# language was used to implement the Behaviour Analysis part and python is used to validate the classification accuracy on the collected data. We have extended the previous work to client server mode to highlight the part of online Behaviour analysis to identify the uniqueness in characteristics of any person to differentiate deceptive and true statements. This paper will report the development and deployment of an online virtual server based handwriting behaviour analysis system using SVM based supervised Machine learning algorithm for classification. © 2019 IEEE.},
author_keywords={C#;  Deception detection;  online HandwritingBehaviourAnalysis;  PCA;  Proxmox;  python;  SVM;  Virtualisation},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hernandez-Alvarez2019187,
author={Hernandez-Alvarez, M.},
title={Detection of possible human trafficking in twitter},
journal={Proceedings - 2019 International Conference on Information Systems and Software Technologies, ICI2ST 2019},
year={2019},
pages={187-191},
doi={10.1109/ICI2ST.2019.00034},
art_number={8940411},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078101027&doi=10.1109%2fICI2ST.2019.00034&partnerID=40&md5=5c98c4fdd4274b124ee8607385921819},
affiliation={Escuela Politécnica Nacional, Departamento de Informática y Ciencias de la Computación - DICC, Quito, Ecuador},
abstract={Social networks in general and Twitter, in particular, have become criminal-friendly tools used to contact and deceive their preys and also, for making covert advertising of their illicit activities. In this paper, we collect and process tweets to detect deception related to sex trafficking using predefined criteria as input features to machine learning classifiers. According to the applicable legal law existing in most of our countries, any minor, who is used to participate in a commercial sex act is a trafficking victim. For this reason, in this work, we used the identification of the possible age of the likely victims as one of the essential criteria for the detection of tweets related to human trafficking for sexual exploitation. We tested the validity of predefined features used for the classification of suspected tweets against the rating made by experts. With reasonable precision, we detected tweets possibly related to sex trafficking of underage girls, information that might guide to the police towards antisocial Twitter users and may be useful for law enforcement in the fight against this detestable crime. We used a semi-supervised learning technique with Naîve Bayes and SVM algorithms to classify the tweets as 'suspicious' or 'not - suspicious' of being related to sex trafficking. © 2019 IEEE.},
author_keywords={Deception detection;  Features;  Hashtags;  Human trafficking;  Machine learning;  Semi-supervised learning;  Social network;  Twitter},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Liliana2019,
author={Liliana, D.Y. and Basaruddin, T.},
title={The fuzzy emotion recognition framework using semantic-linguistic facial features},
journal={IEEE Region 10 Humanitarian Technology Conference, R10-HTC},
year={2019},
volume={2019-November},
doi={10.1109/R10-HTC47129.2019.9042442},
art_number={9042442},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083038787&doi=10.1109%2fR10-HTC47129.2019.9042442&partnerID=40&md5=6069c5c3372e304b6dc54834d330a2ea},
affiliation={State Polytechnic of Jakarta, Department of Informatics and Computer, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia},
abstract={Emotion recognition through facial expression analysis is an emerging research in Artificial Intelligence which faces many challenges. The problem is the variation of facial expressions that displays human emotions. Humans can subjectively express the same emotions in various ways. To overcome the problem of ambiguity in emotion expression, a fuzzy approach is developed to analyze the facial components in determining the type of emotion. In this study, we proposed a framework for fuzzy emotion recognition as a representation of the psychologist knowledge. Three stages in the fuzzy emotion recognition were facial feature extraction with Active Appearance Model; Semantic-linguistic facial features extraction; fuzzy emotion recognition with Fuzzy Emotion Classification. System performance testing provided the best results on extended Cohn Kanade (CK+) facial expression dataset, with the accuracy of linguistic facial component recognition 0.98, and accuracy of fuzzy emotion recognition 0.90. Testing was also performed on custom-made Indonesian Mixed Emotion Dataset (IMED) which resulted in accuracy of 0.87. The fuzzy emotion recognition has a potential to be applied in various real problems such as virtual counseling, stress detection, lie detection, and e-commerce. © 2019 IEEE.},
author_keywords={Facial components;  Facial expression;  Fuzzy emotion;  Linguistic features;  Semantic features},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lakshan2019,
author={Lakshan, I. and Wickramasinghe, L. and Disala, S. and Chandrasegar, S. and Haddela, P.S.},
title={Real Time Deception Detection for Criminal Investigation},
journal={2019 National Information Technology Conference, NITC 2019},
year={2019},
doi={10.1109/NITC48475.2019.9114422},
art_number={9114422},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087204966&doi=10.1109%2fNITC48475.2019.9114422&partnerID=40&md5=ab0181cd95d392384fa685bd834d087c},
affiliation={Sri Lanka Institute of Information Technology, Dept. of Information Technology, Colombo, Sri Lanka},
abstract={Deception Detection System (PREDICTOR) is a solution to support the criminal investigation process by providing a technological analysis in justifying the guilt of an accused criminal in the investigation process. This study gives guidelines to substantiate decision making in the interrogation. In judicature, the importance of a platform that is capable of analyzing the genuineness and the (a) reliability of a lie and a truth, (b) emotion of the suspect and the (c) attentiveness has been recognized for a long period. The feasibility of using Machine Learning (ML) techniques to build such platforms has been explored before. However, no known platform could identify the suspect's authenticity, emotion, and attentiveness. The goal is to analyze the brain waves and build a real-time deception detection application to analyze lie/truth, emotion and the attentiveness, which will support the investigation process in a wide range of angles to decision making. Electroencephalogram (EEG) based real-time lie detection, emotion detection, and attention detection will be implemented using ML tools and techniques along with the help of special hardware equipment called MUSE 2 headband. Especially this equipment is required for the data acquisition as well as the creation of the final application. The outcome of this system is a solution to be used during the criminal investigation process as a deception detection system for lie, emotion and attentiveness of the suspect. This is more effective in the questioning process to get an idea of the suspect. This system will have a major impact on the Police Department, Criminal Investigation Department, and Judicial System to ensure the real criminal and reduce the workload of Criminal Investigation officers. © 2019 IEEE.},
author_keywords={Attention detection;  Criminal investigation;  Deception detection;  Electroencephalogram (EEG);  Emotion detection;  Lie detection;  Machine Learning(ML)},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Fu2019,
author={Fu, H. and Lei, P. and Tao, H. and Zhao, L. and Yang, J.},
title={Improved semi-supervised autoencoder for deception detection},
journal={PLoS ONE},
year={2019},
volume={14},
number={10},
doi={10.1371/journal.pone.0223361},
art_number={e0223361},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073052634&doi=10.1371%2fjournal.pone.0223361&partnerID=40&md5=b553f34e911c77b1a817640a88cb39da},
affiliation={School of Information Science and Engineering, Henan University of Technology, Zhengzhou, China; Key Laboratory of Underwater Acoustic Signal Processing of Ministry of Education, Southeast University, Nanjing, China},
abstract={Existing algorithms of speech-based deception detection are severely restricted by the lack of sufficient number of labelled data. However, a large amount of easily available unlabelled data has not been utilized in reality. To solve this problem, this paper proposes a semisupervised additive noise autoencoder model for deception detection. This model updates and optimizes the semi-supervised autoencoder and it consists of two layers of encoder and decoder, and a classifier. Firstly, it changes the activation function of the hidden layer in network according to the characteristics of the deception speech. Secondly, in order to prevent over-fitting during training, the specific ratio dropout is added at each layer cautiously. Finally, we directly connected the supervised classification task in the output of encoder to make the network more concise and efficient. Using the feature set specified by the INTERSPEECH 2009 Emotion Challenge, the experimental results on Columbia-SRI-Colorado (CSC) corpus and our own deception corpus show that the proposed model can achieve more advanced performance than other alternative methods with only a small amount of labelled data. © 2019 Fu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
document_type={Article},
source={Scopus},
}

@ARTICLE{vanderWalt2019562,
author={van der Walt, E. and Eloff, J.},
title={Identity deception detection: requirements and a model},
journal={Information and Computer Security},
year={2019},
volume={26},
number={4},
pages={562-574},
doi={10.1108/ICS-01-2019-0017},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067845162&doi=10.1108%2fICS-01-2019-0017&partnerID=40&md5=99ea42126241cf335efcfe02c89251a0},
affiliation={Department of Computer Science, University of Pretoria, Pretoria, South Africa},
abstract={Purpose: This paper aims to describe requirements for a model that can assist in identity deception detection (IDD) on social media platforms (SMPs). The model that was discovered demonstrates the usefulness of the requirements. The aim of the model is to identify humans lying about their identity on SMPs. Design/methodology/approach: The requirements of a model for IDD will be determined through a literature study combined with a study that identifies currently available identity related metadata on SMPs. This metadata refers to the attributes that describe a user account on an SMP. The aim is to restrict IDD to be only based on these types of attributes, as opposed to or combined with the contents of a single or multiple communications. Findings: Data science experiments were conducted and in particular supervised machine learning models were discovered that indeed detects identity deception on SMPs with an area under the receiver operator characteristics curve (ROC-AUC) of 75.5 per cent. Originality/value: SMPs allow any user to easily communicate with their friends or the general public at large. People can now be targeted at great scale, most often for malicious purposes. The reality is that many of these cyber-attacks involve some form of identity deception, where the attackers lie about who they are. Much focus to date has been on the identification of non-human deceptive accounts. This paper focuses on deceptive human accounts that target vulnerable individuals on SMPs. © 2019, Emerald Publishing Limited.},
author_keywords={Big data;  Cyber-security;  Fake identities;  Identity deception;  Social media;  Twitter},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gravanis2019201,
author={Gravanis, G. and Vakali, A. and Diamantaras, K. and Karadais, P.},
title={Behind the cues: A benchmarking study for fake news detection},
journal={Expert Systems with Applications},
year={2019},
volume={128},
pages={201-213},
doi={10.1016/j.eswa.2019.03.036},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063508692&doi=10.1016%2fj.eswa.2019.03.036&partnerID=40&md5=c4472527630e6c57f2cac6351190d910},
affiliation={Aristotle University of Thessaloniki, University Campus, Thessaloniki, 54124, Greece; A.T.E.I. of Thessaloniki, P.O BOX 141, GR - 57400, Thessaloniki, Greece},
abstract={Fake news has become a problem of great impact in our information driven society because of the continuous and intense fakesters content distribution. Information quality in news feeds is under questionable veracity calling for automated tools to detect fake news articles. Due to many faces of fakesters, creating such tool is a challenging problem. In this work, we propose a model for fake news detection using content based features and Machine Learning (ML) algorithms. To conclude in most accurate model we evaluate several feature sets proposed for deception detection and word embeddings as well. Moreover, we test the most popular ML classifiers and investigate the possible improvement reached under ensemble ML methods such as AdaBoost and Bagging. An extensive set of earlier data sources has been used for experimentation and evaluation of both feature sets and ML classifiers. Moreover, we introduce a new text corpus, the “UNBiased” (UNB) dataset, which integrates various news sources and fulfills several standards and rules to avoid biased results in classification task. Our experimental results show that the use of an enhanced linguistic feature set with word embeddings along with ensemble algorithms and Support Vector Machines (SVMs) is capable to classify fake news with high accuracy. © 2019 Elsevier Ltd},
author_keywords={Ensemble machine learning;  Fake news;  Linguistic analysis;  Machine learning;  Text classification},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gonzalez-Billandon2019,
author={Gonzalez-Billandon, J. and Aroyo, A.M. and Tonelli, A. and Pasquali, D. and Sciutti, A. and Gori, M. and Sandini, G. and Rea, F.},
title={Can a Robot Catch You Lying? A Machine Learning System to Detect Lies During Interactions},
journal={Frontiers in Robotics and AI},
year={2019},
volume={6},
doi={10.3389/frobt.2019.00064},
art_number={64},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083168101&doi=10.3389%2ffrobt.2019.00064&partnerID=40&md5=17924ef6b6004e9567abcb83b771b3eb},
affiliation={RBCS, Istituto Italiano di Tecnologia, Genova, Italy; DIBRIS, University of Genova, Genova, Italy; Istituto Italiano di Tecnologia, Genova, Italy; UVIP, Istituto Italiano di Tecnologia, Genova, Italy; ICT, Istituto Italiano di Tecnologia, Genova, Italy},
abstract={Deception is a complex social skill present in human interactions. Many social professions such as teachers, therapists and law enforcement officers leverage on deception detection techniques to support their work activities. Robots with the ability to autonomously detect deception could provide an important aid to human-human and human-robot interactions. The objective of this work is to demonstrate the possibility to develop a lie detection system that could be implemented on robots. To this goal, we focus on human and human robot interaction to understand if there is a difference in the behavior of the participants when lying to a robot or to a human. Participants were shown short movies of robberies and then interrogated by a human and by a humanoid robot “detectives.” According to the instructions, subjects provided veridical responses to half of the question and false replies to the other half. Behavioral variables such as eye movements, time to respond and eloquence were measured during the task, while personality traits were assessed before experiment initiation. Participant's behavior showed strong similarities during the interaction with the human and the humanoid. Moreover, the behavioral features were used to train and test a lie detection algorithm. The results show that the selected behavioral variables are valid markers of deception both in human-human and in human-robot interactions and could be exploited to effectively enable robots to detect lies. © Copyright © 2019 Gonzalez-Billandon, Aroyo, Tonelli, Pasquali, Sciutti, Gori, Sandini and Rea.},
author_keywords={deception;  humanoid robot;  lie detection;  ocular behavior;  random forests},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Liu2019,
author={Liu, Z. and Shabani, S. and Balet, N.G. and Sokhn, M.},
title={Detection of satiric news on social media: analysis of the phenomenon with a French dataset},
journal={Proceedings - International Conference on Computer Communications and Networks, ICCCN},
year={2019},
volume={2019-July},
doi={10.1109/ICCCN.2019.8847041},
art_number={8847041},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073159765&doi=10.1109%2fICCCN.2019.8847041&partnerID=40&md5=e79e9fa68cce62149a10a0ddfa51ac8b},
affiliation={Institute of Information Systems, University of Applied Sciences and Arts Western Switzerland (HES-SO Valais-Wallis), Sierre, Switzerland; University of Applied Sciences Western Switzerland, HEG Arc HES-SO, Neuchâtel, Switzerland},
abstract={The topic of deceptive and satiric news has drawn attention from both the public and the academic community, as such misinformation has the potential to have extremely adverse effects on individuals and society. Detecting false and satiric news automatically is a challenging problem in deception detection, and it has tremendous real-word political and social influences. In this paper, we contribute a useful French satiric dataset to the research community and provide a satiric news detection system using machine learning to automate classifications significantly. In addition, we present the preliminary results of our research designed to discriminate real news from satiric stories, and thus ultimately reduce false and satiric news distribution. © 2019 IEEE.},
author_keywords={Classification;  Fake news;  French dataset;  Machine learning;  News satire;  Social media},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Amber2019201,
author={Amber, F. and Yousaf, A. and Imran, M. and Khurshid, K.},
title={P300 Based Deception Detection Using Convolutional Neural Network},
journal={2019 2nd International Conference on Communication, Computing and Digital Systems, C-CODE 2019},
year={2019},
pages={201-204},
doi={10.1109/C-CODE.2019.8681025},
art_number={8681025},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064753824&doi=10.1109%2fC-CODE.2019.8681025&partnerID=40&md5=f44688b8ccef08de2038956c4d436589},
affiliation={Department of Electrical Engineering, Institute of Space Technology, Islamabad, Pakistan; Department of Aeronautics and Astronautics, Institute of Space Technology, Islamabad, Pakistan},
abstract={Algorithms for automatic lie detection from analysis of brain signals have remained a question of interest that fascinate the research community. Nevertheless, the detection algorithms still lack robustness while processing brain signals. The aim would be to learn whether a person is deceitful or not by detection techniques and suggest a vigorous lie detection algorithm. Moreover, recently proposed algorithms for lie detection have shown to achieve a classification accuracy of around 96%. While different classification algorithms such as Support Vector Machines, multilayer neural network, Extreme Learning Machine, and Linear Discriminant Analysis have proposed which typically utilizes three different types of features like time domain features, frequency domain features, and wavelet features, are anticipated in the literature. Accordingly, in this research paper, we presented a lie detection system from the P300 wave. For automatic optimum feature learning, we applied an approach from deep learning, Convolutional Neural Network (CNN), which is very effective for classification problems. The presented model significantly achieves high accuracy of 99.6%. The experimental outcomes show that the technique put forward achieves the maximum accuracy with a lesser amount of training and testing time and reveal improved performance. Additionally, an all-inclusive discussion on the choice of appropriate CNN architecture and classification results presented in this paper along with a comparison with the prior approaches of lie detection. © 2019 IEEE.},
author_keywords={CNN;  Comparison;  Deception detection;  Deep learning;  Lie detection;  P300 wave},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Girgis201993,
author={Girgis, S. and Amer, E. and Gadallah, M.},
title={Deep Learning Algorithms for Detecting Fake News in Online Text},
journal={Proceedings - 2018 13th International Conference on Computer Engineering and Systems, ICCES 2018},
year={2019},
pages={93-97},
doi={10.1109/ICCES.2018.8639198},
art_number={8639198},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063161783&doi=10.1109%2fICCES.2018.8639198&partnerID=40&md5=2928a1d20ca44c2d101b102e9a11cdd4},
affiliation={Faculty of Computer Science, Modern Academy for Computer Science and Management Technology, Cairo, Egypt; Faculty of Computer Science, Misr International University, Cairo, Egypt},
abstract={Spreading of fake news is a social phenomenon that is pervasive at the social level between individuals, and also through social media such as Facebook and Twitter. Fake news that we are interested in is one of many kinds of deception in social media, but it's more important one as it is created with dishonest intention to mislead people. We are concerned about this issue because we have noticed that this phenomenon has recently caused through the means of social communication to change the course of society and peoples and also their views, for example, during revolutions in some Arab countries have emerged some false news that led to the absence of truth and stirs up public opinion and also fake of news is one of the factors Trump successes in the presidential election. So we decided to face and reduce this phenomenon, which is still the main factor to choose most of our decisions. Techniques of fake news detection varied, ingenious, and often exciting. In this paper our objective is to build a classifier that can predict whether a piece of news is fake or not based only its content, thereby approaching the problem from a purely deep learning perspective by RNN technique models (vanilla, GRU) and LSTMs. We will show the difference and analysis of results by applying them to the dataset that we used called LAIR. We found that the results are close, but the GRU is the best of our results that reached (0.217) followed by LSTM (0.2166) and finally comes vanilla (0.215). Due to these results, we will seek to increase accuracy by applying a hybrid model between the GRU and CNN techniques on the same data set. © 2018 IEEE.},
author_keywords={Artificial Intelligence;  CNN(Convolutional Neural Networks);  Deception detection;  Deep Learning;  GRU (Gated Recurrent Unit);  LSTM (long short-term memories);  RNN (Recurrent Neural Network);  Vanilla},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lai201929,
author={Lai, V. and Tan, C.},
title={On human predictions with explanations and predictions of machine learning models: A case study on deception detection},
journal={FAT* 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency},
year={2019},
pages={29-38},
doi={10.1145/3287560.3287590},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061781028&doi=10.1145%2f3287560.3287590&partnerID=40&md5=2c9bd08d5a78154fd42dfd3edf181c6e},
affiliation={University of Colorado, Boulder, United States},
abstract={Humans are the final decision makers in critical tasks that involve ethical and legal concerns, ranging from recidivism prediction, to medical diagnosis, to fighting against fake news. Although machine learning models can sometimes achieve impressive performance in these tasks, these tasks are not amenable to full automation. To realize the potential of machine learning for improving human decisions, it is important to understand how assistance from machine learning models affects human performance and human agency. In this paper, we use deception detection as a testbed and investigate how we can harness explanations and predictions of machine learning models to improve human performance while retaining human agency. We propose a spectrum between full human agency and full automation, and develop varying levels of machine assistance along the spectrum that gradually increase the influence of machine predictions. We find that without showing predicted labels, explanations alone slightly improve human performance in the end task. In comparison, human performance is greatly improved by showing predicted labels (>20% relative improvement) and can be further improved by explicitly suggesting strong machine performance. Interestingly, when predicted labels are shown, explanations of machine predictions induce a similar level of accuracy as an explicit statement of strong machine performance. Our results demonstrate a tradeoff between human performance and human agency and show that explanations of machine predictions can moderate this tradeoff. © 2019 Association for Computing Machinery.},
author_keywords={Explanations;  Human agency;  Human performance;  Predictions},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={FAT∗ 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency},
journal={FAT* 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency},
year={2019},
page_count={384},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061796365&partnerID=40&md5=ec9325f95d3f5c70162e1afb480c7821},
abstract={The proceedings contain 38 papers. The topics discussed include: actionable recourse in linear classification; efficient search for diverse coherent explanations; on human predictions with explanations and predictions of machine learning models: a case study on deception detection; problem formulation and fairness; 50 years of test (un)fairness: lessons for machine learning; fairness and abstraction in sociotechnical systems; a taxonomy of ethical tensions in inferring mental health states from social media; dissecting racial bias in an algorithm that guides health decisions for 70 million people; disparate interactions: an algorithm-in-the-loop analysis of fairness in risk assessments; and an empirical study of rich subgroup fairness for machine learning.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Aroyo20191045,
author={Aroyo, A.M. and Gonzalez-Billandon, J. and Tonelli, A. and Sciutti, A. and Gori, M. and Sandini, G. and Rea, F.},
title={Can a Humanoid Robot Spot a Liar?},
journal={IEEE-RAS International Conference on Humanoid Robots},
year={2019},
volume={2018-November},
pages={1045-1052},
doi={10.1109/HUMANOIDS.2018.8624992},
art_number={8624992},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062287033&doi=10.1109%2fHUMANOIDS.2018.8624992&partnerID=40&md5=97d3cf320281250f56b6789c2f699570},
affiliation={Universita di Genova, DIBRIS, Opera Pia 1316145, Italy; Istituto Italiano di Tecnologia, U-VIP, Enrico Melen 83, Genova, 16152, Italy},
abstract={Lie detection is a necessary skill for a variety of social professions, including teachers, reporters, therapists, and law enforcement officers. Autonomous system and robots should acquire such skill to support professionals in numerous working contexts. Inspired by literature on human-human interaction, this work investigates whether the behavioral cues associated to lying - including eye movements and response temporal features - are apparent also during human-humanoid interaction and can be leveraged by the robot to detect deception. The results highlight strong similarities in the lying behavior toward humans and the robot. Further, the study proposes an implementation of a machine learning algorithm that can detect lies with an accuracy of 75%, when trained with a dataset collected during human-human and human robot interaction. Consequently, this work proposes a technological solution for humanoid interviewers that can be trained with knowledge about lie detection and reuse it to counteract deception. © 2018 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jupe2019,
author={Jupe, L.M. and Keatley, D.A.},
title={Airport artificial intelligence can detect deception: or am i lying?},
journal={Security Journal},
year={2019},
doi={10.1057/s41284-019-00204-7},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073998608&doi=10.1057%2fs41284-019-00204-7&partnerID=40&md5=e01c83bd101e1ec53125d5f2999bd899},
affiliation={Department of Psychology, University of Portsmouth, King Henry Building, King Henry 1 Street, Hants, PO1 2DY, United Kingdom; Behaviour Sequence Analysis (ReBSA) & School of Law, Murdoch University, Perth, 6150, Australia},
abstract={Since the 9/11 terrorist attacks, research has enveloped numerous areas within the psychological sciences as a means to increase the ability to spot potential threats. While airports took to heightened security protocols, many academics looked deeper into ways of detecting deception within international airport settings. Various verbal and nonverbal systems were intensely scrutinised under the empirical magnifying glass with the aim of creating security environments that are better able to detect potential threats. However, in 2018, a €4.5 m grant from the European Union’s Horizon 2020 research and innovation programme, number 700,626, was awarded to further in vivo test the use of computational methods to detect deception from facial cues. The system is deemed a noninvasive psychological profiling system and stems from that of a system called ‘Silent Talker’ (Rothwell et al. in Appl Cognit Psychol 20(6):757–777, 2006). The ‘iBorderCtrl’ AI system uses a variety of ‘at home’ pre-registration systems and real time ‘at the airport’ automatic deception detection systems. Some of the critical methods used in automated deception detection are that of micro-expressions. In this opinion article, we argue that considering the state of the psychological sciences current understanding of micro-expressions and their associations with deception, such in vivo testing is naïve and misinformed. We consider the lack of empirical research that supports the use of micro-expressions in the detection of deception and question the current understanding of the validity of specific cues to deception. With such unclear definitive and reliable cues to deception, we question the validity of using artificial intelligence that includes cues to deception, which have no current empirical support. © 2019, Springer Nature Limited.},
author_keywords={Airport security;  Artificial intelligence;  iBorderCtrl;  Lie detection;  Machine learning},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Nayel201992,
author={Nayel, H.A.},
title={NAYEL@APDA: Machine learning approach for author profiling and deception detection in Arabic texts},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2517},
pages={92-99},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076892312&partnerID=40&md5=b3f582ccea0f2086f5609c201b09bfd8},
affiliation={Department of Computer Science, Faculty of Computers and Artificial Intelligence, Benha University, Egypt},
abstract={In this paper, we describe the methods and experiments that have been used in development of our system for Author Profiling and Deception Detection in Arabic shared task. There are two tasks, Author Profiling in Arabic Tweets and Deception Detection in Arabic Texts. We have submitted three runs for each task. The proposed system depends on classical machine learning approaches namely Linear Classifier, Support Vector Machine and Multilayer Perceptron Classifier. Bag-of-Word with range of n-grams model has been used for feature extraction. Our sub- missions for the first task achieved the second, seventh and third ranks. For the second task, one of our submissions outperformed all other sub- missions developed by other teams. © Copyright 2019 for this paper by its authors.},
author_keywords={Arabic NLP;  Author Profiling;  Deception Detection},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ananthakrishnan2019100,
author={Ananthakrishnan, H. and Ranganathan, A. and Thenmozhi, D. and Aravindan, C.},
title={Arabic author profiling and deception detection using traditional learning methodologies with word embedding},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2517},
pages={100-104},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076887789&partnerID=40&md5=e58b09d1f7927dbde95e7fc696c84278},
affiliation={Department of CSE, SSN College of Engineering, India},
abstract={With the ubiquity of social media, although one's thoughts and opinions can be expressed through virtual platforms effortlessly, there have been numerous cases of posts that threaten the security of a certain community, caste, or religion or spread false propaganda against a certain group of people. Developments in the fields of Natural Language Processing and Machine Learning have paved the way to the concept of author profiling, which helps identify an author's age, demographics, and gender details. The Author Profiling in Arabic Tweets task of FIRE 2019 aims to monitor Arabic Twitter posts and profile their authors concerning their age, gender, and language variety using learning concepts. The task of Deception Detection in Arabic texts focuses on monitoring Twitter and News headlines and detect deceptive texts: Posts that are drafted to seem authentic but suggest other ulterior motives. We have adopted the concept of SGD Optimized Support Vector Machine classification with AraVec word embedding for both the tasks and have achieved a joint F-1 score of 0.3403 for Author Profiling and an average score of 0.7598 for the Deception detection task. © Copyright 2019 for this paper by its authors.},
author_keywords={Arabic Tweets;  Author profiling;  Deception Detection;  Machine Learning;  Natural Language Processing;  News;  Stochaistic gradient descent;  Support Vector Machines},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{SharmilaDevi2019136,
author={Sharmila Devi, V. and Kannimuthu, S. and Ravikumar, G. and Anand Kumar, M.},
title={KCE DALab-APDA@FIRE2019: Author profiling and deception detection in Arabic using weighted embedding},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2517},
pages={136-143},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076929941&partnerID=40&md5=2257a1f0897d7346504ff54c2fe6f97b},
affiliation={Department of Information Technology, Karpagam College of Engineering, India; Department of Computer Science and Engineering, CIET, India; Department of Information Technology, National Institute of Technology Karnataka, Surathkal, India},
abstract={This paper explaining the work submitted on Author Pro- filing and Deception Detection in Arabic Tweets shared task organized at the Forum for Information Retrieval Evaluation (FIRE) 2019. The first task Author profiling illustrates identifying the categories of au- thors based on the Arabic tweets. In the second task, the aim is to Detect deception in Arabic for two genres such as Twitter and News. Deception detection means that the automatic way of identifying false messages in the text content on social network or news. For each task, we have submitted three different systems. For submission 1, we have used the Term Frequency and Inverse Document Frequency (TFIDF) based Support Vector Machine classification and in submission 2, we have used fastText classifier. For submission 3, we have proposed a low dimensional weighted document embedding (TFIDF + Word embedding) with SVM classification. We have attained second place in the Deception detection and third in Author profiling. The performance difference between the top team results and the submitted runs are only 3.34% for Author pro- filing and 1.16% for Deception detection. © Copyright 2019 for this paper by its authors.},
author_keywords={Arabic tweets;  Author profiling;  Deception detection;  FastText Classifier;  Machine Learning;  TFIDF;  Weighted document embeddings;  Word embeddings},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zaynutdinova2019121,
author={Zaynutdinova, A. and Pisarevskaya, D. and Zubov, M. and Makarov, I.},
title={Deception detection in online media ?},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2479},
pages={121-127},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075717106&partnerID=40&md5=2070e77dc56c843a02b402d1ce6a5493},
affiliation={National Research University Higher School of Economics, Moscow, Russian Federation; Department of Data and Network Science, Central European University, Budapest, Hungary; FRC, CSC, RAS, Moscow, Russian Federation; National University of Science and Technology MISIS, Moscow, Russian Federation},
abstract={Russian Federation and European Union are fighting against fake news together with other countries in various topics. The disinformation affected British referendum of existing EU, the US election and Catalonia’s referendum are broadly studied. A need for automated fact-checking increases, European Commission’s Action Plan 8 is an evidence. In this work, we develop a model for detecting disinformation in Russian language in online media. We use reliable and unreliable sources to compare named entities and verbs extracted using DeepPavlov library. Our method shows four time greater recall compared to chosen baseline. Copyright © 2019 for this paper by its authors. Use permitted under Creative Com mons License Attribution 4.0 International (CC BY 4.0).},
author_keywords={DeepPavlov;  Fact checking;  Fake news;  Information extraction;  Named Entities},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{JavierFernaandez-BravoPenuela2019122,
author={Javier Fernaandez-Bravo Penuela, F.},
title={Deception detection in Arabic tweets and news},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2517},
pages={122-126},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076880792&partnerID=40&md5=b57a60a83cea560602463996bf189802},
affiliation={Polytechnic University of Valencia, Spain},
abstract={The project Arabic Author Profiling for Cyber-Security (ARAP)1 aims at preventing cyber-threats using Machine Learning. To this end, they monitor social media to early detect threatening messages and, in such a case, to profile the authors behind. Profiling potential terrorists from messages shared in social media may allow detecting communities whose aim is to undermine the security of others. One of this framework's main challenges is recognizing false positives, such as potential threaten- ing messages that are actually deceptive, ironic or humorous. This paper focuses on the goal of detecting deceptive messages, which are intention- ally written trying to sound authentic. This task is performed on two different genres of Arabic texts: Twitter messages and news headlines. © Copyright 2019 for this paper by its authors.},
author_keywords={Arabic text mining;  Deception detection;  Natural language processing;  Text classification},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Alrifai2019144,
author={Alrifai, K. and Rebdawi, G. and Ghneim, N.},
title={Arabic tweeps traits prediction AT2P},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2517},
pages={144-151},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076880597&partnerID=40&md5=954cd0c4d3f55b5cedba4545bd13f734},
affiliation={Higher Institute for Applied Sciences and Technology, Damascus, Syrian Arab Republic},
abstract={Author profiling is the process of extracting author traits, which constitute the profile of an author, by analyzing his/her writings. Detecting these traits is useful and important process in the domain of social media analysis. In this notebook, we present our approach for author profiling task that is one of the tasks required in Author Profiling and Deception Detection in Arabic (APDA) workshop 2019. The focus of this task is to identify the age, gender, and language variety of Arabic Twitter users (tweeps). For this purpose, several feature vectors and classifiers were evaluated to find out the best prediction models for the three traits. SMO classifier with the feature vector that consisted of UniGram and Stem was the best model for each three traits: gender, age and variety1. © Copyright 2019 for this paper by its authors.},
author_keywords={Age Prediction;  Arabic Social Media Processing;  Author Profiling;  Gender Prediction;  Machine Learning;  Variety Prediction},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Vogel2019288,
author={Vogel, I. and Jiang, P.},
title={Fake News Detection with the New German Dataset “GermanFakeNC”},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11799 LNCS},
pages={288-295},
doi={10.1007/978-3-030-30760-8_25},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072852584&doi=10.1007%2f978-3-030-30760-8_25&partnerID=40&md5=317feef5e53355f478943349b701426d},
affiliation={Fraunhofer Institute for Secure Information Technology SIT, Rheinstrasse 75, Darmstadt, 64295, Germany},
abstract={The spread of misleading information and “alternative facts” on the internet gained in the last decade considerable importance worldwide. In recent years, several attempts have been made to counteract fake news based on automatic classification via machine learning models. These, however, require labeled data. The scarcity of available corpora for predictive modeling is a major stumbling block in this field, especially in other languages than English. Our contribution is twofold. First, we introduce a new publicly available German dataset “German Fake News Corpus” (GermanFakeNC) for the task of fake news detection which consists of 490 manually fact-checked articles. Every false statement in the text is verified claim-by-claim by authoritative sources. Our ground truth for trustworthy news consists of 4,500 news articles from well-known mainstream news publishers. With regard to the second contribution, we choose a Convolutional Neural Network (CNN) (κ = 0.89) and the widely used SVM (κ = 0.72) technique to detect fake news. Thus we hope that our approach will stimulate the progress in fake news detection and claim verification across languages. © Springer Nature Switzerland AG 2019.},
author_keywords={Deception detection;  Fake news detection;  Fake statement;  German corpus},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Monaro2019342,
author={Monaro, M. and Businaro, M. and Spolaor, R. and Li, Q.Q. and Conti, M. and Gamberini, L. and Sartori, G.},
title={The online identity detection via keyboard dynamics},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={881},
pages={342-357},
doi={10.1007/978-3-030-02683-7_24},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055915458&doi=10.1007%2f978-3-030-02683-7_24&partnerID=40&md5=dec4aad75fac4293a1152f8d6d5bda3e},
affiliation={University of Padova, Padua, 35100, Italy},
abstract={Around 50% of the world population is now active on internet, often subscribing websites, social networks or other online services. In this scenario, the issue of online faked identities is more and more present, with the phenomena of identity alteration, identity theft and identity fraud. To date, there are no systems able to detect people who subscribe or authenticate an online service with faked personal information. Moreover, the existing validated lie detection techniques are not suitable to be applied in the online environment. Starting from a previous study, this paper investigates the possibility to detect faked identities recording keystroke dynamics, while the user is filling an online subscription form with personal – real or faked, information. Cognitively overloading liars through few unexpected questions, we demonstrated that it is possible to recognize the deceivers with an accuracy of 85%. To automatically detect liars, three machine-learning classifiers were trained on 40 liars and 40 truth-tellers, and tested on 10 unseen liars and 10 truth-tellers. Liars have proved to be distinguishable from truth-tellers as they make more errors and are slower in typing unexpected information about their identity. © Springer Nature Switzerland AG 2019.},
author_keywords={Faked identity;  Identity verification;  Keystroke dynamics;  Lie detection;  Online identity},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bai20194504,
author={Bai, C. and Kumar, S. and Leskovec, J. and Metzger, M. and Nunamaker, J.F. and Subrahmanian, V.S.},
title={Predicting the visual focus of attention in multi-person discussion videos},
journal={IJCAI International Joint Conference on Artificial Intelligence},
year={2019},
volume={2019-August},
pages={4504-4510},
doi={10.24963/ijcai.2019/626},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074953535&doi=10.24963%2fijcai.2019%2f626&partnerID=40&md5=676a391cb4ec0c69bd3a2851569359b3},
affiliation={Dartmouth College, United States; Stanford University, United States; Georgia Institute of Technology, United States; University of California Santa Barbara, United States; University of Arizona, United States},
abstract={Visual focus of attention in multi-person discussions is a crucial nonverbal indicator in tasks such as inter-personal relation inference, speech transcription, and deception detection. However, predicting the focus of attention remains a challenge because the focus changes rapidly, the discussions are highly dynamic, and the people's behaviors are inter-dependent. Here we propose ICAF (Iterative Collective Attention Focus), a collective classification model to jointly learn the visual focus of attention of all people. Every person is modeled using a separate classifier. ICAF models the people collectively-the predictions of all other people's classifiers are used as inputs to each person's classifier. This explicitly incorporates inter-dependencies between all people's behaviors. We evaluate ICAF on a novel dataset of 5 videos (35 people, 109 minutes, 7604 labels in all) of the popular Resistance game and a widely-studied meeting dataset with supervised prediction. ICAF outperforms the strongest baseline by 1%-5% accuracy in predicting the people's visual focus of attention. Further, we propose a lightly supervised technique to train models in the absence of training labels. We show that light-supervised ICAF performs similar to the supervised ICAF, thus showing its effectiveness and generality to previously unseen videos. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Elkins2019316,
author={Elkins, A.C. and Gupte, A. and Cameron, L.},
title={Humanoid Robots as Interviewers for Automated Credibility Assessment},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11589 LNCS},
pages={316-325},
doi={10.1007/978-3-030-22338-0_26},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069830788&doi=10.1007%2f978-3-030-22338-0_26&partnerID=40&md5=443d85c22d1b02c556320b3e3967654d},
affiliation={San Diego State University Artificial Intelligence Lab, San Diego State University, 5500 Campanile Dr, San Diego, CA  92182, United States},
abstract={Humans are poor at detecting deception under the best conditions. The need for having a decision support system that can be a baseline for data-driven decision making is obvious. Such a system is not biased like humans are, and these often subconscious human biases can impair people’s judgment. A system for helping people at border security (CBP) is the AVATAR. The AVATAR, an Embodied Conversational agent (ECA), is implemented as a self-service kiosk. Our research uses this AVATAR as the baseline and we plan to augment the automated credibility assessment task that the AVATAR performs using a Humanoid robot. We will be taking advantage of humanoid robots’ capability of realistic dialogue and nonverbal gesturing. We are also capturing data from various sensors like microphones, cameras and an eye tracker that will help in model building and testing for the task of deception detection. We plan to carry out an experiment where we compare the results of an interview with the AVATAR and an interview with a humanoid robot. Such a comparative analysis has never been done before, hence we are very eager to conduct such a social experiment. This research paper deals with the design and implementation plan for such an experiment. We also want to highlight what the considerations are while designing such a social experiment. It will help us understand how people perceive robot agent interactions in contrast to the more traditional ECA agents on screen. For example, does the physical presence of a robot encourage greater perceptions of likability, expertise, or dominance? Moreover, this research will address the question on which interaction model (ECA or robot) elicits the most diagnostic cues to detecting deception. This study may also prove very useful to researchers and organizations that want to use robots in increasing social roles and need to understand its societal and personal implications. © 2019, Springer Nature Switzerland AG.},
author_keywords={AI;  Credibility assessment;  Human-Robot interaction;  Social experiment with robots},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tang2018101,
author={Tang, H. and Lu, X. and Cui, Z. and Feng, C. and Lin, Q. and Cui, X. and Su, S. and Liu, C.},
title={Resting-state Functional Connectivity and Deception: Exploring Individualized Deceptive Propensity by Machine Learning},
journal={Neuroscience},
year={2018},
volume={395},
pages={101-112},
doi={10.1016/j.neuroscience.2018.10.036},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056879035&doi=10.1016%2fj.neuroscience.2018.10.036&partnerID=40&md5=d1cd9520192865f4d33f914d6df81784},
affiliation={Business School, Beijing Normal University, Beijing, 100875, China; State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern Institute for Brain Research, Beijing Normal University, Beijing, 100875, China; Brain, Mind & Markets Laboratory, Department of Finance, The University of Melbourne, Victoria, 3010, Australia; Department of Psychiatry, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA  19104, United States; Center for Collaboration and Innovation in Brain and Learning Sciences, Beijing Normal University, Beijing, 100875, China; Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal University, Beijing, China},
abstract={Individuals show marked variability in determining to be honest or deceptive in daily life. A large number of studies have investigated the neural substrates of deception; however, the brain networks contributing to the individual differences in deception remain unclear. In this study, we sought to address this issue by employing a machine-learning approach to predict individuals’ deceptive propensity based on the topological properties of whole-brain resting-state functional connectivity (RSFC). Participants finished the resting-state functional MRI (fMRI) data acquisition, and then, one week later, participated as proposers in a modified ultimatum game in which they spontaneously chose to be honest or deceptive. A linear relevance vector regression (RVR) model was trained and validated to examine the relationship between topological properties of networks of RSFC and actual deceptive behaviors. The machine-learning model sufficiently decoded individual differences in deception using three brain networks based on RSFC, including the executive controlling network (dorsolateral prefrontal cortex, middle frontal cortex, and orbitofrontal cortex), the social and mentalizing network (the temporal lobe, temporo-parietal junction, and inferior parietal lobule), and the reward network (putamen and thalamus). These networks have been found to form a signaling cognitive framework of deception by coding the mental states of others and the reward or values of deception or honesty, and integrating this information to make a final decision about being deceptive or honest. These findings suggest the potential of using RSFC as a task-independent neural trait for predicting deceptive propensity, and shed light on using machine-learning approaches in deception detection. © 2018 IBRO},
author_keywords={cross validation;  deception;  individual difference;  machine learning;  neural trait;  resting-state fMRI},
document_type={Article},
source={Scopus},
}

@CONFERENCE{AswathiVarsha2018,
author={Aswathi Varsha, K.T.K. and Lalitha, S.},
title={Stress Recognition Using Sparse Representation of Speech Signal for Deception Detection Applications in Indian Context},
journal={2017 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2017},
year={2018},
doi={10.1109/ICCIC.2017.8524204},
art_number={8524204},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057994712&doi=10.1109%2fICCIC.2017.8524204&partnerID=40&md5=5f9b2c9d64b2fe7a6665366e86ff6579},
affiliation={Amrita University, Department of Electronics Communication Engineering, Bengaluru, India},
abstract={This work aims at stress recognition of a person using sparse representation of speech samples for a real time application of deception detection. A learned dictionary using K-Singular Value Decomposition (K-SVD) is considered for sparse signal representation. The work incorporates parameterization of nonlinear Teagor Energy Operated Critical Band Autocorrelation Envelop (TEO-CB-Auto-Env) feature extraction of speech samples. The database developed by IIT Guwahati with five stress categories includes Angry, Happy, Lombard, Neutral and Sad. The corpus has speech samples in Hindi language and hence the proposed stress classification system is applicable for Indian context. Weka, Neural Network and Autoencoder Neural Network are used for classification. A better recognition accuracy around 5% higher is gained in this work compared with earlier work on speech based stress recognition on the same database. The comparative performance shows that Random Forest classifier from Weka performs better than Neural Network and Autoencoder Neural Network. © 2017 IEEE.},
author_keywords={K-SVD algorithm;  Sparse Representation;  TEO-CB-Auto-Env feature},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Krigel2018,
author={Krigel, T. and Li, M. and Schitze, R.B. and Wellington, L. and Stoklas, D.-J.J.},
title={Legal, ethical and social impact on the use of computational intelligence based systems for land border crossings},
journal={Proceedings of the International Joint Conference on Neural Networks},
year={2018},
volume={2018-July},
doi={10.1109/IJCNN.2018.8489349},
art_number={8489349},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056534249&doi=10.1109%2fIJCNN.2018.8489349&partnerID=40&md5=5f92370acac5c5e8f67323dca224d699},
affiliation={Institute for Legal Informatics, Leibniz Universität Hannover, D-Hanover, Germany},
abstract={This paper provides an overview on the most relevant legal, ethical and social implications arising from the use of computational intelligence based systems for land border crossings. Based on the automatic deception detection system (ADDS) developed in the iBorderCtrl project, issues such as the peculiarities of the interaction of humans with machines, profiling, automated decision-making and the risk of false positives can be identified and demonstrate how computational intelligence based systems can challenge fundamental legal and ethical principles. These include in particular the right to privacy, human dignity and the principle of non-discrimination. By further analysing the various issues, this paper seeks to provide some thoughts on remedies and safeguards which should be considered when developing computational intelligence based systems. © 2018 IEEE.},
author_keywords={Border Control;  Computational Intelligence;  Data Protection;  Ethics;  Fundamental Rights;  Law;  Privacy},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{vanderWalt201876,
author={van der Walt, E. and Eloff, J.H.P. and Grobler, J.},
title={Cyber-security: Identity deception detection on social media platforms},
journal={Computers and Security},
year={2018},
volume={78},
pages={76-89},
doi={10.1016/j.cose.2018.05.015},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049334380&doi=10.1016%2fj.cose.2018.05.015&partnerID=40&md5=a8d8c067dac9b27d2e4860dbf46f529e},
affiliation={Department of Computer Science, Information Technology Building - Level 4, University of Pretoria, Lynnwood Road, Pretoria, South Africa; Department of Industrial and Systems Engineering, Engineering building 2 Level 3, University of Pretoria, Lynnwood Road Pretoria, South Africa},
abstract={Social media platforms allow billions of individuals to share their thoughts, likes and dislikes in real-time, without any censorship. This freedom, however, comes at a cyber-security risk. Cyber threats are more difficult to detect in a cyber world where anonymity and false identities are ever-present. The speed at which these deceptive identities evolve calls for solutions to detect identity deception. Cyber-security threats caused by humans on social media platforms are widespread and warrant attention. This research posits a solution towards the intelligent detection of deceptive identities contrived by human individuals on social media platforms (SMPs). Firstly, this research evaluates machine learning models by using attributes such as the “profile image” found on SMPs. To improve on the results delivered by these models, past research findings from the field of psychology, such as that humans lie about their gender, are used. Newly engineered features such as “gender-derived-from-the-profile-image” are evaluated to grasp whether these features detect deception with greater accuracy. Furthermore, research results from detecting non-human (also known as bot) accounts are also leveraged to improve on the initial results. These machine learning results are lastly applied to a proposed model for the intelligent detection and interpretation of identity deception on SMPs. This paper shows that the cyber-security threat of identity deception can potentially be minimized, should the vulnerability in the current way of setting up user accounts on SMPs be re-engineered in the future. © 2018 Elsevier Ltd},
author_keywords={Big data;  Bots;  Cyber-security;  Grooming;  Identity deception;  Social media},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Nair20186,
author={Nair, A.V. and Kumar, K.M. and Mathew, J.},
title={An Improved Approach for EEG Signal Classification using Autoencoder},
journal={Proceedings of the 2018 8th International Symposium on Embedded Computing and System Design, ISED 2018},
year={2018},
pages={6-10},
doi={10.1109/ISED.2018.8704011},
art_number={8704011},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065960590&doi=10.1109%2fISED.2018.8704011&partnerID=40&md5=82373dec4dc846e218ca6a4bb5c367af},
affiliation={Indian Institute of Technology PatnaBihar, India},
abstract={Brain signals were started to use in deception detection process from last few years. Electroencephalogram (EEG) signals can reveal many important features of our thought which make it as a better tool for deception detection. A number of experiments were done in terms of visual stimuli based EEG signals. The purpose of this paper is to improvise the existing methods in the classification of familiar and unfamiliar faces which can be used as a basic model in deception detection. In this paper, we proposed a deep learning based classification of EEG signals for the given visual stimuli. In this experiment, the subjects were shown by familiar and unfamiliar faces. After processing using Independent Component Analysis (ICA), the signal was fed to an autoencoder for classification. By training the model properly we got a mean accuracy of 82.21% which is far better than the models using conventional machine learning methods. Our model achieved the state of the art results for classification of familiar and unfamiliar EEG signals. © 2018 IEEE.},
author_keywords={Autoencoder;  Deception;  Electroencephalography (EEG);  Independent Component Analysis (ICA)},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Warnita20181,
author={Warnita, T. and Lestari, D.P.},
title={Construction and analysis of Indonesian-interviews deception corpus},
journal={2017 20th Conference of the Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques, O-COCOSDA 2017},
year={2018},
pages={1-6},
doi={10.1109/ICSDA.2017.8384472},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050011873&doi=10.1109%2fICSDA.2017.8384472&partnerID=40&md5=bd85a014489a6d50498ccbc8488c8100},
affiliation={School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Indonesia},
abstract={In this paper, we present the first deception corpus in Indonesian to support deception detection based on statistical machine learning approach due to the importance of data in related studies. We collect speech recordings along with their high frame rate video from 30 subjects to develop Indonesian Deception Corpus (IDC). Using financial motivation as its basic scenario, IDC consists of 5542 speech segments with a total duration of approximately 16 hours and 34 minutes. As an imbalanced corpus, the majority class is represented by truth segments which is almost four times higher than the lie segments. We also perform some experiments using only the speech corpus, along with the transcriptions. Using the combination of paralinguistic, prosodic, and lexical features, we obtained the best accuracy of 61.26% and F-measure of 61.30% using Random Forest classifier and RUS as the undersampling technique. © 2017 IEEE.},
author_keywords={Deception;  deception detection;  Indonesian;  speech corpus;  video corpus},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Carissimi2018599,
author={Carissimi, N. and Beyan, C. and Murino, V.},
title={A multi-view learning approach to deception detection},
journal={Proceedings - 13th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2018},
year={2018},
pages={599-606},
doi={10.1109/FG.2018.00095},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049395576&doi=10.1109%2fFG.2018.00095&partnerID=40&md5=d712272ce9731c1b25188968d9961230},
affiliation={Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia, Genova, Italy; Dept. of Computer Science, University of Verona, Verona, Italy},
abstract={Recently, automatic deception detection has gained momentum thanks to advances in computer vision, computational linguistics and machine learning research fields. The majority of the work in this area focused on written deception and analysis of verbal features. However, according to psychology, people display various nonverbal behavioral cues, in addition to verbal ones, while lying. Therefore, it is important to utilize additional modalities such as video and audio to detect deception accurately. When multi-modal data was used for deception detection, previous studies concatenated all verbal and nonverbal features into a single vector. This concatenation might not be meaningful, because different feature groups can have different statistical properties, leading to lower classification accuracy. Following this intuition, we apply, for the first time in deception detection, a multi-view learning (MVL) approach, where each view corresponds to a feature group. This results in improved classification results over the state of the art methods. Additionally, we show that the optimized parameters of the MVL algorithm can give insights into the contribution of each feature group to the final results, thus revealing the importance of each feature and eliminating the need of performing feature selection as well. Finally, we focus on analyzing face-based low level, not hand crafted features, which are extracted using various pre-trained Deep Neural Networks (DNNs), showing that face is the most important nonverbal cue for the detection of deception. © 2018 IEEE.},
author_keywords={Deception detection;  Deep learning;  Multi-view learning;  Multiple kernel learning;  Nonverbal behavior;  Social interactions},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Quijano-Sánchez2018155,
author={Quijano-Sánchez, L. and Liberatore, F. and Camacho-Collados, J. and Camacho-Collados, M.},
title={Applying automatic text-based detection of deceptive language to police reports: Extracting behavioral patterns from a multi-step classification model to understand how we lie to the police},
journal={Knowledge-Based Systems},
year={2018},
volume={149},
pages={155-168},
doi={10.1016/j.knosys.2018.03.010},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043353026&doi=10.1016%2fj.knosys.2018.03.010&partnerID=40&md5=2d276ee5122be7d9796a88e30edeb196},
affiliation={UC3M-BS Institute of Financial Big Data, Universidad Carlos III de Madrid, Getafe, Madrid, Spain; Department of Statistics and Operational Research, Universidad Complutense de Madrid, Getafe, Madrid, Spain; Department of Computer Science, Università degli Studi di Roma “La Sapienza”, Rome, Italy; State Secretariat for Security, Interior MinistryMadrid, Spain},
abstract={Filing a false police report is a crime that has dire consequences on both the individual and the system. In fact, it may be charged as a misdemeanor or a felony. For the society, a false report results in the loss of police resources and contamination of police databases used to carry out investigations and assessing the risk of crime in a territory. In this research, we present VeriPol, a model for the detection of false robbery reports based solely on their text. This tool, developed in collaboration with the Spanish National Police, combines Natural Language Processing and Machine Learning methods in a decision support system that provides police officers the probability that a given report is false. VeriPol has been tested on more than 1000 reports from 2015 provided by the Spanish National Police. Empirical results show that it is extremely effective in discriminating between false and true reports with a success rate of more than 91%, improving by more than 15% the accuracy of expert police officers on the same dataset. The underlying classification model can be analysed to extract patterns and insights showing how people lie to the police (as well as how to get away with false reporting). In general, the more details provided in the report, the more likely it is to be honest. Finally, a pilot study carried out in June 2017 has demonstrated the usefulness of VeriPol on the field. © 2018},
author_keywords={Decision support systems;  Information extraction;  Lie detection;  Model knowledge extraction;  Natural language processing;  Predictive policing},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kleinberg2018714,
author={Kleinberg, B. and Mozes, M. and Arntz, A. and Verschuere, B.},
title={Using Named Entities for Computer-Automated Verbal Deception Detection},
journal={Journal of Forensic Sciences},
year={2018},
volume={63},
number={3},
pages={714-723},
doi={10.1111/1556-4029.13645},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030320302&doi=10.1111%2f1556-4029.13645&partnerID=40&md5=5cba36683b147dbd557a979eb2520ed5},
affiliation={Department of Psychology, University of Amsterdam, Nieuwe Achtergracht 129 D, Amsterdam, 1018 WS, Netherlands; Department of Informatics, Technical University of Munich, Boltzmannstr. 3, Garching near, Munich, Germany},
abstract={There is an increasing demand for automated verbal deception detection systems. We propose named entity recognition (NER; i.e., the automatic identification and extraction of information from text) to model three established theoretical principles: (i) truth tellers provide accounts that are richer in detail, (ii) contain more contextual references (specific persons, locations, and times), and (iii) deceivers tend to withhold potentially checkable information. We test whether NER captures these theoretical concepts and can automatically identify truthful versus deceptive hotel reviews. We extracted the proportion of named entities with two NER tools (spaCy and Stanford's NER) and compared the discriminative ability to a lexicon word count approach (LIWC) and a measure of sentence specificity (speciteller). Named entities discriminated truthful from deceptive hotel reviews above chance level, and outperformed the lexicon approach and sentence specificity. This investigation suggests that named entities may be a useful addition to existing automated verbal deception detection approaches. © 2017 American Academy of Forensic Sciences},
author_keywords={computational linguistics;  criteria-based content analysis;  deception detection;  forensic science;  linguistic inquiry and word count;  named entity recognition;  reality monitoring},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kleinberg2018354,
author={Kleinberg, B. and van der Toolen, Y. and Vrij, A. and Arntz, A. and Verschuere, B.},
title={Automated verbal credibility assessment of intentions: The model statement technique and predictive modeling},
journal={Applied Cognitive Psychology},
year={2018},
volume={32},
number={3},
pages={354-366},
doi={10.1002/acp.3407},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044719207&doi=10.1002%2facp.3407&partnerID=40&md5=b09ef167adb42cc4152ec4699a3fcafc},
affiliation={Department of Psychology, University of Amsterdam, Amsterdam, Netherlands; Department of Psychology, University of Portsmouth, Portsmouth, United Kingdom},
abstract={Recently, verbal credibility assessment has been extended to the detection of deceptive intentions, the use of a model statement, and predictive modeling. The current investigation combines these 3 elements to detect deceptive intentions on a large scale. Participants read a model statement and wrote a truthful or deceptive statement about their planned weekend activities (Experiment 1). With the use of linguistic features for machine learning, more than 80% of the participants were classified correctly. Exploratory analyses suggested that liars included more person and location references than truth-tellers. Experiment 2 examined whether these findings replicated on independent-sample data. The classification accuracies remained well above chance level but dropped to 63%. Experiment 2 corroborated the finding that liars' statements are richer in location and person references than truth-tellers' statements. Together, these findings suggest that liars may over-prepare their statements. Predictive modeling shows promise as an automated veracity assessment approach but needs validation on independent data. © 2018 The Authors Applied Cognitive Psychology Published by John Wiley & Sons Ltd.},
author_keywords={credibility assessment;  intentions;  machine learning;  model statement;  verbal deception detection},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Volkova2018575,
author={Volkova, S. and Jang, J.Y.},
title={Misleading or Falsification: Inferring Deceptive Strategies and Types in Online News and Social Media},
journal={The Web Conference 2018 - Companion of the World Wide Web Conference, WWW 2018},
year={2018},
pages={575-583},
doi={10.1145/3184558.3188728},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057214675&doi=10.1145%2f3184558.3188728&partnerID=40&md5=d7c74a78415c36a70bdead5ba8f97310},
affiliation={Pacific Northwest National Laboratory, Richland, WA, United States},
abstract={Deceptive information in online news and social media has had dramatic effect on our society in recent years. This study is the first to gain deeper insights into writers' intent behind digital misinformation by analyzing psycholinguistic signals: moral foundations and connotations extracted from different types of deceptive news ranging from strategic disinformation to propaganda and hoaxes. To ensure consistency of our findings and generalizability across domains, we experiment with data from: (1) confirmed cases of disinformation in news summaries, (2) propaganda, hoax, and disinformation news pages, and (3) social media news. We first contrast lexical markers of biased language, syntactic and stylistic signals, and connotations across deceptive news types including disinformation, propaganda, and hoaxes, and deceptive strategies including misleading or falsification. We then incorporate these insights to build machine learning and deep learning predictive models to infer deception strategies and deceptive news types. Our experimental results demonstrate that unlike earlier work on deception detection, content combined with biased language markers, moral foundations, and connotations leads to better predictive performance of deception strategies compared to syntactic and stylistic signals (as reported in earlier work on deceptive reviews). Falsification strategy is easier to identify than misleading strategy. Disinformation is more difficult to predict than to propaganda or hoaxes. Deceptive news types (disinformation, propaganda, and hoaxes), unlike deceptive strategies (falsification and misleading), are more salient, and thus easier to identify in tweets than in news reports. Finally, our novel connotation analysis across deception types provides deeper understanding of writers' perspectives and therefore reveals the intentions behind digital misinformation. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License.},
author_keywords={connotation analysis;  deception;  deep learning;  machine learning;  misinformation;  natural language processing;  social media analysis},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Monaro2018,
author={Monaro, M. and Gamberini, L. and Zecchinato, F. and Sartori, G.},
title={False identity detection using complex sentences},
journal={Frontiers in Psychology},
year={2018},
volume={9},
number={MAR},
doi={10.3389/fpsyg.2018.00283},
art_number={283},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043332390&doi=10.3389%2ffpsyg.2018.00283&partnerID=40&md5=8a80f550d744ee1dc63ed2e69e21c9d8},
affiliation={Human Inspired Technology Research Centre, University of Padova, Padova, Italy; Department of General Psychology, University of Padova, Padova, Italy},
abstract={The use of faked identities is a current issue for both physical and online security. In this paper, we test the differences between subjects who report their true identity and the ones who give fake identity responding to control, simple, and complex questions. Asking complex questions is a new procedure for increasing liars' cognitive load, which is presented in this paper for the first time. The experiment consisted in an identity verification task, during which response time and errors were collected. Twenty participants were instructed to lie about their identity, whereas the other 20 were asked to respond truthfully. Different machine learning (ML) models were trained, reaching an accuracy level around 90-95% in distinguishing liars from truth tellers based on error rate and response time. Then, to evaluate the generalization and replicability of these models, a new sample of 10 participants were tested and classified, obtaining an accuracy between 80 and 90%. In short, results indicate that liars may be efficiently distinguished from truth tellers on the basis of their response times and errors to complex questions, with an adequate generalization accuracy of the classification models. © 2018 Monaro, Gamberini, Zecchinato and Sartori.},
author_keywords={Complex questions;  Deception detection;  Faked identities;  Lie detection;  Reaction times},
document_type={Article},
source={Scopus},
}

@BOOK{Sartori2018215,
author={Sartori, G. and Zangrossi, A. and Monaro, M.},
title={Deception Detection With Behavioral Methods: The Autobiographical Implicit Association Test, Concealed Information Test-Reaction Time, Mouse Dynamics, and Keystroke Dynamics},
journal={Detecting Concealed Information and Deception: Recent Developments},
year={2018},
pages={215-241},
doi={10.1016/B978-0-12-812729-2.00010-0},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046720155&doi=10.1016%2fB978-0-12-812729-2.00010-0&partnerID=40&md5=4c80416096cb9252634a041c28dfa022},
affiliation={University of Padova, Padova, Italy},
abstract={In this chapter, we present a review of the behavioral lie detection tools currently available in the literature. Behavioral lie detection methods are based on the assumptions that being deceptive is cognitively more complex than telling the truth and that this greater complexity is reflected in an alteration of the subject's behavior during a task. Thus, these techniques are mainly based on analyzing the accuracy and response latency when the subject responds to questions related to the object of the investigation. They can be classified into two main categories, depending on whether they use the true memory among the response alternatives. We depict the main techniques for each category, focusing on the benefits and drawbacks of each tool. We give particular attention to new lie detection technologies that exploit human-computer interactions for behavioral analysis, and their applications. Moreover, we present new paradigms and novel approaches for increasing liars' cognitive loads. Finally, we discuss methodological observations regarding the application of machine learning in lie detection research. © 2018 Elsevier Inc. All rights reserved.},
author_keywords={AIAT;  Behavioral lie detection;  Keystroke dynamics;  Machine learning;  Mouse dynamics;  Reaction times},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Gogate20181,
author={Gogate, M. and Adeel, A. and Hussain, A.},
title={Deep learning driven multimodal fusion for automated deception detection},
journal={2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings},
year={2018},
volume={2018-January},
pages={1-6},
doi={10.1109/SSCI.2017.8285382},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046096761&doi=10.1109%2fSSCI.2017.8285382&partnerID=40&md5=61875776e540b5b8544f0220eb845fe8},
affiliation={CogBID Lab, Department of Computing Science and Mathematics, University of Stirling, Stirling, FK9 4LA, United Kingdom},
abstract={Humans ability to detect lies is no more accurate than chance according to the American Psychological Association. The state-of-the-art deception detection methods, such as deception detection stem from early theories and polygraph have proven to be unreliable. Recent advancement in deception detection includes the application of advanced data analysis and machine learning algorithms. This paper presents a novel deep learning driven multimodal fusion for automated deception detection, incorporating audio cues for the first time along with the visual and textual cues. The critical analysis and comparison of the proposed deep convolutional neural network (CNN) based approach with the state-of-the-art multimodal fusion methods have revealed significant performance improvement up to 96% as compared to the 82% prediction accuracy reported in the recent literature. © 2017 IEEE.},
author_keywords={Deception Detection;  Deep Convolutional Neural Network;  Multimodal Fusion},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wu20181695,
author={Wu, Z. and Singh, B. and Davis, L.S. and Subrahmanian, V.S.},
title={Deception detection in videos},
journal={32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
year={2018},
pages={1695-1702},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060442431&partnerID=40&md5=4e2a9b71bae8bb4dbd02a37ab710ea94},
affiliation={University of Maryland, United States; Dartmouth College, United States},
abstract={We present a system for covert automated deception detection using information available in a video. We study the importance of different modalities like vision, audio and text for this task. On the vision side, our system uses classifiers trained on low level video features which predict human micro-expressions. We show that predictions of high-level micro-expressions can be used as features for deception prediction. Surprisingly, IDT (Improved Dense Trajectory) features which have been widely used for action recognition, are also very good at predicting deception in videos. We fuse the score of classifiers trained on IDT features and high-level micro-expressions to improve performance. MFCC (Mel-frequency Cepstral Coefficients) features from the audio domain also provide a significant boost in performance, while information from transcripts is not very beneficial for our system. Using various classifiers, our automated system obtains an AUC of 0.877 (10-fold cross-validation) when evaluated on subjects which were not part of the training set. Even though state-of-the-art methods use human annotations of micro-expressions for deception detection, our fully automated approach outperforms them by 5%. When combined with human annotations of micro-expressions, our AUC improves to 0.922. We also present results of a user-study to analyze how well do average humans perform on this task, what modalities they use for deception detection and how they perform if only one modality is accessible. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Velichko2018737,
author={Velichko, A. and Budkov, V. and Kagirov, I. and Karpov, A.},
title={Comparative Analysis of Classification Methods for Automatic Deception Detection in Speech},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11096 LNAI},
pages={737-746},
doi={10.1007/978-3-319-99579-3_75},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053784280&doi=10.1007%2f978-3-319-99579-3_75&partnerID=40&md5=fc571144589c34e72df1d74211d2aca7},
affiliation={St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences (SPIIRAS), St. Petersburg, Russian Federation; ITMO University, St. Petersburg, Russian Federation},
abstract={This paper presents the experimental results carried on the speech processing methods for paralinguistic analysis of deceptive and truthful statements. It includes a short survey of databases that contain both deceptive and truthful speech samples, as well as recently developed deception detection systems that were proposed within the framework of computational paralinguistic challenge ComParE-2016 and other scopes. Based on the analysis and comparison of different approaches for processing deceptive and truthful utterances the best methods and optimal parameters are reported as following. The highest performance in terms of Unweighted Average Recall (UAR) measure has been obtained by a Random Forest based classifier with UAR = 79.3%. High results have been shown by a single k-Nearest Neighbor classifier, as well as its combination with other classification methods such as Bagging and Classification via Regression, which demonstrated UAR = 76.3%. © 2018, Springer Nature Switzerland AG.},
author_keywords={Computational paralinguistics;  Deception detection in speech;  Machine learning;  Speech technology},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Levitan2018416,
author={Levitan, S.I. and Maredia, A. and Hirschberg, J.},
title={Acoustic-prosodic indicators of deception and trust in interview dialogues},
journal={Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
year={2018},
volume={2018-September},
pages={416-420},
doi={10.21437/Interspeech.2018-2443},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054970165&doi=10.21437%2fInterspeech.2018-2443&partnerID=40&md5=33c929ca0b6c2a02e4b964d28787a59b},
affiliation={Department of Computer Science, Columbia University, United States},
abstract={We analyze a set of acoustic-prosodic features in both truthful and deceptive responses to interview questions, identifying differences between truthful and deceptive speech. We also study the perception of deception, identifying acoustic-prosodic characteristics of speech that is perceived as truthful or deceptive by interviewers. In addition to studying differences across all speakers, we identify variations in deception production and perception across gender and native language. We conduct machine learning classification experiments aimed at distinguishing between truthful and deceptive speech, using acoustic-prosodic features. We also explore methods of leveraging individual traits for deception classification. Our results show that acoustic-prosodic features are highly effective at classifying deceptive speech. Our best classifier achieved an F1-score of 72.77, well above both the random baseline and above human performance at this task. This work advances our understanding of deception production and perception, and has implications for automatic deception detection and the development of synthesized speech that is trustworthy. © 2018 International Speech Communication Association. All rights reserved.},
author_keywords={Computational paralin-guistics;  Deception;  Prosody;  Trust},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Levitan20181941,
author={Levitan, S.I. and Maredia, A. and Hirschberg, J.},
title={Linguistic cues to deception and perceived deception in interview dialogues},
journal={NAACL HLT 2018 - 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
year={2018},
volume={1},
pages={1941-1950},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054959673&partnerID=40&md5=e8032c15723d8e67095728793a8df028},
affiliation={Department of Computer Science, Columbia University, New York, NY, United States},
abstract={We explore deception detection in interview dialogues. We analyze a set of linguistic features in both truthful and deceptive responses to interview questions. We also study the perception of deception, identifying characteristics of statements that are perceived as truthful or deceptive by interviewers. Our analysis show significant differences between truthful and deceptive question responses, as well as variations in deception patterns across gender and native language. This analysis motivated our selection of features for machine learning experiments aimed at classifying globally deceptive speech. Our best classification performance is 72.74 F1-Score (about 27% better than human performance), which is achieved using a combination of linguistic features and individual traits. © 2018 The Association for Computational Linguistics.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bablani201832,
author={Bablani, A. and Edla, D.R. and Tripathi, D. and Venkatanareshbabu, K.},
title={Subject based Deceit Identification using Empirical Mode Decomposition},
journal={Procedia Computer Science},
year={2018},
volume={132},
pages={32-39},
doi={10.1016/j.procs.2018.05.056},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049060377&doi=10.1016%2fj.procs.2018.05.056&partnerID=40&md5=88963914509f7b557bc3a7369cb43232},
affiliation={Department of Computer Science and Engineering, National Institute of Technology, Goa, 403401, India},
abstract={EEG based lie detectors are gaining attention these days as polygraphs test for deception detection are controlled by human. These detectors use ERP components of EEG to analyze the concealed behavior of any subject. Here in this paper, Empirical Mode Decomposition (EMD) for EEG feature extraction has been applied, as it provide information of both time and frequency domain of a signal. Further, various classifiers have been applied on EEG data to identify subject as guilty or innocent. Classifiers such as SVM, QDA, KNN and decision tree are applied on subject wise EEG data. A novel set of experiments are performed with various participants and analyzed whether they are lying or telling truth. For experimental analysis subjects are presented certain images as stimuli and their responses are recorded and further analyzed. According to results obtained, for most of the subjects, SVM has performed better than others on recorded EEG dataset. © 2018 The Authors. Published by Elsevier Ltd.},
author_keywords={Electroencephalography;  Empirical Mode Decomposition;  Event Related Potential;  P300;  Support Vector Machine},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Qin2018205,
author={Qin, Z. and Gedeon, T. and Caldwell, S.},
title={Neural networks assist crowd predictions in discerning the veracity of emotional expressions},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11306 LNCS},
pages={205-216},
doi={10.1007/978-3-030-04224-0_18},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059036805&doi=10.1007%2f978-3-030-04224-0_18&partnerID=40&md5=170eccfc6213f1b86468b3b114267da8},
affiliation={Research School of Computer Science, Australian National University, Canberra, Australia},
abstract={Crowd predictions have demonstrated powerful performance in predicting future events. We aim to understand crowd prediction efficacy in ascertaining the veracity of human emotional expressions. We discover that collective discernment can increase the accuracy of detecting emotion veracity from 63%, which is the average individual performance, to 80%. Constraining data to best-performers can further increase the result up to 92%. Neural networks can achieve an accuracy of 99.69% by aggregating participants’ answers. That is, assigning positive and negative weights to high and low human predictors, respectively. Furthermore, neural networks that are trained with one emotion data can also produce high accuracies on discerning the veracity of other emotion types: our crowdsourced transfer of emotion learning is novel. We find that our neural networks do not require a large number of participants, particularly, 30 randomly selected, to achieve high accuracy predictions, better than any individual participant. Our proposed method of assembling peoples’ predictions with neural networks can provide insights for applications such as fake news prevention and lie detection. © Springer Nature Switzerland AG 2018.},
author_keywords={Crowd prediction;  Emotion veracity;  Fake news;  Neural network},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Thangaraj2018117,
author={Thangaraj, M. and Sivakami, M.},
title={Text classification techniques: A literature review},
journal={Interdisciplinary Journal of Information, Knowledge, and Management},
year={2018},
volume={13},
pages={117-135},
doi={10.28945/4066},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049168874&doi=10.28945%2f4066&partnerID=40&md5=67ccd78d6ea22642d40974a59a6d2062},
affiliation={Department of Computer Science, Madurai Kamaraj University, Madurai, Tamilnadu, India},
abstract={Aim/Purpose The aim of this paper is to analyze various text classification techniques employed in practice, their strengths and weaknesses, to provide an improved awareness regarding various knowledge extraction possibilities in the field of data mining. Background Artificial Intelligence is reshaping text classification techniques to better acquire knowledge. However, in spite of the growth and spread of AI in all fields of research, its role with respect to text mining is not well understood yet. Methodology For this study, various articles written between 2010 and 2017 on “text classification techniques in AI”, selected from leading journals of computer science, were analyzed. Each article was completely read. The research problems related to text classification techniques in the field of AI were identified and techniques were grouped according to the algorithms involved. These algorithms were divided based on the learning procedure used. Finally, the findings were plotted as a tree structure for visualizing the relationship between learning procedures and algorithms. Contribution This paper identifies the strengths, limitations, and current research trends in text classification in an advanced field like AI. This knowledge is crucial for data scientists. They could utilize the findings of this study to devise customized data models. It also helps the industry to understand the operational efficiency of text mining techniques. It further contributes to reducing the cost of the projects and supports effective decision making. Findings It has been found more important to study and understand the nature of data before proceeding into mining. The automation of text classification process is required, with the increasing amount of data and need for accuracy. Another interesting research opportunity lies in building intricate text data models with deep learning systems. It has the ability to execute complex Natural Language Processing (NLP) tasks with semantic requirements. Recommendations Frame analysis, deception detection, narrative science where data expresses a for Practitioners story, healthcare applications to diagnose illnesses and conversation analysis are some of the recommendations suggested for practitioners. Recommendation Developing simpler algorithms in terms of coding and implementation, better for Researchers approaches for knowledge distillation, multilingual text refining, domain knowledge integration, subjectivity detection, and contrastive viewpoint summarization are some of the areas that could be explored by researchers. Impact on Society Text classification forms the base of data analytics and acts as the engine behind knowledge discovery. It supports state-of-the-art decision making, for example, predicting an event before it actually occurs, classifying a transaction as ‘Fraudulent’ etc. The results of this study could be used for developing applications dedicated to assisting decision making processes. These informed decisions will help to optimize resources and maximize benefits to the mankind. Future Research In the future, better methods for parameter optimization will be identified by selecting better parameters that reflects effective knowledge discovery. The role of streaming data processing is still rarely explored when it comes to text classification. © 2018 Informing Science Institute. All Rights Reserved.},
author_keywords={Analysis;  Classification;  Machine learning;  Statistical methods},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cagnina2017151,
author={Cagnina, L.C. and Rosso, P.},
title={Detecting Deceptive Opinions: Intra and Cross-Domain Classification Using an Efficient Representation},
journal={International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems},
year={2017},
volume={25},
pages={151-174},
doi={10.1142/S0218488517400165},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038576965&doi=10.1142%2fS0218488517400165&partnerID=40&md5=9c3d304ae75c675e2247ee712d7ac934},
affiliation={CONICET (Argentina), LIDIC, Universidad Nacional de San Luis, Ejército de los Andes 950, San Luis, Argentina; PRHLT Research Center, Universitat Politècnica de València, Camino de Vera s/n, España Valencia, Spain},
abstract={Online opinions play an important role for customers and companies because of the increasing use they do to make purchase and business decisions. A consequence of that is the growing tendency to post fake reviews in order to change purchase decisions and opinions about products and services. Therefore, it is really important to filter out deceptive comments from the retrieved opinions. In this paper we propose the character n-grams in tokens, an efficient and effective variant of the traditional character n-grams model, which we use to obtain a low dimensionality representation of opinions. A Support Vector Machines classifier was used to evaluate our proposal on available corpora with reviews of hotels, doctors and restaurants. In order to study the performance of our model, we make experiments with intra and cross-domain cases. The aim of the latter experiment is to evaluate our approach in a realistic cross-domain scenario where deceptive opinions are available in a domain but not in another one. After comparing our method with state-of-The-Art ones we may conclude that using character n-grams in tokens allows to obtain competitive results with a low dimensionality representation. © 2017 World Scientific Publishing Company.},
author_keywords={Cross-domain evaluation;  deception detection;  intra-domain evaluation;  low dimensionality representation;  opinion spam},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shah2017553,
author={Shah, H. and Warwick, K.},
title={Machine humour: examples from Turing test experiments},
journal={AI and Society},
year={2017},
volume={32},
number={4},
pages={553-561},
doi={10.1007/s00146-016-0669-0},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976299305&doi=10.1007%2fs00146-016-0669-0&partnerID=40&md5=0cb5c506a5826d8a64bdb8cf5cfca51d},
affiliation={Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom},
abstract={In this paper, we look at the possibility of a machine having a sense of humour. In particular, we focus on actual machine utterances in Turing test discourses. In doing so, we do not consider the Turing test in depth and what this might mean for humanity, rather we merely look at cases in conversations when the output from a machine can be considered to be humorous. We link such outpourings with Turing’s “arguments from various disabilities” used against the concept of a machine being able to think, taken from his seminal work of 1950. Finally we consider the role that humour might play in adding to the deception, integral to the Turing test, that a machine in practice appears to be a human. © 2016, Springer-Verlag London.},
author_keywords={Chatbots;  Deception detection;  Machine humour;  Natural language;  Turing’s imitation game},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Eembijamil2017,
author={Eembijamil, N.C. and Ishak, I. and Sidi, F.},
title={Deception detection approach for data veracity in online digital news: Headlines vs contents},
journal={AIP Conference Proceedings},
year={2017},
volume={1891},
doi={10.1063/1.5005369},
art_number={020036},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031299922&doi=10.1063%2f1.5005369&partnerID=40&md5=3f770434ff11c9515bda5bbfce9c6b71},
affiliation={Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, UPM Serdang, Selangor Darul Ehsan, 43400, Malaysia},
abstract={Veracity is a way to find the truthfulness, availability, accountability and authenticity while deception refers to the way of identifying whether verbal expressions or the overall content is truthful or not. Among the issue in data veracity is the use of deception element in digital news content. Many research have been conducted to address the issue of deception especially in news content they proposed machine learning-based approaches to detect deception in news content. In this paper we compare available deception detection model to improve deception detection accuracy for online digital news veracity. We also proposed a framework to improve deception detection accuracy over digital news portal focusing on headlines. Furthermore, this paper also discussed potential directions for future research in deception of online news. © 2017 Author(s).},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mbaziira201723,
author={Mbaziira, A.V. and Jones, J.H.},
title={Hybrid text-based deception models for native and non-native English cybercriminal networks},
journal={ACM International Conference Proceeding Series},
year={2017},
volume={Part F130280},
pages={23-27},
doi={10.1145/3093241.3093280},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030110424&doi=10.1145%2f3093241.3093280&partnerID=40&md5=f8b0e6e55367b2a62d0291664e26be3d},
affiliation={George Mason University, 4400 University Dr., Fairfax, VA, United States},
abstract={Cybercriminals are increasingly using Internet messaging to exploit their victims. We develop and apply a text-based deception detection approach to build hybrid models for detecting cybercrime in the text Internet communications from native and non-native English speaking cybercriminal networks, where our models use both computational linguistics (CL) and psycholinguistic (PL) features. We study four types of deception-based cybercrime: fraud, scam, favorable fake reviews, and unfavorable fake reviews. We build two types of generalized hybrid models for both native and non-native English speaking cybercriminal networks: 2-dataset and 3-dataset hybrid models using Naïve Bayes, Support Vector Machines, and kth Nearest Neighbor algorithms. All 2-dataset models are trained on any two forms of cybercrime in different web genres, which are then used to detect and analyze other types of cybercrime in web genres that were not part of the training set to establish model generalizability. Similarly, the 3-dataset models are trained on any three forms of cybercrime in different web genres, that are also used to detect and analyze cybercrime in a web genre that was not part of the training set. Model performance on the test datasets ranges from 60% to 80% accuracy, with the best performance on detection of unfavorable reviews and fraud, and notable differences emerged between detection in messages from native and non-native English speaking groups. Our work may be applied as provider-or user-based filtering tools to identify cybercriminal actors and block or label undesirable messages before they reach their intended targets. © 2017 Association for Computing Machinery.},
author_keywords={Computational linguistics;  Cybercrime;  Deception;  Machine learning;  Natural language processing;  Psycholinguistics},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Monaro2017,
author={Monaro, M. and Gamberini, L. and Sartori, G.},
title={The detection of faked identity using unexpected questions and mouse dynamics},
journal={PLoS ONE},
year={2017},
volume={12},
number={5},
doi={10.1371/journal.pone.0177851},
art_number={e0177851},
note={cited By 27},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019385469&doi=10.1371%2fjournal.pone.0177851&partnerID=40&md5=4af88cdbc9b663d0263bc10833aca074},
affiliation={PhD Program in Brain, Mind and Computer Science, University of Padova, Padova, Italy; University of Padova, Human Inspired Technology Research Centre, Padova, Italy; University of Padova, Department of General Psychology, Padova, Italy},
abstract={The detection of faked identities is a major problem in security. Current memory-detection techniques cannot be used as they require prior knowledge of the respondent's true identity. Here, we report a novel technique for detecting faked identities based on the use of unexpected questions that may be used to check the respondent identity without any prior autobiographical information. While truth-tellers respond automatically to unexpected questions, liars have to "build" and verify their responses. This lack of automaticity is reflected in the mouse movements used to record the responses as well as in the number of errors. Responses to unexpected questions are compared to responses to expected and control questions (i.e., questions to which a liar also must respond truthfully). Parameters that encode mouse movement were analyzed using machine learning classifiers and the results indicate that the mouse trajectories and errors on unexpected questions efficiently distinguish liars from truth-tellers. Furthermore, we showed that liars may be identified also when they are responding truthfully. Unexpected questions combined with the analysis of mouse movement may efficiently spot participants with faked identities without the need for any prior information on the examinee. © 2017 Monaro et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Warwick2017287,
author={Warwick, K. and Shah, H.},
title={Taking the fifth amendment in Turing’s imitation game},
journal={Journal of Experimental and Theoretical Artificial Intelligence},
year={2017},
volume={29},
number={2},
pages={287-297},
doi={10.1080/0952813X.2015.1132273},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953214255&doi=10.1080%2f0952813X.2015.1132273&partnerID=40&md5=6d3f00a8e80dda179eae3e538086fe48},
affiliation={Vice Chancellors Office, Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom; Faculty of Engineering, Environment and Computing, Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom},
abstract={In this paper, we look at a specific issue with practical Turing tests, namely the right of the machine to remain silent during interrogation. In particular, we consider the possibility of a machine passing the Turing test simply by not saying anything. We include a number of transcripts from practical Turing tests in which silence has actually occurred on the part of a hidden entity. Each of the transcripts considered here resulted in a judge being unable to make the ‘right identification’, i.e., they could not say for certain which hidden entity was the machine. © 2016 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={chatbots;  Deception detection;  machine misidentification;  natural language;  Turing’s imitation game},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mendels20171472,
author={Mendels, G. and Levitan, S.I. and Lee, K.-Z. and Hirschberg, J.},
title={Hybrid acoustic-lexical deep learning approach for deception detection},
journal={Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
year={2017},
volume={2017-August},
pages={1472-1476},
doi={10.21437/Interspeech.2017-1723},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039159558&doi=10.21437%2fInterspeech.2017-1723&partnerID=40&md5=0fc5945e0d302be11b80dcdf00eb2f13},
affiliation={1Columbia University, United States},
abstract={Automatic deception detection is an important problem with far-reaching implications for many disciplines. We present a series of experiments aimed at automatically detecting deception from speech. We use the Columbia X-Cultural Deception (CXD) Corpus, a large-scale corpus of within-subject deceptive and non-deceptive speech, for training and evaluating our models. We compare the use of spectral, acoustic-prosodic, and lexical feature sets, using different machine learning models. Finally, we design a single hybrid deep model with both acoustic and lexical features trained jointly that achieves state-of-The-Art results on the CXD corpus. Copyright © 2017 ISCA.},
author_keywords={Computational paralinguistics;  deception;  Deep learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Litvinova201743,
author={Litvinova, O. and Litvinova, T. and Seredin, P. and Lyell, J.},
title={Deception detection in Russian texts},
journal={15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017 - Proceedings of the Student Research Workshop},
year={2017},
pages={43-52},
doi={10.18653/v1/e17-4005},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021661811&doi=10.18653%2fv1%2fe17-4005&partnerID=40&md5=1b2da862f356f1ff09c9ccc8bb2a1f12},
affiliation={Voronezh State Pedagogical University, Lenina St, 86, Voronez, Voronezhskaya oblast, 394024, Russian Federation; Voronezh State University, Universitetskaya pl., 1, Voronez, Voronezhskaya oblast, 394036, Russian Federation; Higher School of Economics, Myasnitskaya ul., 20, Moskva, 101000, Russian Federation},
abstract={Psychology studies show that people detect deception no more accurately than by chance, and it is therefore important to develop tools to enable the detection of deception. The problem of deception detection has been studied for a significant amount of time, however in the last 10- 15 years we have seen methods of computational linguistics being employed with greater frequency. Texts are processed using different NLP tools and then classified as deceptive/truthful using modern machine learning methods. While most of this research has been performed for the English language, Slavic languages have never been the focus of detection deception studies. This paper deals with deception detection in Russian narratives related to the theme "How I Spent Yesterday". It employs a specially designed corpus of truthful and deceptive texts on the same topic from each respondent, such that N = 113. The texts were processed using Linguistic Inquiry and Word Count software that is used in most studies of text-based deception detection. The average amount of parameters, a majority of which were related to Part-of-Speech, lexical-semantic group, and other frequencies. Using standard statistical analysis, statistically significant differences between false and truthful Russian texts was uncovered. On the basis of the chosen parameters our classifier reached an accuracy of 68.3%. The accuracy of the model was found to depend on the author's gender. © 2017 Association for Computational Linguistics.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Volkova2017290,
author={Volkova, S. and Bell, E.},
title={Identifying effective signals to predict deleted and suspended accounts on Twitter across languages},
journal={Proceedings of the 11th International Conference on Web and Social Media, ICWSM 2017},
year={2017},
pages={290-298},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029456433&partnerID=40&md5=5defaee305306ab5bfc14570546fd855},
affiliation={Data Sciences and Analytics, National Security Direct., Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, WA  99354, United States},
abstract={Social networks have an ephemerality to them where accounts and messages are constantly being edited, deleted, or marked as private. This continuous change comes from concerns around privacy, a potential desire for to be forgotten and suspicious behavior. In this study we present a novel task - predicting suspicious e.g., to be deleted or suspended accounts in social media. We analyze multiple datasets of thousands of active, deleted and suspended Twitter accounts to produce a series of predictive representations for the removal or shutdown of an account. We selected these accounts from speakers of three languages - Russian, Spanish, and English to evaluate if speakers of various languages behave differently with regards to deleting accounts. We compared the predictive power of the state-of-the-art machine learning models to recurrent neutral networks trained on previously unexplored features. Furthermore, this work is the first to rely on image and affect signals in addition to language and network to predict deleted and suspended accounts in social media. We found that unlike widely used profile and network features, the discourse of deleted or suspended versus active accounts forms the basis for highly accurate account deletion and suspension prediction. More precisely, we observed that the presence of certain terms in tweets leads to a higher likelihood for that user's account deletion or suspension. Moreover, despite image and affect signals yield lower predictive performance compared to language, they reveal interesting behavioral differences across speakers of different languages. Our extensive analysis and novel findings on language use and suspicious behavior of speakers of different languages can improve the existing approaches to credibility analysis, disinformation and deception detection in social media. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bandyopadhyay2017111,
author={Bandyopadhyay, A. and Hazra, A.},
title={A comparative study of classifier performance on spatial and temporal features of handwritten behavioural data},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10127 LNCS},
pages={111-121},
doi={10.1007/978-3-319-52503-7_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011422052&doi=10.1007%2f978-3-319-52503-7_9&partnerID=40&md5=9d77a71460bc502100fcd046110fa705},
affiliation={Centre for Development of Advanced Computing-Kolkata, Plot-E2/1, Block-GP, Sector-V, Salt Lake City, Kolkata, West Bengal  700091, India},
abstract={The issue of comparing classification algorithms on a data set to find optimal classifier has always been a demanding issue in Machine Learning studies. The goal of this work was to compare the performance of different classifiers tested on spatio-temporal features used to distinguish between true and distorted handwriting behaviour to detect deception using machine learning experiments. Dynamic handwriting features depict a writer’s individuality and neuro-psychic condition. Handwritten features share inter-class characteristics while a few of them are very unique to an individual writer. However, extraction of discriminating features & selecting them in decision making process with respect to an individual is really crucial and complex thing, which helps the construction of any classifier, aiming to build the decision support system. Spatio-temporal attributes carry significant discriminatory information in deception detection. In this work, a set of total twelve features (spatial and temporal with pressure measures) features were used from online handwritten data. Five different classifiers (Naïve Bayes, Logistic Regression, Multi-Layer Perceptron, Random Forest and Support Vector Machine) were tested on these feature set with three separate factual descriptions: Person, Action & Event, in both true and distorted mode to develop a decision support system based on the outcome of the experiment on handwriting behaviour. Both Support Vector Machine and Logistic Regression technique have shown good performance in distinguishing between true and distorted handwritten contents. © Springer International Publishing AG 2017.},
author_keywords={Classifier;  Handwriting behaviour;  Machine learning;  Spatio-temporal feature},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hancock2017388,
author={Hancock, W. and Floyd, M.W. and Molineaux, M. and Aha, D.W.},
title={Towards deception detection in a language-driven game},
journal={FLAIRS 2017 - Proceedings of the 30th International Florida Artificial Intelligence Research Society Conference},
year={2017},
pages={388-393},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029517043&partnerID=40&md5=6899f8e0fd2f6ce4b49ea5aeb833102a},
affiliation={School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, United States; Knexus Research Corporation, Springfield, VA, United States; Navy Center for Applied Research in AI, Naval Research Laboratory (Code 5514), Washington, DC, United States},
abstract={There are many real-world scenarios where agents must reliably detect deceit to make decisions. When deceitful statements are made, other statements or actions may make it possible to uncover the deceit. We describe a goal reasoning agent architecture that supports deceit detection by hypothesizing about an agent's actions, uses new observations to revise past beliefs, and recognizes the plans and goals of other agents. In this paper, we focus on one module of our architecture, the Explanation Generator, and describe how it can generate hypotheses for a most probable truth scenario despite the presence of false information. We demonstrate its use in a multiplayer tabletop social deception game, One Night Ultimate Werewolf. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang2016218,
author={Wang, S.-J. and Yan, W.-J. and Sun, T. and Zhao, G. and Fu, X.},
title={Sparse tensor canonical correlation analysis for micro-expression recognition},
journal={Neurocomputing},
year={2016},
volume={214},
pages={218-232},
doi={10.1016/j.neucom.2016.05.083},
note={cited By 24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992525127&doi=10.1016%2fj.neucom.2016.05.083&partnerID=40&md5=804edeb17dafe785a4cb83db9884e7db},
affiliation={Key Laboratory of Behavior Sciences, Institute of Psychology, Chinese Academy of Sciences, Beijing, 100101, China; College of Teacher Education, Wenzhou University, Wenzhou, 325035, China; Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Center for Machine Vision Research, Department of Computer Science and Engineering, University of Oulu, P.O. Box 4500FI-90014, Finland; State Key Laboratory of Brain and Cognitive Science, Institute of Psychology, Chinese Academy of Sciences, Beijing, 100101, China},
abstract={A micro-expression is considered a fast facial movement that indicates genuine emotions and thus provides a cue for deception detection. Due to its promising applications in various fields, psychologists and computer scientists, particularly those focus on computer vision and pattern recognition, have shown interest and conducted research on this topic. However, micro-expression recognition accuracy is still low. To improve the accuracy of such recognition, in this study, micro-expression data and their corresponding Local Binary Pattern (LBP) (Ojala et al., 2002) [1] code data are fused by correlation analysis. Here, we propose Sparse Tensor Canonical Correlation Analysis (STCCA) for micro-expression characteristics. A sparse solution is obtained by the regularized low rank matrix approximation. Experiments are conducted on two micro-expression databases, CASME and CASME 2, and the results show that STCCA performs better than the Three-dimensional Canonical Correlation Analysis (3D-CCA) without sparse resolution. The experimental results also show that STCCA performs better than three-order Discriminant Tensor Subspace Analysis (DTSA3) with discriminant information, smaller projected dimensions and a larger training set sample size. The experiments also showed that Multi-linear Principal Component Analysis (MPCA) is not suitable for micro-expression recognition because the eigenvectors corresponding to smaller eigenvectors are discarded, and those eigenvectors include brief and subtle motion information. © 2016 Elsevier B.V.},
author_keywords={Correlation analysis;  Micro-expression recognition;  Sparse representation;  Tensor subspace},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Mayya2016699,
author={Mayya, V. and Pai, R.M. and Pai, M.M.M.},
title={Combining temporal interpolation and DCNN for faster recognition of micro-expressions in video sequences},
journal={2016 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2016},
year={2016},
pages={699-703},
doi={10.1109/ICACCI.2016.7732128},
art_number={7732128},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007359830&doi=10.1109%2fICACCI.2016.7732128&partnerID=40&md5=aa2536f715f598515779cef66d62459a},
affiliation={Department of Information and Communication Technology, Manipal Institute of Technology, Manipal University, Manipal, 576104, India},
abstract={Micro-expressions are the hidden human emotions that are short lived and are very hard to detect them in real time conversations. Micro-expressions recognition has proven to be an important behavior source for lie detection during crime interrogation. SMIC and CASME II are the two widely used, spontaneous micro-expressions datasets which are available publicly with baseline results that uses LBP-TOP for feature extraction. Estimation of correct parameters is the key factor for feature extraction using LBP-TOP, which results in long computation time. In this paper, the video sequences are interpolated using temporal interpolation(TIM) and then the facial features are extracted using deep convolutional neural network(DCNN) on CUDA enabled General Purpose Graphics Processing Unit(GPGPU) system. Results show that the proposed combination of DCNN and TIM can achieve better performance than the results published in baseline publications. The feature extraction time is reduced due to the usage of GPU enabled systems. © 2016 IEEE.},
author_keywords={CASME II;  Computer Vision;  Confusion Matrix;  Machine Learning;  Micro-expressions recognition;  SMIC},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Warwick2016989,
author={Warwick, K. and Shah, H.},
title={Can machines think? A report on Turing test experiments at the Royal Society},
journal={Journal of Experimental and Theoretical Artificial Intelligence},
year={2016},
volume={28},
number={6},
pages={989-1007},
doi={10.1080/0952813X.2015.1055826},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933567971&doi=10.1080%2f0952813X.2015.1055826&partnerID=40&md5=dfeff95cf963daf46e537d9683434fe0},
affiliation={Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom},
abstract={In this article we consider transcripts that originated from a practical series of Turing's Imitation Game that was held on 6 and 7 June 2014 at the Royal Society London. In all cases the tests involved a three-participant simultaneous comparison by an interrogator of two hidden entities, one being a human and the other a machine. Each of the transcripts considered here resulted in a human interrogator being fooled such that they could not make the ‘right identification’, that is, they could not say for certain which was the machine and which was the human. The transcripts presented all involve one machine only, namely ‘Eugene Goostman’, the result being that the machine became the first to pass the Turing test, as set out by Alan Turing, on unrestricted conversation. This is the first time that results from the Royal Society tests have been disclosed and discussed in a paper. © 2015 The Author(s). Published by Taylor & Francis.},
author_keywords={chatbots;  deception detection;  machine misidentification;  natural language;  Turing's imitation game},
document_type={Article},
source={Scopus},
}

@BOOK{Ghaziasgar2016112,
author={Ghaziasgar, M. and Bagula, A. and De La Cruz, N. and Connan, J.},
title={Visual data mining: A great opportunity for criminal investigation},
journal={Data Mining Trends and Applications in Criminal Science and Investigations},
year={2016},
pages={112-141},
doi={10.4018/978-1-5225-0463-4.ch005},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012017881&doi=10.4018%2f978-1-5225-0463-4.ch005&partnerID=40&md5=133a63edeec25a9dc964fe6069a76666},
affiliation={University of the Western Cape, South Africa; Rhodes University, South Africa},
abstract={Current generation criminal justice relies mostly on manual procedures and processes which are time-consuming and error-prone. A polygraph test consists of only "yes" or "no" questions and depends several physiological responses in subjects. It's effectiveness and accuracy have been questioned due to the possibility of swaying the examiner by individuals that are capable of controlling their physical reactions in order to defeat the lie detection exercise. The criminal justice of the future is expected to be empowered by the most modern information and communication technologies to provide various participants in the justice system with a rich set of services such as virtual court presence and hearing participation through visual sensor networks. This chapter revisits the issue of deception detection by proposing visual data mining as a non-invasive alternative to deception detection in next generation criminal justice. Image processing and machine learning techniques are used to accurately detect facial micro-expressions which have been shown to be strong indicators of deception. © 2016 by IGI Global. All rights reserved.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Warwick2016409,
author={Warwick, K. and Shah, H.},
title={Passing the Turing Test Does Not Mean the End of Humanity},
journal={Cognitive Computation},
year={2016},
volume={8},
number={3},
pages={409-419},
doi={10.1007/s12559-015-9372-6},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951963784&doi=10.1007%2fs12559-015-9372-6&partnerID=40&md5=e6e763f72cbc566a8b66369c96ef5819},
affiliation={Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom},
abstract={In this paper we look at the phenomenon that is the Turing test. We consider how Turing originally introduced his imitation game and discuss what this means in a practical scenario. Due to its popular appeal we also look into different representations of the test as indicated by numerous reviewers. The main emphasis here, however, is to consider what it actually means for a machine to pass the Turing test and what importance this has, if any. In particular does it mean that, as Turing put it, a machine can “think”. Specifically we consider claims that passing the Turing test means that machines will have achieved human-like intelligence and as a consequence the singularity will be upon us in the blink of an eye. © 2015, The Author(s).},
author_keywords={Chatbots;  Deception detection;  Machine misidentification;  Natural language;  Turing’s imitation game},
document_type={Article},
source={Scopus},
}

@ARTICLE{Warwick2016207,
author={Warwick, K. and Shah, H.},
title={The importance of a human viewpoint on computer natural language capabilities: a Turing test perspective},
journal={AI and Society},
year={2016},
volume={31},
number={2},
pages={207-221},
doi={10.1007/s00146-015-0588-5},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931066295&doi=10.1007%2fs00146-015-0588-5&partnerID=40&md5=bb97fe89d244659c8be699cc6196ad6a},
affiliation={Coventry University, Priory Street, Coventry, CV1 5FB, United Kingdom},
abstract={When judging the capabilities of technology, different humans can have very different perspectives and come to quite diverse conclusions over the same data set. In this paper we consider the capabilities of humans when it comes to judging conversational abilities, as to whether they are conversing with a human or a machine. In particular the issue in question is the importance of human judges interrogating in practical Turing tests. As supportive evidence for this we make use of transcripts which originated from a series of practical Turing’s tests held 6–7 June 2014 at the Royal Society London. Each of the tests involved a 3-participant simultaneous comparison by a judge of two hidden entities, one being a human and the other a machine. Thirty different judges took part in total. Each of the transcripts considered in the paper resulted in a judge being unable to say for certain which was the machine and which was the human. The main point we consider here is the fallibility of humans in deciding whether they are conversing with a machine or a human; hence we are concerned specifically with the decision-making process. © 2015, Springer-Verlag London.},
author_keywords={Chatbots;  Deception detection;  Machine misidentification;  Natural language;  Turing’s imitation game},
document_type={Article},
source={Scopus},
}

@CONFERENCE{VanDerWalt2016416,
author={Van Der Walt, E. and Eloff, J.H.P.},
title={A big data science experiment - Identity deception detection},
journal={Proceedings - 2015 International Conference on Computational Science and Computational Intelligence, CSCI 2015},
year={2016},
pages={416-419},
doi={10.1109/CSCI.2015.169},
art_number={7424127},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964414627&doi=10.1109%2fCSCI.2015.169&partnerID=40&md5=6355f1e32b71d48ccc3d7df7e55f180b},
affiliation={Department of Computer Science, Cyber-security and Big Data Science Research Group, University of Pretoria, South Africa},
abstract={Identity Deception Detection is a problem on social media platforms today. Not only is there challenges towards determining the authenticity of people, but also with analyzing the data that forms part of the communications. These data are of heterogeneous type and include photos, videos and sound. Furthermore, most social media platforms are operating in an uncontrolled environment. Any person can contribute content and take part. Even though age restrictions do exist there are no enforcement of these laws and honesty of the public is expected. This is dangerous for minors specifically as they are either unaware of the dangers or not mature enough to be responsible for their actions online. Online predators are aware of this fact and targeting this group specifically. This paper presents work-in-progress towards developing an intelligent Identity Deception Indicator (IDI). It is envisaged that this work could eventually assists authorities in doing large-scale observation on publicly available social media platforms, such as Twitter. Of particular interest are those personas whose behavior and online content does not fit with the age group they are conversing with. © 2015 IEEE.},
author_keywords={Big Data;  Cyber-security;  Data Science;  Identity deception;  Social media},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Warwick20165,
author={Warwick, K. and Shah, H.},
title={Effects of lying in practical Turing tests},
journal={AI and Society},
year={2016},
volume={31},
number={1},
pages={5-15},
doi={10.1007/s00146-013-0534-3},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955179383&doi=10.1007%2fs00146-013-0534-3&partnerID=40&md5=e3ff888e044ffa1a25c561bbe5668a2b},
affiliation={School of Systems Engineering, University of Reading, Whiteknights, Reading, RG6 6AY, United Kingdom},
abstract={Interpretation of utterances affects an interrogator’s determination of human from machine during live Turing tests. Here, we consider transcripts realised as a result of a series of practical Turing tests that were held on 23 June 2012 at Bletchley Park, England. The focus in this paper is to consider the effects of lying and truth-telling on the human judges by the hidden entities, whether human or a machine. Turing test transcripts provide a glimpse into short text communication, the type that occurs in emails: how does the reader determine truth from the content of a stranger’s textual message? Different types of lying in the conversations are explored, and the judge’s attribution of human or machine is investigated in each test. © 2014, Springer-Verlag London.},
author_keywords={Deception detection;  Hidden human interviewer;  Lying;  Machine;  Truth;  Turing test},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Fan2016268,
author={Fan, C. and Zhao, H. and Chen, X. and Fan, X. and Chen, S.},
title={Distinguishing deception from non-deception in Chinese speech},
journal={Proceedings of 6th International Conference on Intelligent Control and Information Processing, ICICIP 2015},
year={2016},
pages={268-273},
doi={10.1109/ICICIP.2015.7388181},
art_number={7388181},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963815305&doi=10.1109%2fICICIP.2015.7388181&partnerID=40&md5=cae105a1700b4bc53a20b3b13f73a61a},
affiliation={School of Electronics and Information Engineering, Soochow University, Suzhou, 215006, China},
abstract={Deception detection is becoming indispensable to a growing number of applications in law enforcement and other government agencies. Recently, many researchers from both speech signal area and machine learning area have already shown that automatically deception detection from speech is promising. While there are a large amount of research works on English deception detection, few efforts have been put on Chinese which is quite different due to the culture divergence. In order to show the full potential of automatically deception detection, in this paper, we first construct the deceptive and non-deceptive Chinese speech corpus which has not been published so far. And then we propose a novel machine learning-based approach to detect deception in the same gender. Several popular machine learning algorithms are applied. Moreover, a transfer learning-based algorithm is applied for cross-gender deception detection. Experimental results show that our approach performs well on real-world corpus. In intra-gender deception detection, our approach can achieve roughly the same accuracy as the traditional method on English corpus. This means our corpus is reasonable and can be used for deception detection research. In cross-gender deception detection, our approach also outperforms the baseline methods. © 2015 IEEE.},
author_keywords={Chinese deception detection;  corpus construction;  transfer learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bandyopadhyay2016177,
author={Bandyopadhyay, A. and Mukherjee, B. and Hazra, A.},
title={Perception Based Decision Support System for Handwriting Behaviour Analysis},
journal={Procedia Computer Science},
year={2016},
volume={84},
pages={177-185},
doi={10.1016/j.procs.2016.04.084},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994358588&doi=10.1016%2fj.procs.2016.04.084&partnerID=40&md5=2310b3b5f459c4ea7e1f4d2b49100123},
affiliation={Principal Engineer, Centre for Development of Advanced Computing, Salt Lake City, Kolkata, 700 091, India; Project Engineer-I, Centre for Development of Advanced Computing, Salt Lake City, Kolkata, 700 091, India},
abstract={Handwritten text is potentially the most powerful and conventional means of personal authentication in Human Computer Interaction, with applications to be found in document analysis, deception detection, banking and many other areas. Handwriting is a complex perceptual motor task generating linguistic information. Characters reflect shape distinction needed to perceive different phonetic information of words. In this paper, we have tried to emphasize the role of perception and cognition in identifying unique characteristics of handwriting of any person to screen out deceptive and true statements as a computational model in the areas of Pattern Recognition and Human Computer Interaction. The paper reports the prototype development of a decision support system based on handwriting behavior analysis. © 2016 The Authors.},
author_keywords={Deception Detection;  Handwriting Analysis;  Online Handwriting;  Pattern Recognition;  Perception Engineering},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Kawulok2016325,
author={Kawulok, M. and Nalepa, J. and Nurzynska, K. and Smolka, B.},
title={In search of truth: Analysis of smile intensity dynamics to detect deception},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={10022 LNAI},
pages={325-337},
doi={10.1007/978-3-319-47955-2_27},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994131215&doi=10.1007%2f978-3-319-47955-2_27&partnerID=40&md5=131bd3a5ae9e2d981d79ae22d68ed625},
affiliation={Silesian University of Technology, Gliwice, Poland},
abstract={Detection of deceptive facial expressions, including estimating smile genuineness, is an important and challenging research topic that draws increasing attention from the computer vision and pattern recognition community. The state-of-the-art methods require localizing a number of facial landmarks to extract sophisticated facial characteristics. In this paper, we explore how to exploit fast smile intensity detectors to extract temporal features. This allows for real-time discrimination between posed and spontaneous expressions at the early smile onset phase.We report the results of experimental validation, which indicate high competitiveness of our method for the UvA-NEMO benchmark database. © Springer International Publishing AG 2016.},
author_keywords={Affective computing;  Deception detection;  Face analysis;  Facial expressions;  Smile genuineness;  Support vector machines},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Soler-Company2016303,
author={Soler-Company, J. and Wanner, L.},
title={Authorship attribution sing syntactic dependencies},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={288},
pages={303-308},
doi={10.3233/978-1-61499-696-5-303},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988489799&doi=10.3233%2f978-1-61499-696-5-303&partnerID=40&md5=1fee62d8fb3aa29c2d9d6174a3dc082d},
affiliation={NLP Group, Pompeu Fabra University, Spain; Catalan Institute for Research and Advanced Studies (ICREA), Spain},
abstract={Authorship attribution deals with the prediction of the author of a (usually written) discourse. This is of high relevance to a number of applications, including plagiarism detection, authenticity verification and deception detection. So far, most of the state-of-the-art approaches to author attribution rely mainly upon lexical and token (sequence) distribution features. But this means to neglect numerous linguistic studies that clearly indicate the high relevance of syntactic features to the characterization of a personal style of an author.We show in an experiment with 26 authors that indeed the use of syntactic features helps us to achieve a >77% an accuracy. © 2016 The authors and IOS Press. All rights reserved.},
author_keywords={Author Identification;  Author Profiling;  Text Classification},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Azaria2015218,
author={Azaria, A. and Richardson, A. and Kraus, S.},
title={An agent for deception detection in discussion based environments},
journal={CSCW 2015 - Proceedings of the 2015 ACM International Conference on Computer-Supported Cooperative Work and Social Computing},
year={2015},
pages={218-227},
doi={10.1145/2675133.2675137},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968764221&doi=10.1145%2f2675133.2675137&partnerID=40&md5=44cb03807bd7745b28c20a919bb1a200},
affiliation={Dept. of Machine Learning, Carnegie Mellon University, Pittsburgh, PA, United States; Dept. of Industrial Engineering, Lev Academic Center, Israel; Dept. of Computer Science, Bar Ilan University, Israel},
abstract={Extensive use of computerized forums and chat-rooms provides a modern venue for deception. We propose introducing an agent to assist in detecting and incriminating a deceptive participant. We designed a game, where deception in a text based discussion environment occurs. In this game several participants attempt to collectively detect a deceptive member. We compose an automated agent which participates in this game as a regular player. The goal of the agent is to detect the deceptive participant and alert other members, without raising suspicion itself. We use machine learning on the data collected from human players to design this agent. Extensive evaluation of our agent shows that it succeeds in raising the players collective success rate in catching the deceptive player. © 2015 ACM.},
author_keywords={Deception Detection;  Human Agent Interaction;  Machine Learning;  SuspicionEvasion},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chen201563,
author={Chen, J.Q.},
title={Contextual binding and deception detection},
journal={CEUR Workshop Proceedings},
year={2015},
volume={1353},
pages={63-67},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928715276&partnerID=40&md5=53c3593ec9634e94313f8cf051568ec6},
affiliation={National Defense University, United States},
abstract={Deception is frequently used in cyber attacks. Detecting deception is always a challenge, as witnessed in attacks in social media and other online environments. Contexts can help to identify deception. Unfortunately, there is not much literature available in this aspect. This paper explores the unique properties of contextual binding. It examines roles that it plays. It also proposes a novel approach in detecting deception utilizing contextual binding in the cyber domain.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mohanchandra201518,
author={Mohanchandra, K.},
title={Criminal forensic: An application to EEG},
journal={Recent and Emerging Trends in Computer and Computational Sciences, RETCOMP 2015},
year={2015},
pages={18-21},
doi={10.1109/RETCOMP.2015.7090798},
art_number={7090798},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929936087&doi=10.1109%2fRETCOMP.2015.7090798&partnerID=40&md5=ccc9ea9369664362c2cde9de5aa1dc4f},
affiliation={Dept. of Computer Science and Engineering, Medical Imaging Research Centre, Dayananda Sagar College of Engineering, Bangalore, 560078, India},
abstract={In the recent years, especially during the last decade electroencephalography (EEG) based brain computer interface (BCI) have become a prevailing study of neuroscience, machine learning and rehabilitation. A BCI provides an arena for a human brain to communicate with a computer directly without the normal neurophysiologic pathways. The electrical signals of the brain, with their fast responsivity with cognitive processes are most suitable as non-motor control mediation between the human and a computer. This can serve as a communication and control channel for various applications. One of the most intriguing uses of EEG is in forensic investigation, used as a tool in lie detection. Lie detection technology has been applied increasingly to investigate and solve criminal cases. Though the contributions of neurobiological research to forensic technology remain largely hypothetical, the evidences appear promising and further research is both feasible and warranted. The brain based lie detection may veritably give solution to many complicated investigation. This paper explores the evolvement of lie detection technology, their working principles, the latest development, and the prospect of their application in forensic science. © 2015 IEEE.},
author_keywords={Brain computerinterface;  Criminal forensic;  Electroencephalography;  Event relatedpotential;  Lie detection;  Polygraph.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pérez-Rosas20151120,
author={Pérez-Rosas, V. and Mihalcea, R.},
title={Experiments in open domain deception detection},
journal={Conference Proceedings - EMNLP 2015: Conference on Empirical Methods in Natural Language Processing},
year={2015},
pages={1120-1125},
doi={10.18653/v1/d15-1133},
note={cited By 27},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959872376&doi=10.18653%2fv1%2fd15-1133&partnerID=40&md5=d91ef411755cd05dd7ce9d8e1f9210a8},
affiliation={Computer Science and Engineering, University of Michigan, United States},
abstract={The widespread use of deception in online sources has motivated the need for methods to automatically profile and identify deceivers. This work explores deception, gender and age detection in short texts using a machine learning approach. First, we collect a new open domain deception dataset also containing demographic data such as gender and age. Second, we extract feature sets including n-grams, shallow and deep syntactic features, semantic features, and syntactic complexity and readability metrics. Third, we build classifiers that aim to predict deception, gender, and age. Our findings show that while deception detection can be performed in short texts even in the absence of a predetermined domain, gender and age prediction in deceptive texts is a challenging task. We further explore the linguistic differences in deceptive content that relate to deceivers gender and age and find evidence that both age and gender play an important role in people's word choices when fabricating lies. © 2015 Association for Computational Linguistics.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Conroy20151,
author={Conroy, N.J. and Rubin, V.L. and Chen, Y.},
title={Automatic deception detection: Methods for finding fake news},
journal={Proceedings of the Association for Information Science and Technology},
year={2015},
volume={52},
number={1},
pages={1-4},
doi={10.1002/pra2.2015.145052010082},
note={cited By 209},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987722728&doi=10.1002%2fpra2.2015.145052010082&partnerID=40&md5=8c48a5390a854e63f2e380d1c5793223},
affiliation={Language and Information Technology Research Lab (LIT.RL) Faculty of Information and Media Studies, University of Western Ontario, London, ON, Canada},
abstract={This research surveys the current state-of-the-art technologies that are instrumental in the adoption and development of fake news detection. “Fake news detection” is defined as the task of categorizing news along a continuum of veracity, with an associated measure of certainty. Veracity is compromised by the occurrence of intentional deceptions. The nature of online news publication has changed, such that traditional fact checking and vetting from potential deception is impossible against the flood arising from content generators, as well as various formats and genres. The paper provides a typology of several varieties of veracity assessment methods emerging from two major categories – linguistic cue approaches (with machine learning), and network analysis approaches. We see promise in an innovative hybrid approach that combines linguistic cue and machine learning, with network-based behavioral data. Although designing a fake news detector is not a straightforward problem, we propose operational guidelines for a feasible fake news detecting system. Copyright © 2015 by Association for Information Science and Technology},
author_keywords={automation;  Deception detection;  fake news detection;  fraud;  knowledge networks;  methods;  news verification;  predictive modelling;  SVM;  veracity assessment},
document_type={Article},
source={Scopus},
}

@ARTICLE{Meenakshi201512893,
author={Meenakshi, S. and Karpagavalli, S.},
title={Speech emotion recognition using classification algorithms},
journal={International Journal of Applied Engineering Research},
year={2015},
volume={10},
number={5},
pages={12893-12904},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927748469&partnerID=40&md5=f834c9b53f29f689aa08678e06145a5a},
affiliation={PSGR Krishnammal College for Women, Coimbatore, India; Department of Computer Science, PSGR Krishnammal College for Women, Coimbatore, India},
abstract={Emotion Recognition from one’s speech is natural activity in human beings. Emotion recognition aims at identifying the emotional state of a speaker from his/her speech signal. The emotion recognition is useful in applications that are lie detection, in car board system, authentication systems and automatic emotional detection in call centers. There are different categories of emotions such as joy, fear, disgust, surprise, anger, sadness, boredom and neutral. In this proposed work, emotional speech files are collected from Berlin Emotional Speech Database (EMO-DB) covering exclusively 3 emotions Neutral, Anger and Sad. Information on emotion is encoded mainly phonetic and acoustic properties of spoken language. Prosodic features and voice quality also infers emotion characteristics. The emotion speech files are processed to extract features like energy, pitch, intensity and Mel-Frequency Cepstral Coefficient (MFCC). Emotion recognizer is designed with classifiers like Multilayer Perceptron (MLP) and Support Vector Machine (SVM). The experiment carried out for male and female speech files with acoustic features separately and acoustic features along with short term spectral features. The performances of the classifiers are evaluated with predictive accuracy. © Research India Publications.},
author_keywords={Energy;  Intensity;  Machine learning;  MFCC;  Pitch},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pérez-Rosas2014163,
author={Pérez-Rosas, V. and Mihalcea, R.},
title={Gender differences in deceivers writing style},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2014},
volume={8856},
pages={163-174},
doi={10.1007/978-3-319-13647-9_17},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921888544&doi=10.1007%2f978-3-319-13647-9_17&partnerID=40&md5=5abc371ddbc1cc1ebd444f11e168e363},
affiliation={University of North Texas, University of Michigan, United States},
abstract={The widespread use of deception in written content has motivated the need for methods to automatically profile and identify deceivers. Particularly, the identification of deception based on demographic data such as gender, age, and religion, has become of importance due to ethical and security concerns. Previous work on deception detection has studied the role of gender using statistical approaches and domain-specific data. This work explores gender detection in open domain truths and lies using a machine learning approach. First, we collect a deception dataset consisting of truths and lies from male and female participants. Second, we extract a large feature set consisting of n-grams, shallow and deep syntactic features, semantic features derived from a psycholinguistics lexicon, and features derived from readability metrics. Third, we build deception classifiers able to predict participant’s gender with classification accuracies ranging from 60-70%. In addition, we present an analysis of differences in the linguistic style used by deceivers given their reported gender. © Springer International Publishing Switzerland 2014.},
author_keywords={Deception;  Linguistics;  Machine learning},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Azaria20141387,
author={Azaria, A. and Richardson, A. and Kraus, S.},
title={An agent for deception detection in discussion based environments},
journal={13th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2014},
year={2014},
volume={2},
pages={1387-1388},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911394404&partnerID=40&md5=95f71892cfdc323257e26757c03644aa},
affiliation={Dept. of Computer Science, Bar Ilan University, Israel; Dept. of Industrial Engineering, Jerusalem College of Technology, Israel},
abstract={Autonomous agents can be of assistance in detecting and reducing deception in computerized forums and chat-rooms. We focus on text-based environments where the deceiver is a member of a group which is holding a discussion. Deception detection methods which currently exist for such environments, heavily rely on either audio or visual information. We have developed DIG, an innovative machine learning-based autonomous agent, which joins a group of players as a regular member and assists them in catching a deceiver. We introduce "the pirate game" as a platform for deploying this agent. Our experimental study shows that although humans display difficulty detecting deception, DIG is not only capable of finding a deceptive player, it also helps increase the entire group's success. Copyright © 2014, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.},
author_keywords={Deception detection;  Discussions;  Human modeling},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Verhoeven20143081,
author={Verhoeven, B. and Daelemans, W.},
title={CLiPS stylometry investigation (CSI) corpus: A Dutch corpus for the detection of age, gender, personality, sentiment and deception in text},
journal={Proceedings of the 9th International Conference on Language Resources and Evaluation, LREC 2014},
year={2014},
pages={3081-3085},
note={cited By 30},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021843325&partnerID=40&md5=71eccc359fece96ef1b58e2f56c13e4c},
affiliation={CLiPS - Computational Linguistics Group, University of Antwerp, Belgium},
abstract={We present the CLiPS Stylometry Investigation (CSI) corpus, a new Dutch corpus containing reviews and essays written by university students. It is designed to serve multiple purposes: detection of age, gender, authorship, personality, sentiment, deception, topic and genre. Another major advantage is its planned yearly expansion with each year's new students. The corpus currently contains about 305, 000 tokens spread over 749 documents. The average review length is 128 tokens; the average essay length is 1126 tokens. The corpus will be made available on the CLiPS website (www.clips.uantwerpen.be/datasets) and can freely be used for academic research purposes. An initial deception detection experiment was performed on this data. Deception detection is the task of automatically classifying a text as being either truthful or deceptive, in our case by examining the writing style of the author. This task has never been investigated for Dutch before. We performed a supervised machine learning experiment using the SVM algorithm in a 10-fold cross-validation setup. The only features were the token unigrams present in the training data. Using this simple method, we reached a state-of-the-art F-score of 72.2%.},
author_keywords={Computational stylometry;  Deception detection;  Text classification},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Johnson2014339,
author={Johnson, G., Jr. and Santos, E., Jr.},
title={Detecting deception in intelligent systems I: Activation of deception detection tactics},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2014},
volume={3060},
pages={339-354},
doi={10.1007/978-3-540-24840-8_24},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-7444266992&doi=10.1007%2f978-3-540-24840-8_24&partnerID=40&md5=f34161533441f7a2875945bd18cc44d2},
affiliation={University of Connecticut, Booth Engineering Center for Advanced Technology (BECAT), 371 Fairfield Road, Unit 2031, Storrs, CT  06269-2031, United States},
abstract={The continued research, development and acceptance of intelligent systems for diagnosis and decision support has uncovered many practical considerations for the interaction of intelligent, autonomous agents. One such consideration is the possibility of an agent intentionally transmitting misinformation to other agents or to a human decision maker to achieve its own goals. Most intelligent, knowledge-based systems to date have assumed all experts involved in system development operate toward a shared goal and operate in good faith. We wish to challenge these assumptions and consider cases where agents in the system are not assumed to operate in good faith and therefore misinformation is a possibility. Most literature devoted to deception in agent systems focuses on building trust relationships through a history of interaction. We apply models of deception and deception detection from psychology and cognitive science to intelligent multi-agent systems. We focus on a model for deception detection in which the detection and analysis of deception are decoupled. Finally, we introduce a novel method for the detection of deception in multi-agent systems based on correlations between the agents in the system. © Springer-Verlag Berlin Heidelberg 2004.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Xiong2014357,
author={Xiong, Y. and Luo, Y. and Huang, W. and Zhang, W. and Yang, Y. and Gao, J.},
title={A novel classification method based on ICA and ELM: A case study in lie detection},
journal={Bio-Medical Materials and Engineering},
year={2014},
volume={24},
number={1},
pages={357-363},
doi={10.3233/BME-130818},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891054438&doi=10.3233%2fBME-130818&partnerID=40&md5=45837ec2588332465d7232ccde7cce45},
affiliation={College of Mechanical and Electrical Engineering, Wuhan Donghu University, Wuhan, 430212, China; Key Laboratory of Cognitive Science (South-Central University for Nationalities), State Ethnic Affairs Commission, Wuhan 430074, China; Department of Physics, Zhejiang Ocean University, Zhoushan, Zhejiang, 316004, China; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, China},
abstract={The classification of EEG tasks has drawn much attention in recent years. In this paper, a novel classification model based on independent component analysis (ICA) and Extreme learning machine (ELM) is proposed to detect lying. Firstly, ICA and its topography information were used to automatically identify the P300 ICs. Then, time and frequency-domain features were extracted from the reconstructed P3 waveforms. Finally, two classes of feature samples were used to train ELM, Back-propagation network (BPNN) and support vector machine (SVM) classifiers for comparison. The optimal number of P3 ICs and the values of classifier parameter were optimized by the cross-validation procedures. Experimental results show that the presented method (ICA-ELM) achieves the highest training accuracy of 95.40% with extremely less training and testing time on detecting P3 components for the guilty and the innocent subjects. The results indicate that the proposed method can be applied in lie detection. © 2014 - IOS Press and the authors. All rights reserved.},
author_keywords={classification;  EEG;  ERP;  extreme learning machine;  Independent component analysis},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2014,
title={Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2014},
volume={3060},
page_count={590},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945526472&partnerID=40&md5=0e16dd67edfc53f6005d891e36e930c1},
abstract={The proceedings contain 65 papers. The topics discussed include: a principled modular approach to construct flexible conversation protocols; term-based clustering and summarization of web page collections; the frequency of hedging cues in citation contexts in scientific writing; preliminary study of attention control modeling in complex skill training environments; on customizing evolutionary learning of agent behavior; towards efficient training on large datasets for genetic programming; intrinsic representation: bootstrapping symbols from experience; constraint satisfaction methods for information personalization; the structural model interpretation of the NESS test; detecting deception in intelligent systems i: activation of deception detection tactics; a decision-theoretic graphical model for collaborative design on supply chains; wavelet network with OLS optimization for speech signal processing; and the use of increasingly specific user models in the design of mixed-initiative systems.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Fornaciari20131,
author={Fornaciari, T. and Celli, F. and Poesio, M.},
title={The effect of personality type on deceptive communication style},
journal={Proceedings - 2013 European Intelligence and Security Informatics Conference, EISIC 2013},
year={2013},
pages={1-6},
doi={10.1109/EISIC.2013.8},
art_number={6657118},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892172251&doi=10.1109%2fEISIC.2013.8&partnerID=40&md5=3cf405f99cec165724d372b7a5415756},
affiliation={CIMeC - University of Trento, Corso Bettini 31, Rovereto, Italy; University of Essex, Wivenhoe Park, Colchester CO4 3SQ, United Kingdom},
abstract={It has long been hypothesized that the ability to deceive depends on personality - some personality types are 'better' at deceiving in that their deception is harder to recognize. In this work, we evaluate how the pattern of personality of a speaker affects the effectiveness of machine learning models for deception detection in transcripts of oral speech. We trained models to classify as deceptive or not deceptive statements issued in Court by Italian speakers. We then used a system for automatic personality recognition to generate hypotheses about the personality of these speakers, and we clustered the subjects on the basis of their personality traits. It turned out that deception detection models perform differently depending on the patterns of personality traits which characterize the speakers. This suggests that speakers who show certain types of personality also have a communication style in which deception can be detected more, or less, easily. © 2013 IEEE.},
author_keywords={deception detection;  natural language processing;  personality recognition},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Santosuosso2013197,
author={Santosuosso, A.},
title={Neuroscience and converging technologies in Italy: From free will approach to humans as not disconnected entities},
journal={International Neurolaw: A Comparative Analysis},
year={2013},
pages={197-213},
doi={10.1007/978-3-642-21541-4_11},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929572849&doi=10.1007%2f978-3-642-21541-4_11&partnerID=40&md5=ccb8005d2d30f3b0fef65aa5af8a603a},
affiliation={European Center for Law, Science and New Technologies, University of Pavia, Corso Strada Nuova, Pavia, 27100, Italy},
abstract={In recent years, a vast literature has developed on how neuroimaging may increase our understanding of deception, moral and legal responsibility, behaviour prediction, and much more. Common approaches overlook the global reality of neuroscience and neurotechniques. This is the reason why (beyond controversial implications of neuroimaging techniques: i.e. lie detection, determination of mental impairment, or psychopathy) it is important to survey some technological applications of neuroscience on the human body (even beyond the field of criminal law), such as objective measurement of chronic pain, robots and artificial intelligence, brain-computer interfaces. The review focuses on Italian case law on the concept of moral damage and the opportunities that neurotechniques offer in order to have a more objective evaluation. In addition, it is considered the responsibility for robot's actions (especially referring to learning robots) and the possible application of current Italian civil legislation (especially the responsibility of teachers). Conclusive remarks are on the law and the way basic concepts as human individual are affected by neuroscience. © Springer-Verlag Berlin Heidelberg 2012. All rights are reserved.},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Derrick2013,
author={Derrick, D.C. and Meservy, T.O. and Jenkins, J.L. and Burgoon, J.K. and Nunamaker Jr., J.F.},
title={Detecting deceptive chat-based communication using typing behavior and message cues},
journal={ACM Transactions on Management Information Systems},
year={2013},
volume={4},
number={2},
doi={10.1145/2499962.2499967},
art_number={9},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885595173&doi=10.1145%2f2499962.2499967&partnerID=40&md5=98ae00b74d2c73bb7cdd023c290a9601},
affiliation={University of Nebraska at Omaha, PKI 280C, 1110 S. 67th Street, Omaha, NE 68182-0116, United States; Brigham Young University, United States; University of Arizona, United States},
abstract={Computer-mediated deception is prevalent and may have serious consequences for individuals, organizations, and society. This article investigates several metrics as predictors of deception in synchronous chatbased environments, where participants must often spontaneously formulate deceptive responses. Based on cognitive load theory, we hypothesize that deception influences response time, word count, lexical diversity, and the number of times a chat message is edited. Using a custom chatbot to conduct interviews in an experiment, we collected 1,572 deceitful and 1,590 truthful chat-based responses. The results of the experiment confirm that deception is positively correlated with response time and the number of edits and negatively correlated to word count. Contrary to our prediction, we found that deception is not significantly correlated with lexical diversity. Furthermore, the age of the participant moderates the influence of deception on response time. Our results have implications for understanding deceit in chat-based communication and building deception-detection decision aids in chat-based systems. © 2013 ACM.},
author_keywords={Chat;  Deception detection;  Decision support system;  Typing bahavior},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Zage2013254,
author={Zage, D. and Glass, K. and Colbaugh, R.},
title={Improving supply chain security using big data},
journal={IEEE ISI 2013 - 2013 IEEE International Conference on Intelligence and Security Informatics: Big Data, Emergent Threats, and Decision-Making in Security Informatics},
year={2013},
pages={254-259},
doi={10.1109/ISI.2013.6578830},
art_number={6578830},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883399598&doi=10.1109%2fISI.2013.6578830&partnerID=40&md5=abe55921b6a28767bd6870f7d28c8c5b},
affiliation={Sandia National Laboratories, Albuquerque, NM 87185-9300, United States},
abstract={Previous attempts at supply chain risk management are often non-technical and rely heavily on policies/procedures to provide security assurances. This is particularity worrisome as there are vast volumes of data that must be analyzed and data continues to grow at unprecedented rates. In order to mitigate these issues and minimize the amount of manual inspection required, we propose the development of mathematically-based automated screening methods that can be incorporated into supply chain risk management. In particular, we look at methods for identifying deception and deceptive practices that may be present in the supply chain. We examine two classes of constraints faced by deceivers, cognitive/computational limitations and strategic tradeoffs, which can be used to developed graph-based metrics to represent entity behavior. By using these metrics with novel machine learning algorithms, we can robustly detect deceptive behavior and identify potential supply chain issues. © 2013 IEEE.},
author_keywords={Deception Detection;  Machine Learning;  Supply Chain Risk Management},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Fornaciari2013303,
author={Fornaciari, T. and Poesio, M.},
title={Automatic deception detection in Italian court cases},
journal={Artificial Intelligence and Law},
year={2013},
volume={21},
number={3},
pages={303-340},
doi={10.1007/s10506-013-9140-4},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883247308&doi=10.1007%2fs10506-013-9140-4&partnerID=40&md5=e2fe2c9a5657f11f0f1edb300c8e30e9},
affiliation={Center for Mind/Brain Sciences, University of Trento, Trento, Italy; School for Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom},
abstract={Effective methods for evaluating the reliability of statements issued by witnesses and defendants in hearings would be an extremely valuable support to decision-making in court and other legal settings. In recent years, methods relying on stylometric techniques have proven most successful for this task; but few such methods have been tested with language collected in real-life situations of high-stakes deception, and therefore their usefulness outside lab conditions still has to be properly assessed. In this study we report the results obtained by using stylometric techniques to identify deceptive statements in a corpus of hearings collected in Italian courts. The defendants at these hearings were condemned for calumny or false testimony, so the falsity of (some of) their statements is fairly certain. In our experiments we replicated the methods used in previous studies but never before applied to high-stakes data, and tested new methods. We also considered the effect of a number of variables including in particular the homogeneity of the dataset. Our results suggest that accuracy at deception detection clearly above chance level can be obtained with real-life data as well. © 2013 Springer Science+Business Media Dordrecht.},
author_keywords={Criminal proceedings;  Deception detection;  Stylometry},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gao2013,
author={Gao, J. and Wang, Z. and Yang, Y. and Zhang, W. and Tao, C. and Guan, J. and Rao, N.},
title={A Novel Approach for Lie Detection Based on F-Score and Extreme Learning Machine},
journal={PLoS ONE},
year={2013},
volume={8},
number={6},
doi={10.1371/journal.pone.0064704},
art_number={e64704},
note={cited By 43},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878633736&doi=10.1371%2fjournal.pone.0064704&partnerID=40&md5=9b95640ea441a59ba83eede0d6e3371d},
affiliation={College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, China; Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, China; School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, China},
abstract={A new machine learning method referred to as F-score_ELM was proposed to classify the lying and truth-telling using the electroencephalogram (EEG) signals from 28 guilty and innocent subjects. Thirty-one features were extracted from the probe responses from these subjects. Then, a recently-developed classifier called extreme learning machine (ELM) was combined with F-score, a simple but effective feature selection method, to jointly optimize the number of the hidden nodes of ELM and the feature subset by a grid-searching training procedure. The method was compared to two classification models combining principal component analysis with back-propagation network and support vector machine classifiers. We thoroughly assessed the performance of these classification models including the training and testing time, sensitivity and specificity from the training and testing sets, as well as network size. The experimental results showed that the number of the hidden nodes can be effectively optimized by the proposed method. Also, F-score_ELM obtained the best classification accuracy and required the shortest training and testing time. © 2013 Gao et al.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Elkins2013249,
author={Elkins, A.C. and Dunbar, N.E. and Adame, B. and Nunamaker Jr., J.F.},
title={Are users threatened by credibility assessment systems?},
journal={Journal of Management Information Systems},
year={2013},
volume={29},
number={4},
pages={249-262},
doi={10.2753/MIS0742-1222290409},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880218457&doi=10.2753%2fMIS0742-1222290409&partnerID=40&md5=fb7216575bbbcb71c188b26a4e1ecf04},
affiliation={MIS Department, University of Arizona, United States; Center for Applied Social Research, University of Oklahoma, United States; Center for the Management of Information, National Center for Border Security, University of Arizona, United States},
abstract={Despite the improving accuracy of agent-based expert systems, human expert users aided by these systems have not improved their accuracy. Self-affirmation theory suggests that human expert users could be experiencing threat, causing them to act defensively and ignore the system's conflicting recommendations. Previous research has demonstrated that affirming an individual in an unrelated area reduces defensiveness and increases objectivity to conflicting information. Using an affirmation manipulation prior to a credibility assessment task, this study investigated if experts are threatened by counterattitudinal expert system recommendations. For our study, 178 credibility assessment experts from the American Polygraph Association (n = 134) and the European Union's border security agency Frontex (n = 44) interacted with a deception detection expert system to make a deception judgment that was immediately contradicted. Reducing the threat prior to making their judgments did not improve accuracy, but did improve objectivity toward the system. This study demonstrates that human experts are threatened by advanced expert systems that contradict their expertise. As more and more systems increase integration of artificial intelligence and inadvertently assail the expertise and abilities of users, threat and self-evaluative concerns will become an impediment to technology acceptance. © 2013 M.E. Sharpe, Inc. All rights reserved.},
author_keywords={credibility assessment systems;  deception detection;  expert systems;  user anxiety},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Xtong2012,
author={Xtong, Y. and Yang, Y. and Gao, J.},
title={A novel lie detection method based on extreme learning machine using P300},
journal={IET Conference Publications},
year={2012},
volume={2012},
number={636 CP},
doi={10.1049/cp.2012.2471},
art_number={2471},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894592637&doi=10.1049%2fcp.2012.2471&partnerID=40&md5=dce7763c6d3ff1190af054633d8be519},
affiliation={College of Mechanical and Electiical Engineering, Wuhan Donglut University, Wuhan, 430212, China; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, China; College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, 430074, China},
abstract={Machine learning-based lie detection has drawn much attention recently. In this paper, we used extreme learning machine (ELM), a recently-proposed machine learning method based on a single layer feedforward network (SLFN), to classify P300 potentials from guilty subject and non-P300 potentials from innocent subject. Back-propagation network and support vector machine classifiers were also used to compare with the proposed method. The number of hidden nodes in ELM was timed using training with the 10-fold cross validation. The experimental results show that the proposed method reaches the highest classification accuracy with extremely less training and testing tune, compared with the other classification models.},
author_keywords={Extreme learning machine;  Lie detection;  P300;  Probe stimuli},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Rubin2012,
author={Rubin, V.L. and Conroy, N.J.},
title={The art of creating an informative data collection for automated deception detection a corpus of truths and lies},
journal={Proceedings of the ASIST Annual Meeting},
year={2012},
volume={49},
number={1},
doi={10.1002/meet.14504901045},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878589849&doi=10.1002%2fmeet.14504901045&partnerID=40&md5=ed588e04d68b5d5df5ec7657c821d8b3},
affiliation={Language and Information Technology Research Lab (LIT.RL), Faculty of Information and Media Studies, University of Western Ontario, London, ON, N6A 5B7, Canada},
abstract={One of the novel research directions in Natural Language Processing and Machine Learning involves creating and developing methods for automatic discernment of deceptive messages from truthful ones. Mistaking intentionally deceptive pieces of information for authentic ones (true to the writer's beliefs) can create negative consequences, since our everyday decision-making, actions, and mood are often impacted by information we encounter. Such research is vital today as it aims to develop tools for the automated recognition of deceptive, disingenuous or fake information (the kind intended to create false beliefs or conclusions in the reader's mind). The ultimate goal is to support truthfulness ratings that signal the trustworthiness of the retrieved information, or alert information seekers to potential deception. To proceed with this agenda, we require elicitation techniques for obtaining samples of both deceptive and truthful messages from study participants in various subject areas. A data collection, or a corpus of truths and lies, should meet certain basic criteria to allow for meaningful analysis and comparison of socio-linguistic behaviors. In this paper we propose solutions and weigh pros and cons of various experimental set-ups in the art of corpus building. The outcomes of three experiments demonstrate certain limitations with using online crowdsourcing for data collection of this type. Incorporating motivation in the task descriptions, and the role of visual context in creating deceptive narratives are other factors that should be addressed in future efforts to build a quality dataset. Copyright © 2010 Victoria L. Rubin and Niall J. Conroy.},
author_keywords={Corpus construction;  Deception detection;  Elicitations;  Natural language processing},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shojaeilangari20123238,
author={Shojaeilangari, S. and Moradi, M.H.},
title={A new unsupervised pre-processing algorithm based on artificial immune system for ERP assessment in a P300-based GKT},
journal={Research Journal of Applied Sciences, Engineering and Technology},
year={2012},
volume={4},
number={18},
pages={3238-3245},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866790263&partnerID=40&md5=7044a74602abbec1bd1dc7856f5bdb7a},
affiliation={Electrical and Electronic Engineering Department, Nanyang Technological University, Singapore, Singapore; Biomedical Engineering Faculty, Amirkabir University of Technology, Tehran, Iran},
abstract={In recent years, an increasing number of researches have been focused on bio-inspired algorithms to solve the elaborate engineering problems. Artificial Immune System (AIS) is an artificial intelligence technique which has potential of solving problems in various fields. The immune system, due to self-regulating nature, has been an inspiration source of unsupervised learning methods for pattern recognition task. The purpose of this study is to apply the AIS to pre-process the lie-detection dataset to promote the recognition of guilty and innocent subjects. A new Unsupervised AIS (UAIS) was proposed in this study as a pre-processing method before classification. Then, we applied three different classifiers on pre-processed data for Event Related Potential (ERP) assessment in a P300-based Guilty Knowledge Test (GKT). Experiment results showed that UAIS is a successful pre-processing method which is able to improve the classification rate. In our experiments, we observed that the classification accuracies for three different classifiers: K-Nearest Neighbourhood (KNN), Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) were increased after applying UAIS pre-processing. Using of scattering criterion to assessment the features before and after pre-processing proved that our proposed method was able to perform data mapping from a primary feature space to a new area where the data separability was improved significantly. © Maxwell Scientific Organization, 2012.},
author_keywords={Artificial immune system;  Guilty knowledge test;  Lie-detection;  Pre-processing;  Unsupervised learning},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shojaeilangari20122995,
author={Shojaeilangari, S. and Moradi, M.H.},
title={Combination of designed immune based classifiers for ERP assessment in a P300-based GKT},
journal={Research Journal of Applied Sciences, Engineering and Technology},
year={2012},
volume={4},
number={17},
pages={2995-3004},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866765791&partnerID=40&md5=03e6d2adb57210b399256ff0c6ecdd9a},
affiliation={Electrical and Electronic Engineering Department, Nanyang Technological University, Singapore, Singapore; Biomedical Engineering Faculty, Amirkabir University of Technology, Tehran, Iran},
abstract={Constructing a precise classifier is an important issue in pattern recognition task. Combination the decision of several competing classifiers to achieve improved classification accuracy has become interested in many research areas. In this study, Artificial Immune System (AIS) as an effective artificial intelligence technique was used for designing of several efficient classifiers. Combination of multiple immune based classifiers was tested on ERP assessment in a P300-based Guilty Knowledge Test (GKT). Our experimental results showed that the proposed classifier named Compact Artificial Immune System (CAIS) is a successful classification method and can be competitive to other classifiers such as K-Nearest Neighbourhood (KNN), Linear Discriminant Analysis (LDA) and Support Vector Machine (SVM). Also, in the experiments, it was observed that using the decision fusion techniques for multiple classifier combination lead to better recognition results. The best rate of recognition by CAIS was 80.90% that has been improved in compare to other applied classification methods in our study. © Maxwell Scientific Organization, 2012.},
author_keywords={Artificial immune system;  ERP;  Guilty knowledge test;  Lie-detection;  P300},
document_type={Article},
source={Scopus},
}

@CONFERENCE{McCarthy2012188,
author={McCarthy, P.M. and Duran, N.D. and Booker, L.M.},
title={The devil is in the details: New directions in deception analysis},
journal={Proceedings of the 25th International Florida Artificial Intelligence Research Society Conference, FLAIRS-25},
year={2012},
pages={188-195},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865025073&partnerID=40&md5=95b59ecb0c48cbd4643421e88c3a7367},
affiliation={Department of English (Applied Linguistics), University of Memphis, Memphis, TN, United States; Cognitive and Information Sciences, University of California Merced, Merced, CA, United States},
abstract={In this study, we use the computational textual analysis tool, the Gramulator, to identify and examine the distinctive linguistic features of deceptive and truthful discourse. The theme of the study is abortion rights and the deceptive texts are derived from a Devil's Advocate approach, conducted to suppress personal beliefs and values. Our study takes the form of a contrastive corpus analysis, and produces systematic differences between truthful and deceptive personal accounts. Results suggest that deceivers employ a distancing strategy that is often associated with deceptive linguistic behavior. Ultimately, these deceivers struggle to adopt a truth perspective. Perhaps of most importance, our results indicate issues of concern with current deception detection theory and methodology. From a theoretical standpoint, our results question whether deceivers are deceiving at all or whether they are merely poorly expressing a rhetorical position, caused by being forced to speculate on a perceived proto-typical position. From a methodological standpoint, our results cause us to question the validity of deception corpora. Consequently, we propose new rigorous standards so as to better understand the subject matter of the deception field. Finally, we question the prevailing approach of abstract data measurement and call for future assessment to consider contextual lexical features. We conclude by suggesting a prudent approach to future research for fear that our eagerness to analyze and theorize may cause us to misidentify deception. After-all, successful deception, which is the kind we seek to detect, is likely to be an elusive and fickle prey. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Pearl2012183,
author={Pearl, L. and Steyvers, M.},
title={Detecting authorship deception: A supervised machine learning approach using author writeprints},
journal={Literary and Linguistic Computing},
year={2012},
volume={27},
number={2},
pages={183-196},
doi={10.1093/llc/fqs003},
art_number={fqs003},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861555432&doi=10.1093%2fllc%2ffqs003&partnerID=40&md5=ee3087faf4b5b4cca391f764d347878d},
affiliation={University of California, Irvine, CA, United States; Social and Behavioral Sciences, University of California, Gateway Building, Irvine, CA 92697-5100, United States},
abstract={We describe a new supervised machine learning approach for detecting authorship deception, a specific type of authorship attribution task particularly relevant for cybercrime forensic investigations, and demonstrate its validity on two case studies drawn from realistic online data sets. The core of our approach involves identifying uncharacteristic behavior for an author, based on a writeprint extracted from unstructured text samples of the author's writing. The writeprints used here involve stylometric features and content features derived from topic models, an unsupervised approach for identifying relevant keywords that relate to the content areas of a document. One innovation of our approach is to transform the writeprint feature values into a representation that individually balances characteristic and uncharacteristic traits of an author, and we subsequently apply a Sparse Multinomial Logistic Regression classifier to this novel representation. Our method yields high accuracy for authorship deception detection on the two case studies, confirming its utility. © The Author 2012. Published by Oxford University Press on behalf of ALLC. All rights reserved.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ellen2012222,
author={Ellen, J. and Kaina, J. and Parameswaran, S.},
title={Implicit group membership detection in online text: analysis and applications},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2012},
volume={7227 LNCS},
pages={222-230},
doi={10.1007/978-3-642-29047-3_27},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859136000&doi=10.1007%2f978-3-642-29047-3_27&partnerID=40&md5=0900f60567a34e684ea660a8f1150adb},
affiliation={Space and Naval Warfare Systems Center Pacific, United States Navy, San Diego, CA, United States},
abstract={Our thesis is that members of the same group have shared tendencies and nuances in communication style and substance, particularly online. In this paper, we dicuss some potential applications of accuarate authorship affiliation technology. We also discuss related work in similar author identification efforts and the research issues that currently exist when trying to perform automated authorship affiliation. We provide quantitative results from our recent Machine Learning experimenation using Support Vector Machines as some initial validation of our theory. In this paper, we applied our work towards the task of classifying website forum posts by the affiliation of their author. We discuss in detail the stylometric features we used to perform the automated classification and split the original features into individual groups to isolate their respective contributions and/or discriminating capability. Our results show promise towards automating group representation, an important first step in studying group formation. © 2012 Springer-Verlag.},
author_keywords={Authorship affiliation;  Deception detection;  Group detection;  Group Membership;  Machine Learning;  Natural Language Processing;  Stylometrics;  Text classification},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Rubin2012,
author={Rubin, V.L. and Conroy, N.},
title={Discerning truth from deception: Human judgments and automation efforts},
journal={First Monday},
year={2012},
volume={17},
number={3},
doi={10.5210/fm.v17i3.3933},
art_number={3170},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864013036&doi=10.5210%2ffm.v17i3.3933&partnerID=40&md5=5c5ef6a90e95704582bb8b9bb40d64e0},
affiliation={Faculty of Information and Media Studies, University of Western Ontario, London, ON, Canada},
abstract={Recent improvements in effectiveness and accuracy of the emerging field of automated deception detection and the associated potential of language technologies have triggered increased interest in mass media and general public. Computational tools capable of alerting users to potentially deceptive content in computer-mediated messages are invaluable for supporting undisrupted, computer-mediated communication and information practices, credibility assessment and decision-making. The goal of this ongoing research is to inform creation of such automated capabilities. In this study we elicit a sample of 90 computer-mediated personal stories with varying levels of deception. Each story has 10 associated human deception level judgments, confidence scores, and explanations. In total, 990 unique respondents participated in the study. Three approaches are taken to the data analysis of the sample: human judges, linguistic detection cues, and machine learning. Comparable to previous research results, human judgments achieve 50-63 percent success rates, depending on what is considered deceptive. Actual deception levels negatively correlate with their confident judgment as being deceptive (r = -0.35, df = 88, ρ = 0.008). The highest-performing machine learning algorithms reach 65 percent accuracy. Linguistic cues are extracted, calculated, and modeled with logistic regression, but are found not to be significant predictors of deception level, confidence score, or an authors' ability to fool a reader. We address the associated challenges with error analysis. The respondents' stories and explanations are manually content-analyzed and result in a faceted deception classification (theme, centrality, realism, essence, self-distancing) and a stated perceived cue typology. Deception detection remains novel, challenging, and important in natural language processing, machine learning, and the broader library information science and technology community. © 2012, First Monday.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gao201254,
author={Gao, J. and Lu, L. and Yang, Y. and Yu, G. and Na, L. and Rao, N.},
title={A novel concealed information test method based on independent component analysis and support vector machine},
journal={Clinical EEG and Neuroscience},
year={2012},
volume={43},
number={1},
pages={54-63},
doi={10.1177/1550059411428715},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859756574&doi=10.1177%2f1550059411428715&partnerID=40&md5=4fe006896b9fc77c12fc297a0d8b1532},
affiliation={School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, China; Daqing Oilfield General Hospital Grou, Daqing, China; School of Information Technoloy, Jiangxi University of Finance and Economics, Nanchang, China; School of Geosciences and Info-Physics, Central South University, Changsha, China},
abstract={The concealed information test (CIT) has drawn much attention and has been widely investigated in recent years. In this study, a novel CIT method based on denoised P3 and machine learning was proposed to improve the accuracy of lie detection. Thirty participants were chosen as the guilty and innocent participants to perform the paradigms of 3 types of stimuli. The electroencephalogram (EEG) signals were recorded and separated into many single trials. In order to enhance the signal noise ratio (SNR) of P3 components, the independent component analysis (ICA) method was adopted to separate non-P3 components (ie, artifacts) from every single trial. In order to automatically identify the P3 independent components (ICs), a new method based on topography template was proposed to automatically identify the P3 ICs. Then the P3 waveforms with high SNR were reconstructed on Pz electrodes. Second, the 3 groups of features based on time,frequency, and wavelets were extracted from the reconstructed P3 waveforms. Finally, 2 classes of feature samples were used to train a support vector machine (SVM) classifier because it has higher performance compared with several other classifiers. Meanwhile, the optimal number of P3 ICs and some other parameter values in the classifiers were determined by the cross-validation procedures. The presented method achieved a balance test accuracy of 84.29% on detecting P3 components for the guilty and innocent participants. The presented method improves the efficiency of CIT in comparison with previous reported methods. © 2012 EEG and Clinical Neuroscience Society.},
author_keywords={concealed information test;  ICA;  P300;  SVM;  wavelet},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rubin2011,
author={Rubin, V.L. and Conroy, N.J.},
title={Challenges in automated deception detection in computer-mediated communication},
journal={Proceedings of the ASIST Annual Meeting},
year={2011},
volume={48},
doi={10.1002/meet.2011.14504801098},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861445891&doi=10.1002%2fmeet.2011.14504801098&partnerID=40&md5=0cd2fb08fc6d1239485715ee24980fd5},
affiliation={Language and Information Technology Research Lab. (LIT.RL), Faculty of Information and Media Studies, University of Western Ontario, North Campus Building, London, ON N6A 5B7, Canada},
abstract={Deception detection remains novel, challenging, and important in natural language processing, machine learning, and the broader LIS community. Computational tools capable of alerting users to potentially deceptive content in computer-mediated messages are invaluable for supporting undisrupted, computer-mediated communication, information seeking, credibility assessment and decision making. The goal of this ongoing research is to inform creation of such automated capabilities. In this study we elicit a sample of 90 computer-mediated personal stories with varying levels of deception. Each story has 10 associated human judgments, confidence scores, and explanations. In total, 990 unique respondents participated in the study. Three analytical approaches are applied: human judgment accuracy, linguistic cue detection, and machine learning. Comparable to previous research results, human judges achieve 50-63% success rates. Actual deception levels negatively correlate with their confident judgments as being deceptive (r=-0.35, df=88, p=0.008). The best-performing machine learning algorithms reach 65% accuracy. Linguistic cues are extracted, calculated, and modeled with logistic regression, but are found not to be significant predictors of deception level or confidence score. We address the associated challenges with error analysis of the respondents' stories, and prose a faceted deception classification (theme, centrality, realism, essence, distancing) as well as a typology for stated perceived cues for deception detection (world knowledge, logical contradiction, linguistic evidence, and intuitive sense).},
author_keywords={Automated text categorization;  Computer-mediated communication;  Content analysis;  Deception detection;  Elicitation;  Lying;  Machine learning;  Truth;  Verbal cues},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NunamakerJr.201117,
author={Nunamaker Jr., J. and Derrick, D. and Elkins, A. and Burgoon, J. and Patton, M.},
title={Embodied conversational agent-based kiosk for automated interviewing},
journal={Journal of Management Information Systems},
year={2011},
volume={28},
number={1},
pages={17-48},
doi={10.2753/MIS0742-1222280102},
note={cited By 117},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051709642&doi=10.2753%2fMIS0742-1222280102&partnerID=40&md5=6c515ad47f15b954437d91217489c3a3},
affiliation={Center for the Management of Information, University of Arizona, Tucson, United States; University of Nebraska, Omaha, United States; University of Arizona, United States; Center for Identification Technology Research, University of Arizona, United States; Hoffman E-Commerce Laboratory, University of Arizona, United States},
abstract={We have created an automated kiosk that uses embodied intelligent agents to interview individuals and detect changes in arousal, behavior, and cognitive effort by using psychophysiological information systems. In this paper, we describe the system and propose a unique class of intelligent agents, which are described as Special Purpose Embodied Conversational Intelligence with Environmental Sensors (SPECIES). SPECIES agents use heterogeneous sensors to detect human physiology and behavior during interactions, and they affect their environment by influencing human behavior using various embodied states (i.e., gender and demeanor), messages, and recommendations. Based on the SPECIES paradigm, we present three studies that evaluate different portions of the model, and these studies are used as foundational research for the development of the automated kiosk. The first study evaluates human-computer interaction and how SPECIES agents can change perceptions of information systems by varying appearance and demeanor. Instantiations that had the agents embodied as males were perceived as more powerful, while female embodied agents were perceived as more likable. Similarly, smiling agents were perceived as more likable than neutral demeanor agents. The second study demonstrated that a single sensor measuring vocal pitch provides SPECIES with environmental awareness of human stress and deception. The final study ties the first two studies together and demonstrates an avatar-based kiosk that asks questions and measures the responses using vocalic measurements. © 2011 M.E. Sharpe, Inc.},
author_keywords={Avatars;  deception detection;  embodied conversational agents;  NeuroIS},
document_type={Article},
source={Scopus},
}

@BOOK{Rao20111,
author={Rao, R.P.N.},
title={Brain-computer interfacing: An introduction},
journal={Brain-Computer Interfacing: An Introduction},
year={2011},
pages={1-335},
doi={10.1017/CBO9781139032803},
note={cited By 100},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931323896&doi=10.1017%2fCBO9781139032803&partnerID=40&md5=f6ee698762accd5470ad9e66dafef590},
affiliation={Department of Computer Science and Engineering, Neurobiology and Behavior Program, University of Washington, Seattle, United States},
abstract={The idea of interfacing minds with machines has long captured the human imagination. Recent advances in neuroscience and engineering are making this a reality, opening the door to restoration and augmentation of human physical and mental capabilities. Medical applications such as cochlear implants for the deaf and neurally controlled prosthetic limbs for the paralyzed are becoming almost commonplace. Brain-computer interfaces (BCIs) are also increasingly being used in security, lie detection, alertness monitoring, telepresence, gaming, education, art, and human augmentation. This introduction to the field is designed as a textbook for upper-level undergraduate and first-year graduate courses in neural engineering or brain-computer interfacing for students from a wide range of disciplines. It can also be used for self-study, and as a reference by neuroscientists, computer scientists, engineers, and medical practitioners. Key features include: Essential background in neuroscience, brain recording and stimulation technologies, signal processing, and machine learning Detailed description of the major types of BCIs in animals and humans, including invasive, semi-invasive, non-invasive, stimulating, and bidirectional BCIs In-depth discussion of BCI applications and BCI ethics Questions and exercises in each chapter Supporting website with annotated list of book-related links. © Rajesh P. N. Rao 2013.},
document_type={Book},
source={Scopus},
}

@ARTICLE{Gao2010120,
author={Gao, J. and Wang, P. and Zheng, C.},
title={Lie detection method based on P300 and machine learning},
journal={Hsi-An Chiao Tung Ta Hsueh/Journal of Xi'an Jiaotong University},
year={2010},
volume={44},
number={10},
pages={120-124},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649314213&partnerID=40&md5=cf4c68f84a7c1d5312896b7b55779932},
affiliation={School of Life Sciences and Technology, Xi'an Jiaotong University, Xi'an 710049, China},
abstract={For solving the unvariability of subject cognitive states under the same kind of stimulus in the conventional machine learning methods, the method based on P300 and machine learning was proposed. The standard three-stimuli protocol was chosen. Thirty guilty and innocent subjects were randomly divided into two groups and their EEG signals were first recoded. Independent component analysis (ICA) was carried out to decompose the datasets in the probe stimuli. The ICs with the largest projection strength at Pz were selected to reconstruct the Pz waveforms. Then small number of Pz waveforms within each subject is further averaged. Afterwards, the time-domain and wavelet features were extracted from each denoised Pz waveforms. In terms of the classifier to identify the P300 and non-P300 waveforms, the individual diagnostic rate was evaluated. The experimental results show that the SVM classifier is suitable to identify the sense states of lying, and the proposed method enables to improve the SNR in single trails, enhancing the accuracy of identifying the P300 and of individual diagnostic rate.},
author_keywords={Electroencephalo graph;  Independent component analysis;  Lie detection;  P300;  Support vector machine;  Two-step denoising},
document_type={Article},
source={Scopus},
}
