@inproceedings{10.1145/2823465.2823466,
author = {Diana, Barbara and Elia, Massimiliano and Zurloni, Valentino and Elia, Annibale and Maisto, Alessandro and Pelosi, Serena},
title = {Multimodal Deception Detection: A t-Pattern Approach},
year = {2015},
isbn = {9781450339872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2823465.2823466},
doi = {10.1145/2823465.2823466},
abstract = {This work proposes a new approach to deception detection, based on finding significant differences between liars and truth tellers through the analysis of their behavior, verbal and non-verbal. This is based on the combination of two factors: multimodal data collection, and t-pattern analysis. Multimodal approach has been acknowledged in literature about deception detection and on several studies concerning the understanding of any communicative phenomenon. We believe a methodology such as T-pattern analysis could be able to get the best advantages from an approach that combines data coming from multiple signaling systems. In fact, T-pattern analysis is a recent methodology for the analysis of behavior that unveil the complex structure at the basis of the organization of human behavior. For this work, we conducted an experimental study and analyzed data related to a single subject. Results showed how T-pattern analysis allowed to find differences between truth telling and lying. This work aims at making progress in the state of knowledge about deception detection, with the final goal to propose a useful tool for the improvement of public security and well-being.},
booktitle = {Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection},
pages = {21–28},
numpages = {8},
keywords = {multimodality, deception, t-pattern analysis},
location = {Seattle, Washington, USA},
series = {WMDD '15}
}

@inproceedings{10.1145/3366424.3384369,
author = {Hershkovitch Neiterman, Evgeny and Bitan, Moshe and Azaria, Amos},
title = {Multilingual Deception Detection by Autonomous Agents},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3366424.3384369},
doi = {10.1145/3366424.3384369},
abstract = {In this work we present the development of a multilingual deception detection model based on speech. In addition, we also develop a model that detects whether a statement will be perceived as a lie or not by human subjects. To this end, we developed a game for collecting a large scale and high quality labeled data-set in a controlled environments in English and Hebrew. We developed a model that can detect deception based only on a vocal statement from the participants of the experiment. The data-set will be released to the community. },
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {480–484},
numpages = {5},
keywords = {Deception detection, Voice, Lie detection, Agents},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3019612.3019644,
author = {Abouelenien, Mohamed and P\'{e}rez-Rosas, Ver\'{o}nica and Zhao, Bohan and Mihalcea, Rada and Burzo, Mihai},
title = {Gender-Based Multimodal Deception Detection},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3019612.3019644},
doi = {10.1145/3019612.3019644},
abstract = {This paper explores gender-based differences in multimodal deception detection. We introduce a new large, gender-balanced dataset, consisting of 104 subjects with 520 different responses covering multiple scenarios, and perform an extensive analysis of different feature sets extracted from the linguistic, physiological, and thermal data streams recorded from the subjects. We describe a multimodal deception detection system, and show how the two genders achieve different detection rates for different individual and combined feature sets, with accuracy figures reaching 80%. Our experiments and results allow us to make interesting observations concerning the differences in the multimodal detection of deception in males and females.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {137–144},
numpages = {8},
keywords = {deception detection, linguistic, thermal, multimodal, physiological},
location = {Marrakech, Morocco},
series = {SAC '17}
}

@inproceedings{10.1145/3242969.3264967,
author = {Karimi, Hamid},
title = {Interpretable Multimodal Deception Detection in Videos},
year = {2018},
isbn = {9781450356923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3242969.3264967},
doi = {10.1145/3242969.3264967},
abstract = {There are various real-world applications such as video ads, airport screenings, courtroom trials, and job interviews where deception detection can play a crucial role. Hence, there are immense demands on deception detection in videos. Videos contain rich information including acoustic, visual, temporal, and/or linguistic information, which provides great opportunities for advanced deception detection. However, videos are inherently complex; moreover, they lack detective labels in many real-world applications, which poses tremendous challenges to traditional deception detection. In this manuscript, I present my Ph.D. research on the problem of deception detection in videos. In particular, I provide a principled way to capture rich information into a coherent model and propose an end-to-end framework DEV to detect DEceptive Videos automatically. Preliminary results on real-world videos demonstrate the effectiveness of the proposed framework.},
booktitle = {Proceedings of the 20th ACM International Conference on Multimodal Interaction},
pages = {511–515},
numpages = {5},
keywords = {insufficient training data, video, audio, deception detection},
location = {Boulder, CO, USA},
series = {ICMI '18}
}

@inproceedings{10.1145/2663204.2663229,
author = {Abouelenien, Mohamed and P\'{e}rez-Rosas, Veronica and Mihalcea, Rada and Burzo, Mihai},
title = {Deception Detection Using a Multimodal Approach},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2663204.2663229},
doi = {10.1145/2663204.2663229},
abstract = {In this paper we address the automatic identification of deceit by using a multimodal approach. We collect deceptive and truthful responses using a multimodal setting where we acquire data using a microphone, a thermal camera, as well as physiological sensors. Among all available modalities, we focus on three modalities namely, language use, physiological response, and thermal sensing. To our knowledge, this is the first work to integrate these specific modalities to detect deceit. Several experiments are carried out in which we first select representative features for each modality, and then we analyze joint models that integrate several modalities. The experimental results show that the combination of features from different modalities significantly improves the detection of deceptive behaviors as compared to the use of one modality at a time. Moreover, the use of non-contact modalities proved to be comparable with and sometimes better than existing contact-based methods. The proposed method increases the efficiency of detecting deceit by avoiding human involvement in an attempt to move towards a completely automated non-invasive deception detection process.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {58–65},
numpages = {8},
keywords = {deception detection, multimodal processing},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inbook{10.1145/3107990.3108005,
author = {Burzo, Mihai and Abouelenien, Mohamed and Perez-Rosas, Veronica and Mihalcea, Rada},
title = {Multimodal Deception Detection},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108005},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {419–453},
numpages = {35}
}

@inproceedings{10.5555/2857070.2857153,
author = {Rubin, Victoria L. and Chen, Yimin and Conroy, Niall J.},
title = {Deception Detection for News: Three Types of Fakes},
year = {2015},
isbn = {087715547X},
publisher = {American Society for Information Science},
address = {USA},
abstract = {A fake news detection system aims to assist users in detecting and filtering out varieties of potentially deceptive news. The prediction of the chances that a particular news item is intentionally deceptive is based on the analysis of previously seen truthful and deceptive news. A scarcity of deceptive news, available as corpora for predictive modeling, is a major stumbling block in this field of natural language processing (NLP) and deception detection. This paper discusses three types of fake news, each in contrast to genuine serious reporting, and weighs their pros and cons as a corpus for text analytics and predictive modeling. Filtering, vetting, and verifying online information continues to be essential in library and information science (LIS), as the lines between traditional news and online information are blurring.},
booktitle = {Proceedings of the 78th ASIS&amp;T Annual Meeting: Information Science with Impact: Research in and for the Community},
articleno = {83},
numpages = {4},
keywords = {fake news detection, natural language processing, satire, corpus construction, hoax, deception detection, reputable sources, news verification, text analytics, fabrication, predictive modeling, credibility assessment},
location = {St. Louis, Missouri},
series = {ASIST '15}
}

@inproceedings{10.1145/2818346.2820758,
author = {P\'{e}rez-Rosas, Ver\'{o}nica and Abouelenien, Mohamed and Mihalcea, Rada and Burzo, Mihai},
title = {Deception Detection Using Real-Life Trial Data},
year = {2015},
isbn = {9781450339124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2818346.2820758},
doi = {10.1145/2818346.2820758},
abstract = {Hearings of witnesses and defendants play a crucial role when reaching court trial decisions. Given the high-stake nature of trial outcomes, implementing accurate and effective computational methods to evaluate the honesty of court testimonies can offer valuable support during the decision making process. In this paper, we address the identification of deception in real-life trial data. We introduce a novel dataset consisting of videos collected from public court trials. We explore the use of verbal and non-verbal modalities to build a multimodal deception detection system that aims to discriminate between truthful and deceptive statements provided by defendants and witnesses. We achieve classification accuracies in the range of 60-75% when using a model that extracts and fuses features from the linguistic and gesture modalities. In addition, we present a human deception detection study where we evaluate the human capability of detecting deception in trial hearings. The results show that our system outperforms the human capability of identifying deceit.},
booktitle = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
pages = {59–66},
numpages = {8},
keywords = {real-life trial, verbal, non-verbal, multimodal, deception detection},
location = {Seattle, Washington, USA},
series = {ICMI '15}
}

@inproceedings{10.5555/2857070.2857152,
author = {Conroy, Niall J. and Rubin, Victoria L. and Chen, Yimin},
title = {Automatic Deception Detection: Methods for Finding Fake News},
year = {2015},
isbn = {087715547X},
publisher = {American Society for Information Science},
address = {USA},
abstract = {This research surveys the current state-of-the-art technologies that are instrumental in the adoption and development of fake news detection. "Fake news detection" is defined as the task of categorizing news along a continuum of veracity, with an associated measure of certainty. Veracity is compromised by the occurrence of intentional deceptions. The nature of online news publication has changed, such that traditional fact checking and vetting from potential deception is impossible against the flood arising from content generators, as well as various formats and genres.The paper provides a typology of several varieties of veracity assessment methods emerging from two major categories -- linguistic cue approaches (with machine learning), and network analysis approaches. We see promise in an innovative hybrid approach that combines linguistic cue and machine learning, with network-based behavioral data. Although designing a fake news detector is not a straightforward problem, we propose operational guidelines for a feasible fake news detecting system.},
booktitle = {Proceedings of the 78th ASIS&amp;T Annual Meeting: Information Science with Impact: Research in and for the Community},
articleno = {82},
numpages = {4},
keywords = {news verification, fraud, deception detection, knowledge networks, SVM, automation, predictive modelling, veracity assessment, fake news detection, methods},
location = {St. Louis, Missouri},
series = {ASIST '15}
}

@inproceedings{10.1145/3132847.3137174,
author = {Mihalcea, Rada},
title = {Deception Detection: When Computers Become Better than Humans},
year = {2017},
isbn = {9781450349185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3132847.3137174},
doi = {10.1145/3132847.3137174},
abstract = {Whether we like it or not, deception happens every day and everywhere: thousands of trials taking place daily around the world; little white lies: "I'm busy that day!" even if your calendar is blank; news "with a twist" (a.k.a. fake news) meant to attract the readers attraction, and get some advertisement clicks on the side; portrayed identities, on dating sites and elsewhere. Can a computer automatically detect deception in written accounts or in video recordings? In this talk, I will describe our work in building linguistic and multimodal algorithms for deception detection, targeting deceptive statements, trial videos, fake news, identity deceptions, and also going after deception in multiple cultures. I will also show how these algorithms can provide insights into what makes a good lie - and thus teach us how we can spot a liar. As it turns out, computers can be trained to identify lies in many different contexts, and they can do it much better than humans do! },
booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
pages = {3},
numpages = {1},
keywords = {Keynote Talk},
location = {Singapore, Singapore},
series = {CIKM '17}
}

@inproceedings{10.1145/3143699.3143707,
author = {Litvinova, Tatiana and Ryzhkova, Ekaterina and Litvinova, Olga and Larin, Evgeni and Lyell, John and Seredin, Pavel},
title = {Building a Corpus of "Real" Texts for Deception Detection},
year = {2017},
isbn = {9781450354370},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3143699.3143707},
doi = {10.1145/3143699.3143707},
abstract = {Text-based deception detection is currently emerging as a vital multidisciplinary field due to its indisputable theoretical and practical value (police, security, and customs, including predatory communications, such as Internet scams). A very important issue associated with deception detection is designing valid text corpora. Most research has been carried out using texts produced in laboratory settings. There is a lack of "real" deceptive texts written when the stakes for deception are high as they are obviously difficult to collect and label. In addition, studies in text-based deception detection have mostly been performed for Romance and Germanic languages. There are few studies dealing with deception detection in Slavic languages. In this paper one can find an overview of available text corpora used for studying text-based deception detection as well as the description of how the first corpus of "real" deceptive texts for Slavic languages was collected and labeled. We expect this corpus once finished to be a handy tool for developing and testing new deception detection techniques and for carrying out related cross-cultural studies.},
booktitle = {Proceedings of the International Conference IMS-2017},
pages = {110–115},
numpages = {6},
keywords = {Corpus of texts, deception detection, text-based deception detection, Russian language, high-stake deception},
location = {Saint Petersburg, Russian Federation},
series = {IMS2017}
}

@proceedings{10.1145/2823465,
title = {WMDD '15: Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection},
year = {2015},
isbn = {9781450339872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2015 ACM Workshop on Multimodal Deception Detection, WMDD 2015. As deception behavior permeates on almost every human interaction, there is growing interest to understand and recognize the nature of deceptive behavior in multiple domains. The goal of this workshop is to provide the participants with a forum to foster the dissemination of ideas on computational and behavioral methodologies for deception detection. We are very excited about the success of the first edition of this workshop and the unique opportunity of gathering researchers from different fields to share their perspectives on deception detection.The call for papers attracted submissions from United States, Canada, and Europe, which resulted in five accepted papers that will be presented during the workshop. The program also includes three excellent invited speakers: we are grateful to Dr. Yejin Choi (University of Washington), Dr. Jeffrey Hancock (Cornell University), and Dr. Ioannis Pavlidis (University of Houston) for agreeing to speak at our workshop. We couldn't have hoped for a better slate of speakers and presentations!},
location = {Seattle, Washington, USA}
}

@inproceedings{10.5555/2390665.2390708,
author = {Feng, Song and Banerjee, Ritwik and Choi, Yejin},
title = {Syntactic Stylometry for Deception Detection},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Most previous studies in computerized deception detection have relied only on shallow lexico-syntactic patterns. This paper investigates syntactic stylometry for deception detection, adding a somewhat unconventional angle to prior literature. Over four different datasets spanning from the product review to the essay domain, we demonstrate that features driven from Context Free Grammar (CFG) parse trees consistently improve the detection performance over several baselines that are based only on shallow lexico-syntactic features. Our results improve the best published result on the hotel review data (Ott et al., 2011) reaching 91.2% accuracy with 14% error reduction.},
booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2},
pages = {171–175},
numpages = {5},
location = {Jeju Island, Korea},
series = {ACL '12}
}

@inproceedings{10.5555/2615731.2617486,
author = {Azaria, Amos and Richardson, Ariella and Kraus, Sarit},
title = {An Agent for Deception Detection in Discussion Basedenvironments},
year = {2014},
isbn = {9781450327381},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Autonomous agents can be of assistance in detecting and reducing deception in computerized forums and chat-rooms. We focus on text-based environments where the deceiver is a member of a group which is holding a discussion. Deception detection methods which currently exist for such environments, heavily rely on either audio or visual information. We have developed DIG, an innovative machine learning-based autonomous agent, which joins a group of players as a regular member and assists them in catching a deceiver. We introduce "the pirate game" as a platform for deploying this agent. Our experimental study shows that although humans display difficulty detecting deception, DIG is not only capable of finding a deceptive player, it also helps increase the entire group's success.},
booktitle = {Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems},
pages = {1387–1388},
numpages = {2},
keywords = {deception detection, discussions, human modeling},
location = {Paris, France},
series = {AAMAS '14}
}

@inproceedings{10.5555/1920331.1920377,
author = {Rubin, Victoria L.},
title = {On Deception and Deception Detection: Content Analysis of Computer-Mediated Stated Beliefs},
year = {2010},
publisher = {American Society for Information Science},
address = {USA},
abstract = {Deception in computer-mediated communication is defined as a message knowingly and intentionally transmitted by a sender to foster a false belief or conclusion by the perceiver. Stated beliefs about deception and deceptive messages or incidents are content analyzed in a sample of 324 computer-mediated communications. Relevant stated beliefs are obtained through systematic sampling and querying of the blogosphere based on 80 English words commonly used to describe deceptive incidents. Deception is conceptualized broader than lying and includes a variety of deceptive strategies: falsification, concealment (omitting material facts) and equivocation (dodging or skirting issues). The stated beliefs are argued to be valuable toward the creation of a unified multi-faceted ontology of deception, stratified along several classificatory facets such as (1) contextual domain (e.g., personal relations, politics, finances &amp; insurance), (2) deception content (e.g., events, time, place, abstract notions), (3) message format (e.g., a complaint: they lied to us, a victim story: I was lied to or tricked, or a direct accusation: you're lying), and (4) deception variety, each tied to particular verbal cues (e.g., misinforming, scheming, misrepresenting, or cheating). The paper positions automated deception detection within the field of library and information science (LIS), as a feasible natural language processing (NLP) task. Key findings and important constructs in deception research from interpersonal communication, psychology, criminology, and language technology studies are synthesized into an overview. Deception research is juxtaposed to several benevolent constructs in LIS research: trust, credibility, certainty, and authority.},
booktitle = {Proceedings of the 73rd ASIS&amp;T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
articleno = {32},
numpages = {10},
keywords = {blogs, content analysis, natural language processing, information security, automated text classification, computer-mediated communications, deception detection, credibility, trust},
location = {Pittsburgh, Pennsylvania},
series = {ASIS&amp;T '10}
}

@article{10.1145/2422512.2422517,
author = {Vartapetiance, Anna and Gillam, Lee},
title = {Deception Detection for the Tangled Web},
year = {2012},
issue_date = {August 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {1},
issn = {0095-2737},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2422512.2422517},
doi = {10.1145/2422512.2422517},
abstract = {Deception is a reasonably common part of daily life that society sometimes demonstrates a degree of acceptance of, and occasionally people are very willing to be deceived. But can a computer identify deception and distinguish it from that which is not deceptive?We explore deception in various guises, differentiating it from lies, and highlighting the influence of medium and message in both deception and its detection. Our investigations to date have uncovered disagreements relating to the measurements of such cues, and variations in interpretations, as could be problematic in building a deception detection system.},
journal = {SIGCAS Comput. Soc.},
month = aug,
pages = {34–47},
numpages = {14}
}

@inproceedings{10.1145/2388676.2388714,
author = {Mihalcea, Rada and Burzo, Mihai},
title = {Towards Multimodal Deception Detection -- Step 1: Building a Collection of Deceptive Videos},
year = {2012},
isbn = {9781450314671},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2388676.2388714},
doi = {10.1145/2388676.2388714},
abstract = {In this paper, we introduce a novel crowdsourced dataset of deceptive videos. We describe the collection process and the characteristics of the dataset, and we validate it through initial experiments in the recognition of deceptive language. The collection, consisting of 140 truthful and deceptive videos, will enable future experiments in multimodal deceptive detection.},
booktitle = {Proceedings of the 14th ACM International Conference on Multimodal Interaction},
pages = {189–192},
numpages = {4},
keywords = {deception detection, corpus construction},
location = {Santa Monica, California, USA},
series = {ICMI '12}
}

@inproceedings{10.1145/3382507.3418864,
author = {Mathur, Leena and Matari\'{c}, Maja J.},
title = {Introducing Representations of Facial Affect in Automated Multimodal Deception Detection},
year = {2020},
isbn = {9781450375818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3382507.3418864},
doi = {10.1145/3382507.3418864},
abstract = {Automated deception detection systems can enhance health, justice, and security in society by helping humans detect deceivers in high-stakes situations across medical and legal domains, among others. Existing machine learning approaches for deception detection have not leveraged dimensional representations of facial affect: valence and arousal. This paper presents a novel analysis of the discriminative power of facial affect for automated deception detection, along with interpretable features from visual, vocal, and verbal modalities. We used a video dataset of people communicating truthfully or deceptively in real-world, high-stakes courtroom situations. We leveraged recent advances in automated emotion recognition in-the-wild by implementing a state-of-the-art deep neural network trained on the Aff-Wild database to extract continuous representations of facial valence and facial arousal from speakers. We experimented with unimodal Support Vector Machines (SVM) and SVM-based multimodal fusion methods to identify effective features, modalities, and modeling approaches for detecting deception. Unimodal models trained on facial affect achieved an AUC of 80%, and facial affect contributed towards the highest-performing multimodal approach (adaptive boosting) that achieved an AUC of 91% when tested on speakers who were not part of training sets. This approach achieved a higher AUC than existing automated machine learning approaches that used interpretable visual, vocal, and verbal features to detect deception in this dataset, but did not use facial affect. Across all videos, deceptive and truthful speakers exhibited significant differences in facial valence and facial arousal, contributing computational support to existing psychological theories on relationships between affect and deception. The demonstrated importance of facial affect in our models informs and motivates the future development of automated, affect-aware machine learning approaches for modeling and detecting deception and other social behaviors in-the-wild.},
booktitle = {Proceedings of the 2020 International Conference on Multimodal Interaction},
pages = {305–314},
numpages = {10},
keywords = {multimodal machine learning, social signal processing, affective computing, deception detection, human behavior analysis},
location = {Virtual Event, Netherlands},
series = {ICMI '20}
}

@inproceedings{10.1145/3360774.3360788,
author = {Rahman, Md. Mizanur and Shome, Atanu and Chellappan, Sriram and Islam, A. B. M. Alim Al},
title = {How Smart Your Smartphone is in Lie Detection?},
year = {2019},
isbn = {9781450372831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3360774.3360788},
doi = {10.1145/3360774.3360788},
abstract = {Lying is a (practically) unavoidable component of our day to day interactions with other people, and it includes both oral and textual communications (e.g. text entered via smartphones). Detecting when a person is lying has important applications, especially with the ubiquity of messaging via smart-phones, coupled with rampant increases in (intentional) spread of mis-information today. In this paper, we design a technique to detect whether or not a person's textual inputs when typed via a smartphone indicate lying. To do so, first, we judiciously develop a smartphone based survey that guarantees any participant to provide a mix of true and false responses. While the participant is texting out responses to each question, the smartphone measures readings from its inbuilt inertial sensors, and then computes features like shaking, acceleration, tilt angle, typing speed etc. experienced by it. Subsequently, for each participant (47 in total), we glean the true and false responses using our own experiences with them, and also via informal discussions with each participant. By comparing the responses of each participant, along with the corresponding motion features computed by the smartphone, we implement several machine learning algorithms to detect when a participant is lying, and our accuracy is around 70% in the most stringent leave-one-out evaluation strategy. Later, utilizing findings of our analysis, we develop an architecture for real-time lie detection using smartphones. Yet another user evaluation of our lie detection system yields 84%-90% accuracy in detecting false responses.},
booktitle = {Proceedings of the 16th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {338–347},
numpages = {10},
keywords = {ubiquitous computing, lie detection, machine learning, human-computer interaction, android application},
location = {Houston, Texas, USA},
series = {MobiQuitous '19}
}

@inproceedings{10.1145/3282286.3282287,
author = {Islam, Md. Saiful and Mamun, Nursadul and Ullah, Muhammad S.},
title = {Speech Based Deception Detection Using Bispectral Analysis},
year = {2018},
isbn = {9781450363860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3282286.3282287},
doi = {10.1145/3282286.3282287},
abstract = {Speech is considered as one of the most efficient and effective way to communicate with each other. However, a deception is a very common phenomenon in speech communication. It is difficult to detect if anyone is actually telling the truth or not. This study proposes a neural response based novel technique to identify the true or false from speech. In this study, the speech signal is used as the input to the auditory nerve model. This technique applies the higher order statistics called bispectrum to the auditory neurogram to distinguish the true and false from speech. Different parameters of the bispectrum are used as a feature to detect a deception from speech. Deceptive speech can be detected accurately by using the 'normalized bispectral entropy' of the bispectrum feature parameters for the envelope information (ENV) data and the 'maximum bispectrum' of the bispectrum feature parameter for the temporal fine structure (TFS) data. Speech based deception detection is a speech processing method which provides better accuracy to detect deception than many other deception detection techniques. This technique could be applied effectively for the national security systems.},
booktitle = {Proceedings of the 2nd International Conference on Graphics and Signal Processing},
pages = {95–99},
numpages = {5},
keywords = {Deception, Neurogram, Bispectrum Analysis, Higher Order Statistics, Auditory Nerve Model},
location = {Sydney, NSW, Australia},
series = {ICGSP'18}
}

@inproceedings{10.5555/2388616.2388623,
author = {Baxter, Daniel},
title = {Current and Future Needs for Deception Detection in Government Screening Environments},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {The focus of this talk is on the applications and techniques currently used in government screening venues and on anticipated future applications. I will begin with a discussion of how and why the polygraph is used in a screening interview and touch on some of the newer techniques in deception detection using body movements, vocal and verbal behavior that are now being tested. We'll then look at some of the needs for deception detection and applications on our wish list. The talk will include cases where the current technology has been good and where it has not.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {48},
numpages = {1},
location = {Avignon, France},
series = {EACL 2012}
}

@proceedings{10.5555/2388616,
title = {EACL 2012: Proceedings of the Workshop on Computational Approaches to Deception Detection},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Welcome to the EACL-2012 Workshop on Computational Approaches to Deception Detection. In organizing the workshop, we hope that it will allow us to review the foundations of this relatively new subfield with computational linguistics and encourage more work in the area.For much of the twentieth century, the fields of psychology and criminal justice have studied the behaviors that might be associated, directly or indirectly, with deception. Three types of behavior have been examined: facial expressions and body movements; vocal behaviors, including prosodic features; and verbal behaviors, including the words and structures that might correlate with deception.Now is a good time to review the NLP approaches that have been tried, and to consider the foundations and trends, both theoretical and applied, that will enable us to move forward productively. Several areas of natural language processing are ripe to address the vocal and verbal features that might be associated with deception and new approaches may well combine information from all three modalities. A spate of recent NLP papers on the classification of narratives as truthful or deceptive suggests that the field is ready to open up to this promising area. We see some trends in deception research, expressed in the current collection of papers by descriptions of stylometric techniques, sensor technologies, machine learning approaches and models of data collection and processing.},
location = {Avignon, France}
}

@inproceedings{10.1145/3349801.3349806,
author = {Avola, Danilo and Cinque, Luigi and Foresti, Gian Luca and Pannone, Daniele},
title = {Automatic Deception Detection in RGB Videos Using Facial Action Units},
year = {2019},
isbn = {9781450371896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3349801.3349806},
doi = {10.1145/3349801.3349806},
abstract = {The outcome of situations such as police interrogatory or court trials is strongly influenced by the behaviour of the interviewed subject. In particular, a deceptive behaviour may completely overturn such sensible situations. Moreover, if some specific devices such as polygraph or magnetic resonance are used, the subject is aware of being monitored and thus he may change his behaviour accordingly. To overcome this problem, in this paper a method for detecting deception in RGB videos is presented. The method automatically extracts facial Action Units (AU) from video frames containing the interviewed subject, and classifies them through an SVM as truthful or deception. Experiments on real trial court data and comparisons with the current state of the art show the effectiveness of the proposed method.},
booktitle = {Proceedings of the 13th International Conference on Distributed Smart Cameras},
articleno = {5},
numpages = {6},
keywords = {RGB video, facial action unit, Deception detection, SVM},
location = {Trento, Italy},
series = {ICDSC 2019}
}

@inproceedings{10.1145/2675133.2675137,
author = {Azaria, Amos and Richardson, Ariella and Kraus, Sarit},
title = {An Agent for Deception Detection in Discussion Based Environments},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2675133.2675137},
doi = {10.1145/2675133.2675137},
abstract = {Extensive use of computerized forums and chat-rooms provides a modern venue for deception. We propose introducing an agent to assist in detecting and incriminating a deceptive participant. We designed a game, where deception in a text based discussion environment occurs. In this game several participants attempt to collectively detect a deceptive member. We compose an automated agent which participates in this game as a regular player. The goal of the agent is to detect the deceptive participant and alert other members, without raising suspicion itself. We use machine learning on the data collected from human players to design this agent. Extensive evaluation of our agent shows that it succeeds in raising the players collective success rate in catching the deceptive player.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {218–227},
numpages = {10},
keywords = {deception detection, suspicion evasion, human agent interaction, machine learning},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@inproceedings{10.1145/3368567.3368586,
author = {Rangel, Francisco and Rosso, Paolo and Charfi, Anis and Zaghouani, Wajdi and Ghanem, Bilal and S\'{a}nchez-Junquera, Javier},
title = {On the Author Profiling and Deception Detection in Arabic Shared Task at FIRE},
year = {2019},
isbn = {9781450377508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3368567.3368586},
doi = {10.1145/3368567.3368586},
abstract = {This paper summarises the Author Profiling and Deception Detection in Arabic (APDA) shared task at PAN@FIRE 2019. Two have been the main aims of this year's task: i) to profile the age, gender and native language of a Twitter user; ii) to determine whether an Arabic text is deceptive or not in two different genres: Twitter and news headlines. For this purpose we have created three corpora in Arabic. Altogether, the approaches of 13 participants are evaluated.},
booktitle = {Proceedings of the 11th Forum for Information Retrieval Evaluation},
pages = {7–9},
numpages = {3},
keywords = {Twitter, FIRE, deception detection, Arabic, author profiling},
location = {Kolkata, India},
series = {FIRE '19}
}

@inproceedings{10.1145/3056662.3056709,
author = {Turnip, Arjon and Amri, M Faizal and Fakrurroja, Hanif and Simbolon, Artha Ivonita and Suhendra, M. Agung and Kusumandari, Dwi Esti},
title = {Deception Detection of EEG-P300 Component Classified by SVM Method},
year = {2017},
isbn = {9781450348577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3056662.3056709},
doi = {10.1145/3056662.3056709},
abstract = {This study will explore the differences in brain wave activity while a person is either telling the truth or being deceptive. A subject brain wave activities based EEG-P300 component will be monitored while they first respond truthfully and then falsely to questions in regards to a mock theft scenario. Eleven males whose age are around 24 ± 3 years old were subject to the experiment. For extraction and classification, an independent component analysis and support vector machine methods were adopted. The gathered data were then divided into training and test data to produce several models. The results show that a larger spike in the P300 component when the subject was instructed to conceal which watch they had chosen. The findings of these experiments have been promising in testing the validity of using an EEG in deception detection.},
booktitle = {Proceedings of the 6th International Conference on Software and Computer Applications},
pages = {299–303},
numpages = {5},
keywords = {extraction, deception, BCI, SVM, classification, EEG-P300},
location = {Bangkok, Thailand},
series = {ICSCA '17}
}

@inproceedings{10.1145/3361758.3361782,
author = {Farizi, Farah Ditha and Bangay, Shaun and Mckenzie, Sophie},
title = {Facial Cues for Deception Detection in Virtual Reality Based Communication},
year = {2019},
isbn = {9781450372466},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3361758.3361782},
doi = {10.1145/3361758.3361782},
abstract = {Deception and deception detection is a part of human communication and needs to be accurately represented in computer mediated communication. In this study deception facial micro-expressions are translated from live human footage onto virtual reality based avatars in order to assess how well these cues can be represented and communicated in a virtual world. The results indicate that human observers are no better at detecting deception in this scenario than in previous experiments. Classification methods identify limitations in accurately representing the expression space. The experimental design does suggest strategies for using virtual reality for more accurately investigating deception practices for future studies.},
booktitle = {Proceedings of the 3rd International Conference on Big Data and Internet of Things},
pages = {65–69},
numpages = {5},
keywords = {Behaviour Modelling, Psychology in VR, Facial Cues, Computer Mediated Communication in VR},
location = {Melbourn, VIC, Australia},
series = {BDIOT 2019}
}

@inproceedings{10.1145/2910674.2910682,
author = {Abouelenien, Mohamed and Mihalcea, Rada and Burzo, Mihai},
title = {Analyzing Thermal and Visual Clues of Deception for a Non-Contact Deception Detection Approach},
year = {2016},
isbn = {9781450343374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2910674.2910682},
doi = {10.1145/2910674.2910682},
abstract = {With increased levels of security threats and the long-term consequences of falsely accusing the innocent and freeing the guilty, there is a growing need for reliable and efficient deception detection systems. Polygraph tests are invasive and require elongated time and human expertise, which is subject to bias and error. In this paper, we analyze thermal and visual clues of deception using a dataset collected from 30 subjects and multiple scenarios. We analyze expressions and other visual features and provide the first comparison between thermal facial regions to identify areas with higher capability of indicating deceit. Our experimental results show that our non-contact feature fusion model outperforms traditional physiological measurements, paving the road for non-invasive deception detection methodologies.},
booktitle = {Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {35},
numpages = {4},
keywords = {visual, multimodal, deception, physiological, thermal},
location = {Corfu, Island, Greece},
series = {PETRA '16}
}

@inproceedings{10.5555/2388616.2388626,
author = {Li, Deqing and Santos, Eugene},
title = {Argument Formation in the Reasoning Process: Toward a Generic Model of Deception Detection},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Research on deception detection has been mainly focused on two kinds of approaches. In one, people consider deception types and taxonomies, and use different counter strategies to detect and reverse deception. In the other, people search for verbal and non-verbal cues in the content of deceptive communication. However, general theories that study fundamental properties of deception which can be applied in computational models are still very rare. In this work, we propose a general model of deception detection guided by a fundamental principle in the formation of communicative deception. Experimental results using our model demonstrate that deception is distinguishable from unintentional misinformation.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {63–71},
numpages = {9},
location = {Avignon, France},
series = {EACL 2012}
}

@article{10.1145/2287714.2287716,
author = {Yang, Yanjuan and Mannino, Michael},
title = {An Experimental Comparison of a Document Deception Detection Policy Using Real and Artificial Deception},
year = {2012},
issue_date = {August 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1936-1955},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2287714.2287716},
doi = {10.1145/2287714.2287716},
abstract = {Developing policies to screen documents for deception is often hampered by the cost of data collection and the inability to evaluate policy alternatives due to lack of data. To lower data collection costs and increase the amount of data, artificially generated deception data can be used, but the impact of using artificially generated deception data is not well understood. This article studies the impact of artificially generated deception on document screening policies. The deception and truth data were collected from financial aid applications, a document-centric area with limited resources for screening. Real deception was augmented with artificial data generated by noise and deception generation models. Using the real data and artificially generated data, we designed an innovative experiment with deception type and deception rate as factors, and harmonic mean and cost as outcome variables. We used two budget models (fixed and variable) typically employed by financial aid offices to measure the cost of noncompliance in financial aid applications. The analysis included an evaluation of a common policy for deception screening using both fixed and varying screening rates. The results of the experiment provided evidence of similar performance of screening policy with real and artificial deception, suggesting the possibility of using artificially generated deception to reduce the costs associated with obtaining training data.},
journal = {J. Data and Information Quality},
month = aug,
articleno = {6},
numpages = {25},
keywords = {data generation model, deception, artificial deception, noise, boosted deception, Screening policy, natural deception}
}

@article{10.1145/2605292,
author = {Rubin, Victoria L.},
title = {TALIP Perspectives, Guest Editorial Commentary: Pragmatic and Cultural Considerations for Deception Detection in Asian Languages},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {1530-0226},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2605292},
doi = {10.1145/2605292},
abstract = {In hopes of sparking a discussion, I argue for much needed research on automated deception detection in Asian languages. The task of discerning truthful texts from deceptive ones is challenging, but a logical sequel to opinion mining. I suggest that applied computational linguists pursue broader interdisciplinary research on cultural differences and pragmatic use of language in Asian cultures, before turning to detection methods based on a primarily Western (English-centric) worldview. Deception is fundamentally human, but how do various cultures interpret and judge deceptive behavior?},
journal = {ACM Transactions on Asian Language Information Processing},
month = jun,
articleno = {10},
numpages = {8}
}

@inproceedings{10.1145/2823465.2823468,
author = {Levitan, Sarah I. and An, Guzhen and Wang, Mandi and Mendels, Gideon and Hirschberg, Julia and Levine, Michelle and Rosenberg, Andrew},
title = {Cross-Cultural Production and Detection of Deception from Speech},
year = {2015},
isbn = {9781450339872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2823465.2823468},
doi = {10.1145/2823465.2823468},
abstract = {Detecting deception from different dimensions of human behavior has been a major goal of research in psychology and computational linguistics for some years and is currently of considerable interest to military and law enforcement agencies. However, relatively little work has been done to develop automatic methods to detect deception from spoken language or to compare deception detection and production between different cultures. We present results of experiments on a new corpus of deceptive and non-deceptive speech, collected from native speakers of Standard American English and Mandarin Chinese, all speaking English, to investigate acoustic, prosodic, and lexical cues to deception. We report first on the role of personality factors derived from the NEO-FFI (Neuroticism-Extraversion-Openness Five Factor Inventory) and of gender, ethnicity and confidence ratings on subjects? ability to deceive and to detect deception. We then present classification results discriminating deceptive from non-deceptive speech, using these features as well as acoustic and prosodic cues. We find that combining acoustic and prosodic features with information about the speaker?s personality, gender, and language results in a classification accuracy of 65.86%, which represents ~10% relative improvement from baseline accuracy.},
booktitle = {Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection},
pages = {1–8},
numpages = {8},
keywords = {american english, speech analysis, mandarin chinese, deception detection, cross-cultural},
location = {Seattle, Washington, USA},
series = {WMDD '15}
}

@inproceedings{10.1145/3287560.3287590,
author = {Lai, Vivian and Tan, Chenhao},
title = {On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection},
year = {2019},
isbn = {9781450361255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3287560.3287590},
doi = {10.1145/3287560.3287590},
abstract = {Humans are the final decision makers in critical tasks that involve ethical and legal concerns, ranging from recidivism prediction, to medical diagnosis, to fighting against fake news. Although machine learning models can sometimes achieve impressive performance in these tasks, these tasks are not amenable to full automation. To realize the potential of machine learning for improving human decisions, it is important to understand how assistance from machine learning models affects human performance and human agency.In this paper, we use deception detection as a testbed and investigate how we can harness explanations and predictions of machine learning models to improve human performance while retaining human agency. We propose a spectrum between full human agency and full automation, and develop varying levels of machine assistance along the spectrum that gradually increase the influence of machine predictions. We find that without showing predicted labels, explanations alone slightly improve human performance in the end task. In comparison, human performance is greatly improved by showing predicted labels (&gt;20% relative improvement) and can be further improved by explicitly suggesting strong machine performance. Interestingly, when predicted labels are shown, explanations of machine predictions induce a similar level of accuracy as an explicit statement of strong machine performance. Our results demonstrate a tradeoff between human performance and human agency and show that explanations of machine predictions can moderate this tradeoff.},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {29–38},
numpages = {10},
keywords = {human agency, human performance, explanations, predictions},
location = {Atlanta, GA, USA},
series = {FAT* '19}
}

@inproceedings{10.1145/2823465.2823469,
author = {Radlak, Krystian and Bozek, Maciej and Smolka, Bogdan},
title = {Silesian Deception Database: Presentation and Analysis},
year = {2015},
isbn = {9781450339872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2823465.2823469},
doi = {10.1145/2823465.2823469},
abstract = {Numerous studies have examined behavioral cues to deception with low temporal video resolution, which does not enable to track the facial movements dynamics. Another problem is the lack of publicly available video databases that allow to develop computer vision algorithms dedicated to the automatic deception recognition. In this paper, we describe a novel publicly available database that consists of 101 video recordings acquired with the use of a high speed camera at 100 fps in a well-controlled laboratory environment and proper illumination. Within this database, over 1.1 million frames were coded providing the ground truth for the potential cues of deception displayed on the subject's face during telling the truth and lying. Some preliminary psychological implications are also presented.},
booktitle = {Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection},
pages = {29–35},
numpages = {7},
keywords = {face analysis, deception detection, cognitive load, silesian deception database},
location = {Seattle, Washington, USA},
series = {WMDD '15}
}

@inproceedings{10.1145/2823465.2823470,
author = {Abouelenien, Mohamed and Mihalcea, Rada and Burzo, Mihai},
title = {Trimodal Analysis of Deceptive Behavior},
year = {2015},
isbn = {9781450339872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2823465.2823470},
doi = {10.1145/2823465.2823470},
abstract = {The need arises for developing a more reliable deception detection system to address the shortcomings of the traditional polygraph tests and the dependability on physiological indicators of deceit. This paper describes a new deception detection dataset, provides a novel comparison between three modalities to identify deception including the visual, thermal, and physiological domains, and analyzes whether certain facial areas are more capable of indicating deceit. Our experimental results show a promising performance especially with the thermal modality, and provide guidelines for our data collection process and future work.},
booktitle = {Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection},
pages = {9–13},
numpages = {5},
keywords = {physiological, thermal, deception, visual, trimodal},
location = {Seattle, Washington, USA},
series = {WMDD '15}
}

@inproceedings{10.1145/2823465.2823467,
author = {Chen, Yimin and Conroy, Niall J. and Rubin, Victoria L.},
title = {Misleading Online Content: Recognizing Clickbait as "False News"},
year = {2015},
isbn = {9781450339872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2823465.2823467},
doi = {10.1145/2823465.2823467},
abstract = {Tabloid journalism is often criticized for its propensity for exaggeration, sensationalization, scare-mongering, and otherwise producing misleading and low quality news. As the news has moved online, a new form of tabloidization has emerged: ?clickbaiting.? ?Clickbait? refers to ?content whose main purpose is to attract attention and encourage visitors to click on a link to a particular web page? [?clickbait,? n.d.] and has been implicated in the rapid spread of rumor and misinformation online. This paper examines potential methods for the automatic detection of clickbait as a form of deception. Methods for recognizing both textual and non-textual clickbaiting cues are surveyed, leading to the suggestion that a hybrid approach may yield best results.},
booktitle = {Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection},
pages = {15–19},
numpages = {5},
keywords = {reliability, clickbait, standardization, human factors, news verification, reader behavior, automated deception detection},
location = {Seattle, Washington, USA},
series = {WMDD '15}
}

@inproceedings{10.5555/2388616.2388631,
author = {Rubin, Victoria L. and Vashchilko, Tatiana},
title = {Identification of Truth and Deception in Text: Application of Vector Space Model to Rhetorical Structure Theory},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {The paper proposes to use Rhetorical Structure Theory (RST) analytic framework to identify systematic differences between deceptive and truthful stories in terms of their coherence and structure. A sample of 36 elicited personal stories, self-ranked as completely truthful or completely deceptive, is manually analyzed by assigning RST discourse relations among a story's constituent parts. Vector Space Model (VSM) assesses each story's position in multi-dimensional RST space with respect to its distance to truth and deceptive centers as measures of the story's level of deception and truthfulness. Ten human judges evaluate if each story is deceptive or not, and assign their confidence levels, which produce measures of the human expected deception and truthfulness levels. The paper contributes to deception detection research and RST twofold: a) demonstration of discourse structure analysis in pragmatics as a prominent way of automated deception detection and, as such, an effective complement to lexico-semantic analysis, and b) development of RST-VSM methodology to interpret RST analysis in identification of previously unseen deceptive texts.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {97–106},
numpages = {10},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388624,
author = {Elkins, Aaron C. and Derrick, Douglas C. and Gariup, Monica},
title = {The Voice and Eye Gaze Behavior of an Imposter: Automated Interviewing and Detection for Rapid Screening at the Border},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Contextual differences present significant challenges when developing computational methods for detecting deception. We conducted a field experiment with border guards from the European Union in order to demonstrate that deception detection can be done robustly using context specific computational models. In the study, some of the participants were given a "fraudulent" document with incorrect data and asked to pass through a checkpoint. An automated system used an embodied conversational agent (ECA) to conduct interviews. Based on the participants' vocalic and ocular behavior our specific model classified 100% of the imposters while limiting false positive errors. The overall accuracy was 94.47%.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {49–54},
numpages = {6},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388620,
author = {Gokhman, Stephanie and Hancock, Jeff and Prabhu, Poornima and Ott, Myle and Cardie, Claire},
title = {In Search of a Gold Standard in Studies of Deception},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {In this study, we explore several popular techniques for obtaining corpora for deception research. Through a survey of traditional as well as non-gold standard creation approaches, we identify advantages and limitations of these techniques for web-based deception detection and offer crowd-sourcing as a novel avenue toward achieving a gold standard corpus. Through an in-depth case study of online hotel reviews, we demonstrate the implementation of this crowdsourcing technique and illustrate its applicability to a broad array of online reviews.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {23–30},
numpages = {8},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.1145/3242969.3242993,
author = {Ondras, Jan and Gunes, Hatice},
title = {Detecting Deception and Suspicion in Dyadic Game Interactions},
year = {2018},
isbn = {9781450356923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3242969.3242993},
doi = {10.1145/3242969.3242993},
abstract = {In this paper we focus on detection of deception and suspicion from electrodermal activity (EDA) measured on left and right wrists during a dyadic game interaction. We aim to answer three research questions: (i) Is it possible to reliably distinguish deception from truth based on EDA measurements during a dyadic game interaction? (ii) Is it possible to reliably distinguish the state of suspicion from trust based on EDA measurements during a card game? (iii) What is the relative importance of EDA measured on left and right wrists? To answer our research questions we conducted a study in which 20 participants were playing the game Cheat in pairs with one EDA sensor placed on each of their wrists. Our experimental results show that EDA measures from left and right wrists provide more information for suspicion detection than for deception detection and that the person-dependent detection is more reliable than the person-independent detection. In particular, classifying the EDA signal with Support Vector Machine (SVM) yields accuracies of 52% and 57% for person-independent prediction of deception and suspicion respectively, and 63% and 76% for person-dependent prediction of deception and suspicion respectively. Also, we found that: (i) the optimal interval of informative EDA signal for deception detection is about 1 s while it is around 3.5 s for suspicion detection; (ii) the EDA signal relevant for deception/suspicion detection can be captured after around 3.0 seconds after a stimulus occurrence regardless of the stimulus type (deception/truthfulness/suspicion/trust); and that (iii) features extracted from EDA from both wrists are important for classification of both deception and suspicion. To the best of our knowledge, this is the first work that uses EDA data to automatically detect both deception and suspicion in a dyadic game interaction setting.},
booktitle = {Proceedings of the 20th ACM International Conference on Multimodal Interaction},
pages = {200–209},
numpages = {10},
keywords = {deception detection, dyadic game interactions, electrodermal activity, suspicion detection, affective computing},
location = {Boulder, CO, USA},
series = {ICMI '18}
}

@article{10.1145/2499962.2499967,
author = {Derrick, Douglas C. and Meservy, Thomas O. and Jenkins, Jeffrey L. and Burgoon, Judee K. and Nunamaker, Jay F.},
title = {Detecting Deceptive Chat-Based Communication Using Typing Behavior and Message Cues},
year = {2013},
issue_date = {August 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {2158-656X},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2499962.2499967},
doi = {10.1145/2499962.2499967},
abstract = {Computer-mediated deception is prevalent and may have serious consequences for individuals, organizations, and society. This article investigates several metrics as predictors of deception in synchronous chat-based environments, where participants must often spontaneously formulate deceptive responses. Based on cognitive load theory, we hypothesize that deception influences response time, word count, lexical diversity, and the number of times a chat message is edited. Using a custom chatbot to conduct interviews in an experiment, we collected 1,572 deceitful and 1,590 truthful chat-based responses. The results of the experiment confirm that deception is positively correlated with response time and the number of edits and negatively correlated to word count. Contrary to our prediction, we found that deception is not significantly correlated with lexical diversity. Furthermore, the age of the participant moderates the influence of deception on response time. Our results have implications for understanding deceit in chat-based communication and building deception-detection decision aids in chat-based systems.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = aug,
articleno = {9},
numpages = {21},
keywords = {Decision support system, chat, deception detection, typing bahavior}
}

@inproceedings{10.5555/2388616.2388619,
author = {Almela, \'{A}ngela and Valencia-Garc\'{\i}a, Rafael and Cantos, Pascual},
title = {Seeing through Deception: A Computational Approach to Deceit Detection in Written Communication},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {The present paper addresses the question of the nature of deception language. Specifically, the main aim of this piece of research is the exploration of deceit in Spanish written communication. We have designed an automatic classifier based on Support Vector Machines (SVM) for the identification of deception in an ad hoc opinion corpus. In order to test the effectiveness of the LIWC2001 categories in Spanish, we have drawn a comparison with a Bag-of-Words (BoW) model. The results indicate that the classification of the texts is more successful by means of our initial set of variables than with the latter system. These findings are potentially applicable to areas such as forensic linguistics and opinion mining, where extensive research on languages other than English is needed.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {15–22},
numpages = {8},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388617,
author = {Hauch, Valerie and Masip, Jaume and Bland\'{o}n-Gitlin, Iris and Sporer, Siegfried L.},
title = {Linguistic Cues to Deception Assessed by Computer Programs: A Meta-Analysis},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Research syntheses suggest that verbal cues are more diagnostic of deception than other cues. Recently, to avoid human judgmental biases, researchers have sought to find faster and more reliable methods to perform automatic content analyses of statements. However, diversity of methods and inconsistent findings do not present a clear picture of effectiveness. We integrate and statistically synthesize this literature. Our meta-analyses revealed small, but significant effect-sizes on some linguistic categories. Liars use fewer exclusive words, self- and other-references, fewer time-related, but more space-related, negative and positive emotion words, and more motion verbs or negations than truth-tellers.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {1–4},
numpages = {4},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388628,
author = {Sporer, Siegfried L.},
title = {Making the Subjective Objective? Computer-Assisted Quantification of Qualitative Content Cues to Deception},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Research syntheses suggest that verbal content cues are more diagnostic than other cues in discriminating between truth and deception. In many studies on content cues, raters are trained to rate the presence of specific content cues, an inherently subjective process. This necessitates to demonstrate inter-coder reliability first. Depending on the statistical coefficient used, establishing adequate inter-rater reliabilities for these subjective judgments often creates a problem. To address some of these problems, a new method for coding these content cues with a computer program developed for qualitative research, MaxQDA (www.maxqda.de), is proprosed. The application of the program is demonstrated using the Aberdeen Report Judgment Scales (ARJS; Sporer, 2004) with a set of 72 deceptive and true accounts of a driving examination. Data on different types of inter-coder reliabilities are presented and implications for future research with computer-assisted qualitative coding procedures as well as training of coders are outlined.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {78–85},
numpages = {8},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.1145/2522848.2522888,
author = {Mihalcea, Rada and P\'{e}rez-Rosas, Ver\'{o}nica and Burzo, Mihai},
title = {Automatic Detection of Deceit in Verbal Communication},
year = {2013},
isbn = {9781450321297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2522848.2522888},
doi = {10.1145/2522848.2522888},
abstract = {This paper presents experiments in building a classifier for the automatic detection of deceit. Using a dataset of deceptive videos, we run several comparative evaluations focusing on the verbal component of these videos, with the goal of understanding the difference in deceit detection when using manual versus automatic transcriptions, as well as the difference between spoken and written lies. We show that using only the linguistic component of the deceptive videos, we can detect deception with accuracies in the range of 52-73%.},
booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
pages = {131–134},
numpages = {4},
keywords = {speech transcription, deception detection, crowdsourcing},
location = {Sydney, Australia},
series = {ICMI '13}
}

@inproceedings{10.5555/2388616.2388618,
author = {Vartapetiance, Anna and Gillam, Lee},
title = {"I Don't Know Where He is Not": Does Deception Research yet Offer a Basis for Deception Detectives?},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Suppose we wanted to create an intelligent machine that somehow drew its intelligence from large collections of text, possibly involving the processing of collections available on the Web such as Wikipedia. Does past research in deception offer a sufficiently robust basis upon which we might develop a means to filter out texts that are deceptive, either partially or entirely? Could we identify, for example, any deliberately deceptive edits to Wikipedia without consulting the edit history? In this paper, we offer a critical review of deception research. We suggest that there are a range of inconsistencies, contradictions, and other difficulties in recent deception research, and identify how we might begin to address deception research in a more systematic manner.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {5–14},
numpages = {10},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388625,
author = {Swerts, Marc},
title = {Let's Lie Together: Co-Presence Effects on Children's Deceptive Skills},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {A person's expressive behavior is different in situations where he or she is alone, or where an additional person is present. This study looks at the extent to which such physical co-presence effects have an impact on a child's ability to deceive. Using an experimental digitized puppet show, truthful and deceptive utterances were elicited from children who were interacting with two story characters. The children were sitting alone, or as a couple together with another child. A first perception study in which minimal pairs of truthful and deceptive utterances were shown (vision-only) to adult observers revealed that the correct detection of deceptive utterances is dependent on whether the stimuli were produced by a child alone or together with another child (both being visible). A second perception study presented participants with videos from children of the couples condition that were edited so that only one child was visible. The study revealed that the deceptive utterances could more often be detected correctly in the more talkative children than in the more passive ones.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {55–62},
numpages = {8},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388622,
author = {Fornaciari, Tommaso and Poesio, Massimo},
title = {On the Use of Homogenous Sets of Subjects in Deceptive Language Analysis},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Recent studies on deceptive language suggest that machine learning algorithms can be employed with good results for classification of texts as truthful or untruthful. However, the models presented so far do not attempt to take advantage of the differences between subjects. In this paper, models have been trained in order to classify statements issued in Court as false or not-false, not only taking into consideration the whole corpus, but also by identifying more homogenous subsets of producers of deceptive language. The results suggest that the models are effective in recognizing false statements, and their performance can be improved if subsets of homogeneous data are provided.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {39–47},
numpages = {9},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.1145/3098954.3104047,
author = {Monaro, Merylin and Spolaor, Riccardo and Li, QianQian and Conti, Mauro and Gamberini, Luciano and Sartori, Giuseppe},
title = {Type Me the Truth! Detecting Deceitful Users via Keystroke Dynamics},
year = {2017},
isbn = {9781450352574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3098954.3104047},
doi = {10.1145/3098954.3104047},
abstract = {In this paper, we propose a novel method, based on keystroke dynamics, to distinguish between fake and truthful personal information written via a computer keyboard. Our method does not need any prior knowledge about the user who is providing data. To our knowledge, this is the first work that associates the typing human behavior with the production of lies regarding personal information. Via experimental analysis involving 190 subjects, we assess that this method is able to distinguish between truth and lies on specific types of autobiographical information, with an accuracy higher than 75%. Specifically, for information usually required in online registration forms (e.g., name, surname and email), the typing behavior diverged significantly between truthful or untruthful answers. According to our results, keystroke analysis could have a great potential in detecting the veracity of self-declared information, and it could be applied to a large number of practical scenarios requiring users to input personal data remotely via keyboard.},
booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
articleno = {60},
numpages = {6},
keywords = {keyboard interaction, cybersecurity, Lie detection, keystroke dynamics, fake accounts},
location = {Reggio Calabria, Italy},
series = {ARES '17}
}

@inproceedings{10.5555/2388616.2388621,
author = {Fitzpatrick, Eileen and Bachenko, Joan},
title = {Building a Data Collection for Deception Research},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Research in high stakes deception has been held back by the sparsity of ground truth verification for data collected from real world sources. We describe a set of guidelines for acquiring and developing corpora that will enable researchers to build and test models of deceptive narrative while avoiding the problem of sanctioned lying that is typically required in a controlled experiment. Our proposals are drawn from our experience in obtaining data from court cases and other testimony, and uncovering the background information that enabled us to annotate claims made in the narratives as true or false.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {31–38},
numpages = {8},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.1145/3345336.3345337,
author = {Borj, Parisa Rezaee and Bours, Patrick},
title = {Detecting Liars in Chats Using Keystroke Dynamics},
year = {2019},
isbn = {9781450363051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3345336.3345337},
doi = {10.1145/3345336.3345337},
abstract = {In this paper we will investigate the possibilities for detecting liars in chat rooms who have taken on a different identity. While using a different identity people might require more time to reply to questions of the chat partner, or might use corrections to change their text to avoid inconsistencies in their answers. These issues will cause differences in the typing behavior, which can be measured in the typing rhythm. We have shown in this paper that, with a high accuracy, we can distinguish between a chat of a person who uses his/her own identity and is honest in his/her answers, and a chat of a person who is lying because his/her answers need to be consistent to an assumed identity. We obtained a correct classification of a single message in a chat with an accuracy of more than 70% and a correct classification of a full chat with well over 90% accuracy.},
booktitle = {Proceedings of the 2019 3rd International Conference on Biometric Engineering and Applications},
pages = {1–6},
numpages = {6},
keywords = {Keystroke dynamics, Chat room, Liars, Deception detection, Typing rhythm},
location = {Stockholm, Sweden},
series = {ICBEA 2019}
}

@inproceedings{10.5555/2388616.2388630,
author = {Juola, Patrick},
title = {Detecting Stylistic Deception},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Whistleblowers and activists need the ability to communicate without disclosing their identity, as of course do kidnappers and terrorists. Recent advances in the technology of stylometry (the study of authorial style) or "authorship attribution" have made it possible to identify the author with high reliability in a non-confrontational setting. In a confrontational setting, where the author is deliberately masking their identity (i.e. attempting to deceive), the results are much less promising. In this paper, we show that although the specific author may not be identifiable, the intent to deceive and to hide his identity can be. We show this by a reanalysis of the Brennan and Greenstadt (2009) deception corpus and discuss some of the implications of this surprising finding.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {91–96},
numpages = {6},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388627,
author = {Dinu, Liviu P. and Niculae, Vlad and \c{S}ulea, Octavia-Maria},
title = {Pastiche Detection Based on Stopword Rankings: Exposing Impersonators of a Romanian Writer},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We applied hierarchical clustering using Rank distance, previously used in computational stylometry, on literary texts written by Mateiu Caragiale and a number of different authors who attempted to impersonate Caragiale after his death, or simply to mimic his style. Their pastiches were consistently clustered opposite to the original work, thereby confirming the performance of the method and proposing an extension of the method from simple authorship attribution to the more complicated problem of pastiche detection.The novelty of our work is the use of frequency rankings of stopwords as features, showing that this idea yields good results for pastiche detection.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {72–77},
numpages = {6},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.5555/2388616.2388629,
author = {Bogdanova, Dasha and Rosso, Paolo and Solorio, Thamar},
title = {Modelling Fixated Discourse in Chats with Cyberpedophiles},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {The ability to detect deceptive statements in predatory communications can help in the identification of sexual predators, a type of deception that is recently attracting the attention of the research community. Due to the intention of a pedophile of hiding his/her true identity (name, age, gender and location) its detection is a challenge. According to previous research, fixated discourse is one of the main characteristics inherent to the language of online sexual predation. In this paper we approach this problem by computing sex-related lexical chains spanning over the conversation. Our study shows a considerable variation in the length of sex-related lexical chains according to the nature of the corpus, which supports our belief that this could be a valuable feature in an automated pedophile detection system.},
booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
pages = {86–90},
numpages = {5},
location = {Avignon, France},
series = {EACL 2012}
}

@inproceedings{10.1145/2535948.2535954,
author = {Lim, Kai Keat and Friedrich, Max and Radun, Jenni and Jokinen, Kristiina},
title = {Lying through the Eyes: Detecting Lies through Eye Movements},
year = {2013},
isbn = {9781450325639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2535948.2535954},
doi = {10.1145/2535948.2535954},
abstract = {In this pilot study, we investigated if it is possible to detect lies through eye gaze behavior. Earlier research suggests that lying increases the cognitive load, resulting in less eye -movements and shorter saccade amplitudes. To investigate these findings further, a structured interview was conducted with three subjects. During the interview, subjects were supposed to lie in half of their answers. The subjects' eye gazes were tracked during the interview session. We hypothesized that people show shorter saccade amplitudes and tend to engage in less eye movements when lying. A significant difference could be observed for saccade amplitudes between the truth telling and lie telling situations. The overall results support the theory that cognitive load decreases the number of eye movements, but our analysis also revealed significant individual differences. This raised the question whether different individuals have different ways of handling deception and whether different viewing behavior patterns could be found for different groups of individuals.},
booktitle = {Proceedings of the 6th Workshop on Eye Gaze in Intelligent Human Machine Interaction: Gaze in Multimodal Interaction},
pages = {51–56},
numpages = {6},
keywords = {lie detection, eye tracking},
location = {Sydney, Australia},
series = {GazeIn '13}
}

@inproceedings{10.5555/3191835.3191912,
author = {Alowibdi, Jalal S. and Buy, Ugo A. and Yu, Philip S. and Stenneth, Leon},
title = {Detecting Deception in Online Social Networks},
year = {2014},
isbn = {9781479958764},
publisher = {IEEE Press},
abstract = {Over the past decade Online Social Networks (OSNs) have been helping hundreds of millions of people develop reliable computer-mediated relations. However, many user profiles in OSNs contain misleading, inconsistent or false information. Existing studies have shown that lying in OSNs is quite widespread, often for protecting a user's privacy. In order for OSNs to continue expanding their role as a communication medium in our society, it is crucial for information posted on OSNs to be trusted. Here we define a set of analysis methods for detecting deceptive information about user genders in Twitter. In addition, we report empirical results with our stratified data set consisting of 174,600 Twitter profiles with a 50--50 breakdown between male and female users.Our automated approach compares gender indicators obtained from different profile characteristics including first name, user name, and layout colors. We establish the overall accuracy of each indicator and the strength of all possible values for each indicator through extensive experimentations with our data set. We define male trending users and female trending users based on two factors, namely the overall accuracy of each characteristic and the relative strength of the value of each characteristic for a given user. We apply a Bayesian classifier to the weighted average of characteristics for each user. We flag for possible deception profiles that we classify as male or female in contrast with a self-declared gender that we obtain independently of Twitter profiles. Finally, we use manual inspections on a subset of profiles that we identify as potentially deceptive in order to verify the correctness of our predictions.},
booktitle = {Proceedings of the 2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {383–390},
numpages = {8},
keywords = {gender classification, Twitter, profile characteristics, deception detection},
location = {Beijing, China},
series = {ASONAM '14}
}

@inproceedings{10.1145/3313831.3376873,
author = {Lai, Vivian and Liu, Han and Tan, Chenhao},
title = {"Why is 'Chicago' Deceptive?" Towards Building Model-Driven Tutorials for Humans},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3313831.3376873},
doi = {10.1145/3313831.3376873},
abstract = {To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a train- ing phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tutorials, explanations, interpretable machine learning, deception detection},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/2070481.2070515,
author = {Raiman, Nimrod and Hung, Hayley and Englebienne, Gwenn},
title = {Move, and i Will Tell You Who You Are: Detecting Deceptive Roles in Low-Quality Data},
year = {2011},
isbn = {9781450306416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2070481.2070515},
doi = {10.1145/2070481.2070515},
abstract = {Motion, like speech, provides information about one's emotional state. This work introduces an automated non-verbal audio-visual approach for detecting deceptive roles in multi-party conversations using low resolution video. We show how using simple features extracted from motion and speech improves over speech-only for the detection of deceptive roles. Our results show that deceptive players were recognised with significantly higher precision when video features were used. We improve the classification performance with 22.6% compared to our baseline.},
booktitle = {Proceedings of the 13th International Conference on Multimodal Interfaces},
pages = {201–204},
numpages = {4},
keywords = {deception detection, multi-party conversation, human behavior},
location = {Alicante, Spain},
series = {ICMI '11}
}

@inproceedings{10.1145/3184558.3186567,
author = {Azevedo, Lucas},
title = {Truth or Lie: Automatically Fact Checking News},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3184558.3186567},
doi = {10.1145/3184558.3186567},
abstract = {In the actual scenario of ever-growing data consumption speed and quantity, factors like news source decentralization, citizen journalism and democratization of media, make the task of manually checking and correcting disinformation across the internet impractical or infeasible . Here, there is an imperative need for a fast and reliable way to account for the veracity of what is produced and spread as information: Automatic fact-checking. In this work we present the problem of fact-checking in the era of big data and post-truth. Some existing approaches for this task are presented and their main features discussed and compared. Concluding, a new approach inspired on the best components of the existing ones is presented.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {807–811},
numpages = {5},
keywords = {deception detection, natural language processing, automatic fact-checking},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3322645.3322688,
author = {Tarmizi, Fatin Amanina Ahmad and Tan, Phan Xuan and Sharif, Khaironi Yatim and Kamioka, Eiji},
title = {Online News Veracity Assessment Using Emotional Weight},
year = {2019},
isbn = {9781450361033},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3322645.3322688},
doi = {10.1145/3322645.3322688},
abstract = {Trillions of data are being created every day on the Internet due to the growing number of social platforms on the World Wide Web (WWW). Processed data when given in context makes information of any knowledge. However, irresponsible use of the data or misinterpretation of data could be the reasons for false information dissemination. Many researchers from various fields, such as computer science and social science, draw their focus on assessing the veracity of information. There are many techniques to perceive this topic, for instance, social network behaviour, and semantic analysis. The common practice is using semantic analysis approach, where the syntactic structure is analysed and polarity of the texts is determined. In this paper, we approach the veracity assessment by using emotion analysis. We identified emotional states conveyed in news content and calculated the weight of each state in each news content. Contrary to popular belief, our finding showed that emotional, or affective states conveyed in false news are varied - positive and negative states. The distinct feature is the weight of the states in news content. Using multi-layer perceptron, we classified the news and achieved 90% accuracy with our collected dataset and 85% using LIAR dataset.},
booktitle = {Proceedings of the 2019 2nd International Conference on Information Science and Systems},
pages = {60–64},
numpages = {5},
keywords = {Veracity assessment, text analysis, deception detection, affective science, emotion analysis},
location = {Tokyo, Japan},
series = {ICISS 2019}
}

@article{10.1145/3161178,
author = {Sen, Taylan and Hasan, Md Kamrul and Teicher, Zach and Hoque, Mohammed Ehsan},
title = {Automated Dyadic Data Recorder (ADDR) Framework and Analysis of Facial Cues in Deceptive Communication},
year = {2018},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3161178},
doi = {10.1145/3161178},
abstract = {We developed an online framework that can automatically pair two crowd-sourced participants, prompt them to follow a research protocol, and record their audio and video on a remote server. The framework comprises two web applications: an Automatic Quality Gatekeeper for ensuring only high quality crowd-sourced participants are recruited for the study, and a Session Controller which directs participants to play a research protocol, such as an interrogation game. This framework was used to run a research study for analyzing facial expressions during honest and deceptive communication using a novel interrogation protocol. The protocol gathers two sets of nonverbal facial cues in participants: features expressed during questions relating to the interrogation topic and features expressed during control questions. The framework and protocol were used to gather 151 dyadic conversations (1.3 million video frames). Interrogators who were lied to expressed the smile-related lip corner puller cue more often than interrogators who were being told the truth, suggesting that facial cues from interrogators may be useful in evaluating the honesty of witnesses in some contexts. Overall, these results demonstrate that this framework is capable of gathering high quality data which can identify statistically significant results in a communication study.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {163},
numpages = {22},
keywords = {web framework, facial expression analysis, video conferencing, Deception detection, interrogation}
}

@inproceedings{10.1145/3308560.3316604,
author = {Pisarevskaya, Dina and Galitsky, Boris and Taylor, Jay and Ozerov, Andrey},
title = {An Anatomy of a Lie:},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3308560.3316604},
doi = {10.1145/3308560.3316604},
abstract = {Automated detection of text with misrepresentations such as fake reviews is an important task for online reputation management. The dataset of customer complaints - emotionally charged texts which are very similar to reviews and include descriptions of problems customers experienced with certain businesses – is presented. It contains 2746 complaints about banks and provides clear ground truth, based on available factual knowledge about the financial domain. Among them, 400 texts were manually tagged. Initial experiments were performed in order to explore the links between implicit cues of the rhetoric structure of texts and the validity of arguments, and also how truthful/deceptive are these texts.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {373–380},
numpages = {8},
keywords = {Fake Reviews, Rhetorical Structure Theory, Discourse Analysis, Deception Detection, Customer Complaints},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2993148.2997624,
author = {Radlak, Krystian and Smolka, Bogdan},
title = {Automated Recognition of Facial Expressions Authenticity},
year = {2016},
isbn = {9781450345569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2993148.2997624},
doi = {10.1145/2993148.2997624},
abstract = { Recognition of facial expressions authenticity is quite troublesome for humans. Therefore, it is an interesting topic for the computer vision community, as the developed algorithms for facial expressions authenticity estimation may be used as indicators of deception. This paper discusses the state-of-the art methods developed for smile veracity estimation and proposes a plan of development and validation of a novel approach to automated discrimination between genuine and posed facial expressions. The proposed fully automated technique is based on the extension of the high-dimensional Local Binary Patterns (LBP) to the spatio-temporal domain and combines them with the dynamics of facial landmarks movements. The proposed technique will be validated on several existing smile databases and a novel database created with the use of a high speed camera. Finally, the developed framework will be applied for the detection of deception in real life scenarios. },
booktitle = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
pages = {577–581},
numpages = {5},
keywords = {facial expressions spontaneity, facial expressions recognition, human-computer interaction, smile genuineness, deception detection},
location = {Tokyo, Japan},
series = {ICMI '16}
}

@inproceedings{10.1145/2212776.2223786,
author = {Tawari, Ashish and Tran, Cuong and Doshi, Anup and Zander, Thorsten and Trivedi, Mohan},
title = {Distributed Multisensory Signals Acquisition and Analysis in Dyadic Interactions},
year = {2012},
isbn = {9781450310161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2212776.2223786},
doi = {10.1145/2212776.2223786},
abstract = {Human-machine interaction could be enhanced by providing information about the user's state, allowing for automated adaption of the system. Such context-aware system, however, should be able to deal with spontaneous and subtle user behavior. The artificial intelligence behind such systems, hence, also needs to deal with spontaneous behavior data for training as well as evaluation. Although harder to collect and annotate, spontaneous behavior data are preferable to posed as they are representative of real world behavior. Towards this end, we have designed a distributed testbed for multisensory signals acquisition while facilitating spontaneous interactions. We recorded audio-visual as well as physiological signals from 6 pairs of subjects while they were playing a bluffing dice game against each other. In this paper, we introduce the collected database and provide our preliminary results of bluff detection based on spatio-temporal face image signal analysis.},
booktitle = {CHI '12 Extended Abstracts on Human Factors in Computing Systems},
pages = {2261–2266},
numpages = {6},
keywords = {multimodal database, facial expression analysis, emotion recognition, deception detection},
location = {Austin, Texas, USA},
series = {CHI EA '12}
}

@inproceedings{10.1145/3371382.3378253,
author = {Pasquali, Dario and Aroyo, Alexander Mois and Gonzalez-Billandon, Jonas and Rea, Francesco and Sandini, Giulio and Sciutti, Alessandra},
title = {Your Eyes Never Lie: A Robot Magician Can Tell If You Are Lying},
year = {2020},
isbn = {9781450370578},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3371382.3378253},
doi = {10.1145/3371382.3378253},
abstract = {Detecting lies in a real-world scenario is an important skill for a humanoid robot that aims to act as a teacher, a therapist, or a caregiver. In these contexts, it is essential to detect lies while preserving the pleasantness of the social interaction and the informality of the relation. This study investigates whether pupil dilation related to an increase in cognitive load can be used to swiftly identify a lie in an entertaining scenario. The iCub humanoid robot plays the role of a magician in a card game, telling which card the human partner is lying about. The results show a greater pupil dilation in presence of a false statement even if in front of a robot and without the need of a strictly controlled scenario. We developed a heuristic method (accuracy of 71.4% against 16.6% chance level) and a random forest classifier (precision and recall of 83.3%) to detect the false statement. Additionally, the current work suggests a potential method to assess the lying strategy of the partner.},
booktitle = {Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {392–394},
numpages = {3},
keywords = {human-robot interaction, lie detection, humanoid robot, pupillometry, machine learning},
location = {Cambridge, United Kingdom},
series = {HRI '20}
}

@article{10.1145/1805286.1805289,
author = {Jensen, Matthew L. and Burgoon, Judee K. and Nunamaker, Jay F.},
title = {Judging the Credibility of Information Gathered from Face-to-Face Interactions},
year = {2010},
issue_date = {July 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {1936-1955},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/1805286.1805289},
doi = {10.1145/1805286.1805289},
abstract = {One of the most pernicious threats to information quality comes through perpetration of deception by information suppliers. Deception undermines many critical dimensions of information quality, such as accuracy, completeness, and believability. Despite this threat, information gatherers are ill equipped to assess the credibility of information suppliers. This work presents a prototype system that examines messages gathered during direct, face-to-face information gathering. The system unobtrusively identifies kinesic and linguistic features that may indicate deception in information suppliers’ messages. System use was found to significantly improve assessment ability in between-subjects and within-subjects tests. The improved ability to accurately assess credibility during face-to-face interactions should yield higher information quality.},
journal = {J. Data and Information Quality},
month = jul,
articleno = {3},
numpages = {20},
keywords = {information veracity, linguistics, human-computer interaction, kinesics, Credibility assessment, decision-aids, deception detection}
}

@inproceedings{10.1145/3382507.3421166,
author = {Levitan, Sarah Ita and Tan, Xinyue and Hirschberg, Julia},
title = {LieCatcher: Game Framework for Collecting Human Judgments of Deceptive Speech},
year = {2020},
isbn = {9781450375818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3382507.3421166},
doi = {10.1145/3382507.3421166},
abstract = {Humans are notoriously poor at detecting deception --- most are worse than chance. To address this issue we have developed LieCatcher, a single-player web-based Game With A Purpose (GWAP) that allows players to assess their lie detection skills while providing human judgments of deceptive speech. Players listen to audio recordings drawn from a corpus of deceptive and non-deceptive interview dialogues, and guess if the speaker is lying or telling the truth. They are awarded points for correct guesses and at the end of the game they receive a score summarizing their performance at lie detection. We present the game design and implementation, and describe a crowdsourcing experiment conducted to study perceived deception.},
booktitle = {Proceedings of the 2020 International Conference on Multimodal Interaction},
pages = {762–763},
numpages = {2},
keywords = {games with a purpose, trust, deception, speech annotation},
location = {Virtual Event, Netherlands},
series = {ICMI '20}
}

@inproceedings{10.5555/2857070.2857151,
author = {Chen, Yimin and Conroy, Niall J. and Rubin, Victoria L.},
title = {News in an Online World: The Need for an "Automatic Crap Detector"},
year = {2015},
isbn = {087715547X},
publisher = {American Society for Information Science},
address = {USA},
abstract = {Widespread adoption of internet technologies has changed the way that news is created and consumed. The current online news environment is one that incentivizes speed and spectacle in reporting, at the cost of fact-checking and verification. The line between user generated content and traditional news has also become increasingly blurred. This poster reviews some of the professional and cultural issues surrounding online news and argues for a two-pronged approach inspired by Hemingway's "automatic crap detector" (Manning, 1965) in order to address these problems: a) proactive public engagement by educators, librarians, and information specialists to promote digital literacy practices; b) the development of automated tools and technologies to assist journalists in vetting, verifying, and fact-checking, and to assist news readers by filtering and flagging dubious information.},
booktitle = {Proceedings of the 78th ASIS&amp;T Annual Meeting: Information Science with Impact: Research in and for the Community},
articleno = {81},
numpages = {4},
keywords = {natural language processing, journalism practices, deception detection, online news, credibility assessment, news verification, fake news detection, media commercialization},
location = {St. Louis, Missouri},
series = {ASIST '15}
}

@inproceedings{10.1145/2818346.2820745,
author = {Demyanov, Sergey and Bailey, James and Ramamohanarao, Kotagiri and Leckie, Christopher},
title = {Detection of Deception in the Mafia Party Game},
year = {2015},
isbn = {9781450339124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2818346.2820745},
doi = {10.1145/2818346.2820745},
abstract = {The problem of deception detection is very challenging. Only trained people with specialist knowledge are able to demonstrate an accuracy that is sufficiently higher than random predictions. We present a multi-stage automatic system for extracting features from facial cues and evaluate it on the Mafia game database which we have collected. It is a large database of truthful and deceptive people, recorded in conditions more variable and realistic than many other databases of similar kind. We demonstrate that using the extracted features we are able to correctly classify instances with an average AUC (area under the ROC curve) equal to 0.61, significantly better than random predictions.},
booktitle = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
pages = {335–342},
numpages = {8},
keywords = {video processing, deception, facial cues, action units, classification},
location = {Seattle, Washington, USA},
series = {ICMI '15}
}

@article{10.1145/3395046,
author = {Zhou, Xinyi and Zafarani, Reza},
title = {A Survey of Fake News: Fundamental Theories, Detection Methods, and Opportunities},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3395046},
doi = {10.1145/3395046},
abstract = {The explosive growth in fake news and its erosion to democracy, justice, and public trust has increased the demand for fake news detection and intervention. This survey reviews and evaluates methods that can detect fake news from four perspectives: the false knowledge it carries, its writing style, its propagation patterns, and the credibility of its source. The survey also highlights some potential research tasks based on the review. In particular, we identify and detail related fundamental theories across various disciplines to encourage interdisciplinary research on fake news. It is our hope that this survey can facilitate collaborative efforts among experts in computer and information sciences, social sciences, political science, and journalism to research fake news, where such efforts can lead to fake news detection that is not only efficient but, more importantly, explainable.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {109},
numpages = {40},
keywords = {social media, misinformation, fact-checking, news verification, information credibility, disinformation, Fake news, deception detection, knowledge graph}
}

@article{10.1162/coli_a_00338,
author = {Cocarascu, Oana and Toni, Francesca},
title = {Combining Deep Learning and Argumentative Reasoning for the Analysis of Social Media Textual Content Using Small Data Sets},
year = {2018},
issue_date = {December 2018},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {44},
number = {4},
issn = {0891-2017},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1162/coli_a_00338},
doi = {10.1162/coli_a_00338},
abstract = {The use of social media has become a regular habit for many and has changed the way people interact with each other. In this article, we focus on analyzing whether news headlines support tweets and whether reviews are deceptive by analyzing the interaction or the influence that these texts have on the others, thus exploiting contextual information. Concretely, we define a deep learning method for relation-based argument mining to extract argumentative relations of attack and support. We then use this method for determining whether news articles support tweets, a useful task in fact-checking settings, where determining agreement toward a statement is a useful step toward determining its truthfulness. Furthermore, we use our method for extracting bipolar argumentation frameworks from reviews to help detect whether they are deceptive. We show experimentally that our method performs well in both settings. In particular, in the case of deception detection, our method contributes a novel argumentative feature that, when used in combination with other features in standard supervised classifiers, outperforms the latter even on small data sets.},
journal = {Comput. Linguist.},
month = dec,
pages = {833–858},
numpages = {26}
}

@inproceedings{10.1145/2872427.2883087,
author = {KC, Santosh and Mukherjee, Arjun},
title = {On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp},
year = {2016},
isbn = {9781450341431},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2872427.2883087},
doi = {10.1145/2872427.2883087},
abstract = {Recently, the problem of opinion spam has been widespread and has attracted a lot of research attention. While the problem has been approached on a variety of dimensions, the temporal dynamics in which opinion spamming operates is unclear. Are there specific spamming policies that spammers employ? What kind of changes happen with respect to the dynamics to the truthful ratings on entities. How do buffered spamming operate for entities that need spamming to retain threshold popularity and reduced spamming for entities making better success? We analyze these questions in the light of time-series analysis on Yelp. Our analyses discover various temporal patterns and their relationships with the rate at which fake reviews are posted. Building on our analyses, we employ vector autoregression to predict the rate of deception across different spamming policies. Next, we explore the effect of filtered reviews on (long-term and imminent) future rating and popularity prediction of entities. Our results discover novel temporal dynamics of spamming which are intuitive, arguable and also render confidence on Yelp's filtering. Lastly, we leverage our discovered temporal patterns in deception detection. Experimental results on large-scale reviews show the effectiveness of our approach that significantly improves the existing approaches.},
booktitle = {Proceedings of the 25th International Conference on World Wide Web},
pages = {369–379},
numpages = {11},
keywords = {time series, opinion spam, spam detection},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16}
}

@inproceedings{10.1145/3184558.3188728,
author = {Volkova, Svitlana and Jang, Jin Yea},
title = {Misleading or Falsification: Inferring Deceptive Strategies and Types in Online News and Social Media},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3184558.3188728},
doi = {10.1145/3184558.3188728},
abstract = {Deceptive information in online news and social media has had dramatic effect on our society in recent years. This study is the first to gain deeper insights into writers' intent behind digital misinformation by analyzing psycholinguistic signals: moral foundations and connotations extracted from different types of deceptive news ranging from strategic disinformation to propaganda and hoaxes. To ensure consistency of our findings and generalizability across domains, we experiment with data from: (1) confirmed cases of disinformation in news summaries, (2) propaganda, hoax, and disinformation news pages, and (3) social media news. We first contrast lexical markers of biased language, syntactic and stylistic signals, and connotations across deceptive news types including disinformation, propaganda, and hoaxes, and deceptive strategies including misleading or falsification. We then incorporate these insights to build machine learning and deep learning predictive models to infer deception strategies and deceptive news types. Our experimental results demonstrate that unlike earlier work on deception detection, content combined with biased language markers, moral foundations, and connotations leads to better predictive performance of deception strategies compared to syntactic and stylistic signals (as reported in earlier work on deceptive reviews). Falsification strategy is easier to identify than misleading strategy. Disinformation is more difficult to predict than to propaganda or hoaxes. Deceptive news types (disinformation, propaganda, and hoaxes), unlike deceptive strategies (falsification and misleading), are more salient, and thus easier to identify in tweets than in news reports. Finally, our novel connotation analysis across deception types provides deeper understanding of writers' perspectives and therefore reveals the intentions behind digital misinformation.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {575–583},
numpages = {9},
keywords = {social media analysis, misinformation, machine learning, deception, connotation analysis, natural language processing, deep learning},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1145/3193077.3193080,
author = {Mbaziira, Alex V. and Murphy, Diane R.},
title = {An Empirical Study on Detecting Deception and Cybercrime Using Artificial Neural Networks},
year = {2018},
isbn = {9781450363594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3193077.3193080},
doi = {10.1145/3193077.3193080},
abstract = {Ubiquity of the Internet and wide adoption of the computing and mobile devices is driving explosion of data. Interestingly, cybercriminals are also leveraging these popular technologies to cash in on cybercrime in form of scams, fraud and fake online reviews. Existing content filtering techniques, which have been successful in containing spam, are failing to filter these new types of cybercrime because cybercriminals generate text messages to bypass content filters. In this paper, we use natural language processing and a deception-detection discourse to build hybrid models for detecting these forms of text-based cybercrime. Since we have four datasets each of which contains deceptive text messages representing a specific type of cybercrime and truthful text messages, we combine 2 datasets and 3 datasets together to generate training sets for the hybrid models with more than one type of cybercrime. The hybrid cybercrime detection models are trained using Artificial Neural Networks (ANN), Na\"{\i}ve Bayes (NB), Support Vector Machines (SVM) and kth Nearest Neighbor (kNN). The models are then evaluated on test sets containing instances that were not part of the training sets. The results for model performance of NB, kNN and SVM classifiers are compared against those of ANN. Most the models generalize well in detecting cybercrime. ANN model performance on the test sets ranges from 70% to 90% accuracy compared to model performance range of 60% to 80% for the other three classifiers. The best performance is in detecting unfavorable fake reviews and fraud.},
booktitle = {Proceedings of the 2nd International Conference on Compute and Data Analysis},
pages = {42–46},
numpages = {5},
keywords = {natural language processing, supervised learning, artificial neural networks, deception, Cybercrime},
location = {DeKalb, IL, USA},
series = {ICCDA 2018}
}

@inproceedings{10.1145/3093241.3093280,
author = {Mbaziira, Alex V. and Jones, James H.},
title = {Hybrid Text-Based Deception Models for Native and Non-Native English Cybercriminal Networks},
year = {2017},
isbn = {9781450352413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3093241.3093280},
doi = {10.1145/3093241.3093280},
abstract = {Cybercriminals are increasingly using Internet messaging to exploit their victims. We develop and apply a text-based deception detection approach to build hybrid models for detecting cybercrime in the text Internet communications from native and non-native English speaking cybercriminal networks, where our models use both computational linguistics (CL) and psycholinguistic (PL) features. We study four types of deception-based cybercrime: fraud, scam, favorable fake reviews, and unfavorable fake reviews. We build two types of generalized hybrid models for both native and non-native English speaking cybercriminal networks: 2-dataset and 3-dataset hybrid models using Na\"{\i}ve Bayes, Support Vector Machines, and kth Nearest Neighbor algorithms. All 2-dataset models are trained on any two forms of cybercrime in different web genres, which are then used to detect and analyze other types of cybercrime in web genres that were not part of the training set to establish model generalizability. Similarly, the 3-dataset models are trained on any three forms of cybercrime in different web genres, that are also used to detect and analyze cybercrime in a web genre that was not part of the training set. Model performance on the test datasets ranges from 60% to 80% accuracy, with the best performance on detection of unfavorable reviews and fraud, and notable differences emerged between detection in messages from native and non-native English speaking groups. Our work may be applied as provider- or user-based filtering tools to identify cybercriminal actors and block or label undesirable messages before they reach their intended targets.},
booktitle = {Proceedings of the International Conference on Compute and Data Analysis},
pages = {23–27},
numpages = {5},
keywords = {natural language processing, Cybercrime, deception, computational linguistics, psycholinguistics, machine learning},
location = {Lakeland, FL, USA},
series = {ICCDA '17}
}

@inproceedings{10.1145/3197768.3197792,
author = {Hessler, Christian and Abouelenien, Mohamed and Burzo, Mihai},
title = {A Survey on Extracting Physiological Measurements from Thermal Images},
year = {2018},
isbn = {9781450363907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3197768.3197792},
doi = {10.1145/3197768.3197792},
abstract = {Multiple techniques are used to extract physiological signals from the human body. These signals provide a reliable method to identify the physical and mental state of a person at any given point in time. However, these techniques require contact and cooperation of the individual as well as human effort for connecting the devices and collecting the needed measurement. Moreover, these methods can be invasive, time-consuming, and infeasible in many cases. Recent efforts have been made in order to find alternatives to extract these measurements using non-contact and efficient techniques. In this paper we provide a survey that explores different approaches for extracting vital signs from thermal images as well as review applications that could potentially leverage these techniques.},
booktitle = {Proceedings of the 11th PErvasive Technologies Related to Assistive Environments Conference},
pages = {229–236},
numpages = {8},
keywords = {Physiological, non-contact, Thermal, human behavior},
location = {Corfu, Greece},
series = {PETRA '18}
}

@article{10.1145/2185520.2185587,
author = {McDonnell, Rachel and Breidt, Martin and B\"{u}lthoff, Heinrich H.},
title = {Render Me Real? Investigating the Effect of Render Style on the Perception of Animated Virtual Humans},
year = {2012},
issue_date = {July 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {4},
issn = {0730-0301},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2185520.2185587},
doi = {10.1145/2185520.2185587},
abstract = {The realistic depiction of lifelike virtual humans has been the goal of many movie makers in the last decade. Recently, films such as Tron: Legacy and The Curious Case of Benjamin Button have produced highly realistic characters. In the real-time domain, there is also a need to deliver realistic virtual characters, with the increase in popularity of interactive drama video games (such as L.A. Noire™ or Heavy Rain™). There have been mixed reactions from audiences to lifelike characters used in movies and games, with some saying that the increased realism highlights subtle imperfections, which can be disturbing. Some developers opt for a stylized rendering (such as cartoon-shading) to avoid a negative reaction [Thompson 2004]. In this paper, we investigate some of the consequences of choosing realistic or stylized rendering in order to provide guidelines for developers for creating appealing virtual characters. We conducted a series of psychophysical experiments to determine whether render style affects how virtual humans are perceived. Motion capture with synchronized eye-tracked data was used throughout to animate custom-made virtual model replicas of the captured actors.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {91},
numpages = {11},
keywords = {motion capture, perception, facial animation, uncanny valley}
}

@book{10.1145/3107990,
editor = {Oviatt, Sharon and Schuller, Bj\"{o}rn and Cohen, Philip R. and Sonntag, Daniel and Potamianos, Gerasimos and Kr\"{u}ger, Antonio},
title = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
volume = {21},
abstract = {The Handbook of Multimodal-Multisensor Interfaces provides the first authoritative resource on what has become the dominant paradigm for new computer interfaces: user input involving new media (speech, multi-touch, hand and body gestures, facial expressions, writing) embedded in multimodal-multisensor interfaces that often include biosignals.This edited collection is written by international experts and pioneers in the field. It provides a textbook, reference, and technology roadmap for professionals working in this and related areas.This second volume of the handbook begins with multimodal signal processing, architectures, and machine learning. It includes recent deep-learning approaches for processing multisensorial and multimodal user data and interaction, as well as context-sensitivity. A further highlight is processing of information about users' states and traits, an exciting emerging capability in next-generation user interfaces. These chapters discuss real-time multimodal analysis of emotion and social signals from various modalities and perception of affective expression by users. Further chapters discuss multimodal processing of cognitive state using behavioral and physiological signals to detect cognitive load, domain expertise, deception, and depression. This collection of chapters provides walk-through examples of system design and processing, information on tools and practical resources for developing and evaluating new systems, and terminology, and tutorial support for mastering this rapidly expanding field. In the final section of this volume, experts exchange views on the timely and controversial challenge topic of multimodal deep learning. The discussion focuses on how multimodal-multisensor interfaces are most likely to advance human performance during the next decade.}
}

@inbook{10.1145/3107990.3108007,
title = {Index/Bios/Glossary},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108007},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {473–531},
numpages = {59}
}

@inbook{10.1145/3107990.3107991,
title = {Preface},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107991},
abstract = {The content of this handbook is most appropriate for graduate students and of primary interest to students studying computer science and information technology, human-computer interfaces, mobile and ubiquitous interfaces, affective and behavioral computing, machine learning, and related multidisciplinary majors. When teaching graduate classes with this book, whether in a quarter- or semester-long course, we recommend initially requiring that students spend two weeks reading the introductory textbook, The Paradigm Shift to Multimodality in Contemporary Interfaces (Morgan &amp; Claypool Publishers, Human-Centered Interfaces Synthesis Series, 2015). With this orientation, a graduate class providing an overview of multimodal-multisensor interfaces then could select chapters from the current handbook, distributed across topics in the different sections.As an example, in a 10-week course the remaining 8 weeks might be allocated to reading select chapters on: (1) theory, user modeling, and common modality combinations (2 weeks); (2) prototyping and software tools, signal processing, and architectures (2 weeks); (3) language and dialogue processing (1 week); (4) detection of emotional and cognitive state (2 weeks); and (5) commercialization, future trends, and societal issues (1 week). In a more extended 16-week course, we recommend spending an additional week reading and discussing chapters on each of these five topic areas, as well as an additional week on the introductory textbook, The Paradigm Shift to Multimodality in Contemporary Interfaces. As an alternative, in a semester-long course in which students will be conducting a project in one target area (e.g., designing multimodal dialogue systems for in-vehicle use), some or all of the additional time in the semester course could be spent: (1) reading a more in-depth collection of handbook chapters on language and dialogue processing (e.g., 2 weeks) and (2) conducting the hands-on project (e.g., 4 weeks).For more tailored versions of a course on multimodal-multisensor interfaces, another approach is to have students read the handbook chapters in relevant sections and then follow up with more targeted and in-depth technical papers. For example, a course intended for a cognitive science audience might start by reading The Paradigm Shift to Multimodality in Contemporary Interfaces, followed by assigning chapters from the handbook sections on: (1) theory, user modeling, and common modality combinations; (2) multimodal processing of social and emotional information; and (3) multimodal processing of cognition and mental health status. Afterward, the course could teach students different computational and statistical analysis techniques related to these chapters, ideally through demonstration. Students might then be asked to conduct a hands-on project in which they apply one or more analysis methods to multimodal data to build user models or predict mental states.As a second example, a course intended for a computer science audience might also start by reading The Paradigm Shift to Multimodality in Contemporary Interfaces, followed by assigning chapters on: (1) prototyping and software tools; (2) multimodal signal processing and architectures; and (3) language and dialogue processing. Afterward, students might engage in a hands-on project in which they design, build, and evaluate the performance of a multimodal system.In all of these teaching scenarios, we anticipate that professors will find this handbook to be a particularly comprehensive and valuable current resource for teaching about multimodal-multisensor interfaces.AcknowledgmentsIn the present age, reviewers are one of the most precious commodities on earth. First and foremost, we'd like to thank our dedicated expert reviewers, who provided insightful comments on the chapters and their revisions, sometimes on short notice. This select group included Antonis Argyros (University of Crete, Greece), Vassilis Athitsos (University of Texas at Arlington, USA), Nicholas Cummins (University of Augsburg, Germany), Randall Davis (MIT, USA), Jun Deng (audEERING, Germany), Jing Han (University of Passau, Germany), Anthony Jameson (DFKI, Germany), Michael Johnston (Interactions Corp., USA), Thomas Kehrenberg (University of Sussex, UK), Gil Keren (ZD.B, Germany), Elsa Andrea Kirchner (DFKI, Germany), Stefan Kopp (Bielefeld University, Germany), Marieke Longchamp (Laboratoire de Neurosciences Cognitive, France), Vedhas Pandit (University of Passau, Germany), Diane Pawluk (Virginia Commonwealth University, USA), Jouni Pohjalainen (Jabra), Hesam Sagha (audEERING, Germany), Maximillian Schmitt (University of Augsburg, Germany), Gabriel Skantze (KTH Royal Institute of Technology, Sweden), Zixing Zhang (Imperial College London, UK), and the handbook's main editors.We'd also like to thank the handbook's eminent advisory board, 12 people who provided valuable guidance throughout the project, including suggestions for chapter topics, assistance with expert reviewing, participation on the panel of experts in our challenge topic discussions, and valuable advice. Advisory board members included Samy Bengio (Google, USA), James Crowley (INRIA, France), Marc Ernst (Bielefeld University, Germany), Anthony Jameson (DFKI, Germany), Stefan Kopp (Bielefeld University, Germany), Andr\'{a}s L\~{o}rincz (ELTE, Hungary), Kenji Mase (Nagoya University, Japan), Fabio Pianesi (FBK, Italy), Steve Renals (University of Edinburgh, UK), Arun Ross (Michigan State University, USA), David Traum (USC, USA), Wolfgang Wahlster (DFKI, Germany), and Alex Waibel (CMU, USA).We all know that publishing has been a rapidly changing field, and in many cases authors and editors no longer receive the generous support they once did. We'd like to warmly thank Diane Cerra, our Morgan &amp; Claypool Executive Editor, for her amazing skillfulness, flexibility, and delightful good nature throughout all stages of this project. It's hard to imagine having a more experienced publications advisor and friend, and for a large project like this one her experience was invaluable. Thanks also to Mike Morgan, President of Morgan &amp; Claypool, for his support on all aspects of this project. Finally, thanks to Tamer \"{O}zsu and Michel Beaudouin-Lafon of ACM Books for their advice and support.Many colleagues around the world graciously provided assistance in large and small ways---content insights, copies of graphics, critical references, and other valuable information used to document and illustrate this book. Thanks to all who offered their assistance, which greatly enriched this multi-volume handbook. For financial and professional support, we'd like to thank DFKI in Germany and Incaa Designs, an independent 501(c)(3) nonprofit organization in the US. In addition, Bj\"{o}rn Schuller would like to acknowledge support from the European Horizon 2020 Research &amp; Innovation Action SEWA (agreement no. 645094).},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {xvii–xix},
numpages = {63}
}

@inbook{10.1145/3107990.3107992,
title = {Introduction: Trends in Intelligent Multimodal-Multisensorial Interfaces: Cognition, Emotion, Social Signals, Deep Learning, and More},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107992},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {1–16},
numpages = {16}
}

@inbook{10.1145/3107990.3108001,
author = {Martin, Jean-Claude and Clavel, C\'{e}line and Courgeon, Matthieu and Ammi, Mehdi and Amorim, Michel-Ange and Tsalamlal, Yacine and Gaffary, Yoren},
title = {How Do Users Perceive Multimodal Expressions of Affects?},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108001},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {263–285},
numpages = {23}
}

@inbook{10.1145/3107990.3108006,
author = {Bengio, Samy and Deng, Li and Morency, Louis-Philippe and Schuller, Bj\"{o}rn},
title = {Perspectives on Predictive Power of Multimodal Deep Learning: Surprises and Future Directions},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108006},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {455–472},
numpages = {18}
}

@inbook{10.1145/3107990.3107999,
author = {Vinciarelli, Alessandro and Esposito, Anna},
title = {Multimodal Analysis of Social Signals},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107999},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {203–226},
numpages = {24}
}

@inbook{10.1145/3107990.3107993,
author = {Baltru\v{s}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
title = {Challenges and Applications in Multimodal Machine Learning},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107993},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {17–48},
numpages = {32}
}

@inbook{10.1145/3107990.3107994,
author = {Alpaydin, Ethem},
title = {Classifying Multimodal Data},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107994},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {49–69},
numpages = {21}
}

@inbook{10.1145/3107990.3107996,
author = {Keren, Gil and Mousa, Amr El-Desoky and Pietquin, Olivier and Zafeiriou, Stefanos and Schuller, Bj\"{o}rn},
title = {Deep Learning for Multisensorial and Multimodal Interaction},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107996},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {99–128},
numpages = {30}
}

@inbook{10.1145/3107990.3107995,
author = {Panagakis, Yannis and Rudovic, Ognjen and Pantic, Maja},
title = {Learning for Multimodal and Affect-Sensitive Interfaces},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107995},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {71–98},
numpages = {28}
}

@inbook{10.1145/3107990.3107997,
author = {Schuller, Bj\"{o}rn},
title = {Multimodal User State and Trait Recognition: An Overview},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107997},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {129–165},
numpages = {37}
}

@inbook{10.1145/3107990.3108002,
author = {Zhou, Jianlong and Yu, Kun and Chen, Fang and Wang, Yang and Arshad, Syed Z.},
title = {Multimodal Behavioral and Physiological Signals as Indicators of Cognitive Load},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108002},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {287–329},
numpages = {43}
}

@inbook{10.1145/3107990.3108000,
author = {Wagner, Johannes and Andr\'{e}, Elisabeth},
title = {Real-Time Sensing of Affect and Social Signals in a Multimodal Framework: A Practical Approach},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108000},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {227–261},
numpages = {35}
}

@inbook{10.1145/3107990.3107998,
author = {D'Mello, Sidney K. and Bosch, Nigel and Chen, Huili},
title = {Multimodal-Multisensor Affect Detection},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3107998},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {167–202},
numpages = {36}
}

@inbook{10.1145/3107990.3108003,
author = {Oviatt, Sharon and Grafsgaard, Joseph and Chen, Lei and Ochoa, Xavier},
title = {Multimodal Learning Analytics: Assessing Learners' Mental State during the Process of Learning},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108003},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {331–374},
numpages = {44}
}

@inbook{10.1145/3107990.3108004,
author = {Cohn, Jeffrey F. and Cummins, Nicholas and Epps, Julien and Goecke, Roland and Joshi, Jyoti and Scherer, Stefan},
title = {Multimodal Assessment of Depression from Behavioral Signals},
year = {2018},
isbn = {9781970001716},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3107990.3108004},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Signal Processing, Architectures, and Detection of Emotion and Cognition - Volume 2},
pages = {375–417},
numpages = {43}
}

@inproceedings{10.1145/2813852.2813861,
author = {Pereira, Mariana Serras and Shahid, Suleman and Postma, Eric and Swerts, Marc},
title = {Is Your Body Lying? Exploring Bodily Cues for Deception Using an Automated Movement Analysis},
year = {2015},
isbn = {9781450335300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2813852.2813861},
doi = {10.1145/2813852.2813861},
booktitle = {Proceedings of the Facial Analysis and Animation},
articleno = {9},
numpages = {1},
location = {Vienna, Austria},
series = {FAA '15}
}

@inproceedings{10.5555/2002472.2002512,
author = {Ott, Myle and Choi, Yejin and Cardie, Claire and Hancock, Jeffrey T.},
title = {Finding Deceptive Opinion Spam by Any Stretch of the Imagination},
year = {2011},
isbn = {9781932432879},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008). Consequently, websites containing consumer reviews are becoming targets of opinion spam. While recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam---fictitious opinions that have been deliberately written to sound authentic. Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset. Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing.},
booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1},
pages = {309–319},
numpages = {11},
location = {Portland, Oregon},
series = {HLT '11}
}

@article{10.1145/2629612,
author = {Tsikerdekis, Michail and Zeadally, Sherali},
title = {Online Deception in Social Media},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {9},
issn = {0001-0782},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2629612},
doi = {10.1145/2629612},
abstract = {The unknown and the invisible exploit the unwary and the uninformed for illicit financial gain and reputation damage.},
journal = {Commun. ACM},
month = sep,
pages = {72–80},
numpages = {9}
}

@article{10.1145/3409116,
author = {Cresci, Stefano},
title = {A Decade of Social Bot Detection},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {10},
issn = {0001-0782},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3409116},
doi = {10.1145/3409116},
abstract = {Bots increasingly tamper with political elections and economic discussions. Tracing trends in detection strategies and key suggestions on how to win the fight.},
journal = {Commun. ACM},
month = sep,
pages = {72–83},
numpages = {12}
}

@article{10.1145/3310331,
author = {Gr\"{o}ndahl, Tommi and Asokan, N.},
title = {Text Analysis in Adversarial Settings: Does Deception Leave a Stylistic Trace?},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0360-0300},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3310331},
doi = {10.1145/3310331},
abstract = {Textual deception constitutes a major problem for online security. Many studies have argued that deceptiveness leaves traces in writing style, which could be detected using text classification techniques. By conducting an extensive literature review of existing empirical work, we demonstrate that while certain linguistic features have been indicative of deception in certain corpora, they fail to generalize across divergent semantic domains. We suggest that deceptiveness as such leaves no content-invariant stylistic trace, and textual similarity measures provide a superior means of classifying texts as potentially deceptive. Additionally, we discuss forms of deception beyond semantic content, focusing on hiding author identity by writing style obfuscation. Surveying the literature on both author identification and obfuscation techniques, we conclude that current style transformation methods fail to achieve reliable obfuscation while simultaneously ensuring semantic faithfulness to the original text. We propose that future work in style transformation should pay particular attention to disallowing semantically drastic changes.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {45},
numpages = {36},
keywords = {author identification, deanonymization, Stylometry, text obfuscation, deception}
}

@inproceedings{10.1145/2468356.2479508,
author = {Vizer, Lisa M.},
title = {Different Strokes for Different Folks: Individual Stress Response as Manifested in Typed Text},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2468356.2479508},
doi = {10.1145/2468356.2479508},
abstract = {Stress is a part of everyday life, but chronic high stress can have psychological and physiological side effects. Systems that can detect harmful levels of stress could assist users in managing their stress and health. However, current assessments are often obtrusive or require specialized equipment. This research leverages attributes of everyday keyboard interactions to proactively and continuously monitor cognitive function. A laboratory study was conducted where typing samples were collected under stress and no-stress conditions. Keystroke and linguistic features were extracted from the samples and models were constructed for each participant. Correct classification rates ranged from 62% to 88% with a mean of 72%.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {2773–2778},
numpages = {6},
keywords = {natural language processing, cognitive stress, keystroke dynamics, affective computing},
location = {Paris, France},
series = {CHI EA '13}
}

@article{10.1145/3305260,
author = {Sharma, Karishma and Qian, Feng and Jiang, He and Ruchansky, Natali and Zhang, Ming and Liu, Yan},
title = {Combating Fake News: A Survey on Identification and Mitigation Techniques},
year = {2019},
issue_date = {May 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {2157-6904},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3305260},
doi = {10.1145/3305260},
abstract = {The proliferation of fake news on social media has opened up new directions of research for timely identification and containment of fake news and mitigation of its widespread impact on public opinion. While much of the earlier research was focused on identification of fake news based on its contents or by exploiting users’ engagements with the news on social media, there has been a rising interest in proactive intervention strategies to counter the spread of misinformation and its impact on society. In this survey, we describe the modern-day problem of fake news and, in particular, highlight the technical challenges associated with it. We discuss existing methods and techniques applicable to both identification and mitigation, with a focus on the significant advances in each method and their advantages and limitations. In addition, research has often been limited by the quality of existing datasets and their specific application contexts. To alleviate this problem, we comprehensively compile and summarize characteristic features of available datasets. Furthermore, we outline new directions of research to facilitate future development of effective and interdisciplinary solutions.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
articleno = {21},
numpages = {42},
keywords = {rumor detection, misinformation, fake news detection, AI}
}

@inproceedings{10.1145/1753326.1753481,
author = {Steptoe, William and Steed, Anthony and Rovira, Aitor and Rae, John},
title = {Lie Tracking: Social Presence, Truth and Deception in Avatar-Mediated Telecommunication},
year = {2010},
isbn = {9781605589299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/1753326.1753481},
doi = {10.1145/1753326.1753481},
abstract = {The success of visual telecommunication systems depends on their ability to transmit and display users' natural nonverbal behavior. While video-mediated communication (VMC) is the most widely used form of interpersonal remote interaction, avatar-mediated communication (AMC) in shared virtual environments is increasingly common. This paper presents two experiments investigating eye tracking in AMC. The first experiment compares the degree of social presence experienced in AMC and VMC during truthful and deceptive discourse. Eye tracking data (gaze, blinking, and pupil size) demonstrates that oculesic behavior is similar in both mediation types, and uncovers systematic differences between truth telling and lying. Subjective measures show users' psychological arousal to be greater in VMC than AMC. The second experiment demonstrates that observers of AMC can more accurately detect truth and deception when viewing avatars with added oculesic behavior driven by eye tracking. We discuss implications for the design of future visual telecommunication media interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1039–1048},
numpages = {10},
keywords = {social presence, deception, trust, eye tracking, video-mediated communication, virtual environments, avatar-mediated communication},
location = {Atlanta, Georgia, USA},
series = {CHI '10}
}

@inproceedings{10.1145/2910674.2910705,
author = {Abouelenien, Mohamed and Burzo, Mihai and Mihalcea, Rada},
title = {Human Acute Stress Detection via Integration of Physiological Signals and Thermal Imaging},
year = {2016},
isbn = {9781450343374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2910674.2910705},
doi = {10.1145/2910674.2910705},
abstract = {Daily pressure, work load, and family responsibilities among other factors impose increasing levels of stress on different individuals. Hence, detecting stress as early as possible can potentially reduce the severe consequences and risks that someone may experience. In this paper, we develop a novel dataset to detect acute stress using 50 subjects. We additionally analyze different features extracted automatically from the thermal and physiological modalities. Furthermore, we develop a system that integrates both thermal and physiological features for improved stress detection rates. Our system achieves promising results exceeding 75% accuracy and has the potential to be further improved by adding additional modalities, which can provide a useful and reliable approach in early detection of stress.},
booktitle = {Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {32},
numpages = {8},
keywords = {modality, thermal, acute stress, physiological},
location = {Corfu, Island, Greece},
series = {PETRA '16}
}

@inproceedings{10.1145/2970030.2970031,
author = {Cocarascu, Oana and Toni, Francesca},
title = {Detecting Deceptive Reviews Using Argumentation},
year = {2016},
isbn = {9781450343046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2970030.2970031},
doi = {10.1145/2970030.2970031},
abstract = {The unstoppable rise of social networks and the web is facing a serious challenge: identifying the truthfulness of online opinions and reviews. In this paper we use Argumentation Frameworks (AFs) extracted from reviews and explore whether the use of these AFs can improve the performance of machine learning techniques in detecting deceptive behaviour, resulting from users lying in order to mislead readers. The AFs represent how arguments from reviews relate to arguments from other reviews as well as to arguments about the goodness of the items being reviewed.},
booktitle = {Proceedings of the 1st International Workshop on AI for Privacy and Security},
articleno = {9},
numpages = {8},
keywords = {Argumentation, Machine Learning, Deceptive reviews},
location = {The Hague, Netherlands},
series = {PrAISe '16}
}

@inproceedings{10.1145/3132847.3133150,
author = {Patwari, Ayush and Goldwasser, Dan and Bagchi, Saurabh},
title = {TATHYA: A Multi-Classifier System for Detecting Check-Worthy Statements in Political Debates},
year = {2017},
isbn = {9781450349185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3132847.3133150},
doi = {10.1145/3132847.3133150},
abstract = {Fact-checking political discussions has become an essential clog in computational journalism. This task encompasses an important sub-task---identifying the set of statements with 'check-worthy' claims. Previous work has treated this as a simple text classification problem discounting the nuances involved in determining what makes statements check-worthy. We introduce a dataset of political debates from the 2016 US Presidential election campaign annotated using all major fact-checking media outlets and show that there is a need to model conversation context, debate dynamics and implicit world knowledge. We design a multi-classifier system TATHYA, that models latent groupings in data and improves state-of-art systems in detecting check-worthy statements by 19.5% in F1-score on a held-out test set, gaining primarily gaining in Recall.},
booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
pages = {2259–2262},
numpages = {4},
keywords = {clustering, natural language processing, computational journalism},
location = {Singapore, Singapore},
series = {CIKM '17}
}

@article{10.1145/3359624,
author = {Pala, Pietro and Chen, Liming and Huang, Di and Liu, Xiaoming and Zafeiriou, Stefanos},
title = {Introduction to the Special Issue on Face Analysis Applications},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3s},
issn = {1551-6857},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3359624},
doi = {10.1145/3359624},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = oct,
articleno = {85},
numpages = {2}
}

@inproceedings{10.1145/2905055.2905081,
author = {Dewang, Rupesh Kumar and Singh, Pushpendra and Singh, Anil Kumar},
title = {Finding of Review Spam through "Corleone, Review Genre, Writing Style and Review Text Detail Features"},
year = {2016},
isbn = {9781450339629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2905055.2905081},
doi = {10.1145/2905055.2905081},
abstract = {In the era of e-commerce, customers are trust on on-line review. Reviews help them to make right decisions to buy a product or hire a service. Spammer are writes the fake review to promote or demote the target products. Reviews are spam or non-spam; this is the biggest problem for E-commerce business. Moreover, the spam detection problem is complex task. Spammers are inventing new methods to writing spam reviews. It cannot be recognized easily. In this paper, we have extracted some new writing style features like, attractive text ratio and function word ratio and corleone-based features like, lexical validity and text like fraction and compared with already existing features. We have applied support vector machine (SVM), logistic regression, random forest, Jrip, functional tree, Naive Bayes, J48, PART algorithms for classification of review as a spam or non-spam. The SVM, random forest and logistic regression gives the 68% accuracy.},
booktitle = {Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {23},
numpages = {6},
keywords = {Review Spam, Lexical Features, Supervised Learning Algorithms},
location = {Udaipur, India},
series = {ICTCS '16}
}

@inproceedings{10.1145/3230833.3233277,
author = {Tsinganos, Nikolaos and Sakellariou, Georgios and Fouliras, Panagiotis and Mavridis, Ioannis},
title = {Towards an Automated Recognition System for Chat-Based Social Engineering Attacks in Enterprise Environments},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3230833.3233277},
doi = {10.1145/3230833.3233277},
abstract = {Increase in usage of electronic communication tools (email, IM, Skype, etc.) in enterprise environments has created new attack vectors for social engineers. Billions of people are now using electronic equipment in their everyday workflow which means billions of potential victims of Social Engineering (SE) attacks. Human is considered the weakest link in cybersecurity chain and breaking this defense is nowadays the most accessible route for malicious internal and external users. While several methods of protection have already been proposed and applied, none of these focuses on chat-based SE attacks while at the same time automation in the field is still missing. Social engineering is a complex phenomenon that requires interdisciplinary research combining technology, psychology, and linguistics. Attackers treat human personality traits as vulnerabilities and use the language as their weapon to deceive, persuade and finally manipulate the victims as they wish. Hence, a holistic approach is required to build a reliable SE attack recognition system. In this paper we present the current state-of-the-art on SE attack recognition systems, we dissect a SE attack to recognize the different stages, forms, and attributes and isolate the critical enablers that can influence a SE attack to work. Finally, we present our approach for an automated recognition system for chat-based SE attacks that is based on Personality Recognition, Influence Recognition, Deception Recognition, Speech Act and Chat History.},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {53},
numpages = {10},
keywords = {Social Engineering, Speech Act, Deception, Personality, Persuasion},
location = {Hamburg, Germany},
series = {ARES 2018}
}

@inproceedings{10.1145/2187836.2187864,
author = {Ott, Myle and Cardie, Claire and Hancock, Jeff},
title = {Estimating the Prevalence of Deception in Online Review Communities},
year = {2012},
isbn = {9781450312295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2187836.2187864},
doi = {10.1145/2187836.2187864},
abstract = {Consumers' purchase decisions are increasingly influenced by user-generated online reviews. Accordingly, there has been growing concern about the potential for posting deceptive opinion spam---fictitious reviews that have been deliberately written to sound authentic, to deceive the reader. But while this practice has received considerable public attention and concern, relatively little is known about the actual prevalence, or rate, of deception in online review communities, and less still about the factors that influence it.We propose a generative model of deception which, in conjunction with a deception classifier, we use to explore the prevalence of deception in six popular online review communities: Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor, and Yelp. We additionally propose a theoretical model of online reviews based on economic signaling theory, in which consumer reviews diminish the inherent information asymmetry between consumers and producers, by acting as a signal to a product's true, unknown quality. We find that deceptive opinion spam is a growing problem overall, but with different growth rates across communities. These rates, we argue, are driven by the different signaling costs associated with deception for each review community, e.g., posting requirements. When measures are taken to increase signaling cost, e.g., filtering reviews written by first-time reviewers, deception prevalence is effectively reduced.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {201–210},
numpages = {10},
keywords = {gibbs sampling, online reviews, deception prevalence, signaling theory, deceptive opinion spam},
location = {Lyon, France},
series = {WWW '12}
}

@article{10.1162/coli_r_00365,
author = {Girju, Roxana},
title = {Null},
year = {2020},
issue_date = {December 2019},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {45},
number = {4},
issn = {0891-2017},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1162/coli_r_00365},
doi = {10.1162/coli_r_00365},
journal = {Comput. Linguist.},
month = jan,
pages = {819–821},
numpages = {3}
}

@inproceedings{10.5555/1838206.1838470,
author = {Dras, Mark and Richards, Debbie and Taylor, Meredith and Gardiner, Mary},
title = {Deceptive Agents and Language},
year = {2010},
isbn = {9780982657119},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The use of virtual agents in training requires them to have several human-like characteristics; one of these is the ability to appear deceptive. We take work from the psychology literature on cues to deception, with a focus on language-related cues, and examine whether it is possible to use resources from the field of Language Technology to construct scenarios with agents showing cues to deception detectable by human judges, a task that has been shown in a text-only context to be difficult. We show that this detection is in fact possible in the context of virtual agents, and that there are interesting results for individual cues, in particular for dialogue- versus lexical-level cues, and a 'placebo' effect.},
booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: Volume 1 - Volume 1},
pages = {1539–1540},
numpages = {2},
keywords = {agents in virtual environments, language technology},
location = {Toronto, Canada},
series = {AAMAS '10}
}

@inproceedings{10.1145/3018896.3018942,
author = {Song, Chungsik and Goswami, Kunal and Park, Younghee and Chang, Sang-Yoon and Choo, Euijin},
title = {Graphic Model Analysis of Frauds in Online Consumer Reviews},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3018896.3018942},
doi = {10.1145/3018896.3018942},
abstract = {Consumers often rely on online reviews and opinions posted on social media to make a decision when they purchase products or services. This article addresses what are collectively referred to as opinion spam, which are opinions posted by fake reviewers who seek to promote or tear down target entities for financial gain. This has led industry and academic research to seek to develop an efficient and scalable framework to detect such opinion spam. Yelp dataset for online reviews are studied using graph-based methods that leverage the relational ties among reviewers, reviews, and businesses. Yelp user networks is considered, in which reviewer nodes are connected to each other as "friends" relationship. We investigate structural properties of user networks for recommended (non-spam) and fake (spam) reviewer groups. It has demonstrated that networks for groups of recommended reviewers show characteristics of a small-world network. However, networks for groups of fake reviewers reveal properties closer to those of a random network. Clues from the study of structural properties of user networks are used to extend a fraud detection framework which exploits network effects among reviewers and products. Our extended framework is more effective on detecting frauds in Yelp review dataset than previous works.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {47},
numpages = {7},
keywords = {graph theory, small world network, opinion spam},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/3175587.3175588,
author = {Al-Gawwam, Sarmad and Benaissa, Mohammed},
title = {Eye Blink Detection Using Facial Features Tracker},
year = {2017},
isbn = {9781450353823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3175587.3175588},
doi = {10.1145/3175587.3175588},
abstract = {A new technique to detect eye blinks is proposed, based on state- of-the-art facial feature detectors to localize the eyes and eyelid contours. This technique shows excellent robustness to varying illumination, facial expressions and head orientation. The proposed algorithm first estimates the eye features positions and extracts the vertical distance between the eye lids describing the eye opening in each video frame, then uses a Savitzky--Golay filter to smooth the resulting data while keeping the peak information to detect eye blinks as sharp peaks. The efficiency of the proposed technique is shown to outperform related approaches on three standard datasets.},
booktitle = {Proceedings of the International Conference on Bioinformatics Research and Applications 2017},
pages = {27–30},
numpages = {4},
keywords = {signal processing, eye blink detection, video analysis},
location = {Barcelona, Spain},
series = {ICBRA 2017}
}

@article{10.1145/3137597.3137600,
author = {Shu, Kai and Sliva, Amy and Wang, Suhang and Tang, Jiliang and Liu, Huan},
title = {Fake News Detection on Social Media: A Data Mining Perspective},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1931-0145},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3137597.3137600},
doi = {10.1145/3137597.3137600},
abstract = {Social media for news consumption is a double-edged sword. On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media. On the other hand, it enables the wide spread of fake news", i.e., low quality news with intentionally false information. The extensive spread of fake news has the potential for extremely negative impacts on individuals and society. Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention. Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ine ective or not applicable. First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination. Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy. Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem. In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets. We also discuss related research areas, open problems, and future research directions for fake news detection on social media.},
journal = {SIGKDD Explor. Newsl.},
month = sep,
pages = {22–36},
numpages = {15}
}

@inproceedings{10.1145/2781562.2781601,
author = {Wimmer, Hayden and Yoon, Victoria},
title = {Leveraging Technology to Improve Intent to Purchase},
year = {2015},
isbn = {9781450334617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2781562.2781601},
doi = {10.1145/2781562.2781601},
abstract = {Distribution of deceptive counterfeit goods via online marketplaces such as Amazon and eBay has introduced a particularly burdensome decision making process for the consumers. The consumers need to spend additional time in the information search step, reading product and seller reviews to assist with counterfeit detection. Automated counterfeit detection could assist with this process. This paper presents the conceptual framework that employs artificial intelligence techniques, such as natural language processing and topic analysis, in order to automatically detecting counterfeit goods. Specifically, online reviews of products and sellers can be downloaded and parsed using natural language processing. Topic analysis methods can be performed against the resulting text corpus to detect the most frequent terms in the reviews and to examine the reviews for a collection of keywords related to fraudulent products. The implications of this research are to alert consumers to potentially counterfeit products thereby increasing trust and efficiency in the online marketplace.},
booktitle = {Proceedings of the 17th International Conference on Electronic Commerce 2015},
articleno = {33},
numpages = {5},
keywords = {Natural Language Processing, Content Analysis, Counterfeit Detection},
location = {Seoul, Republic of Korea},
series = {ICEC '15}
}

@inproceedings{10.1145/2441776.2441858,
author = {Snyder, Jaime},
title = {Drawing Practices in Image-Enabled Collaboration},
year = {2013},
isbn = {9781450313315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2441776.2441858},
doi = {10.1145/2441776.2441858},
abstract = {Advances in image-making tools have greatly increased our opportunities to use images to collaborate. Much current research in the area of visualization focuses on building systems to generate visual representations of large data sets. A small but growing subset of this research focuses on collaborative aspects of information and data visualization. In order to expand the scope of collaborative visualization research, a qualitative study examined the role that spontaneous drawing practices play in face-to-face conversations. Empirical examples describe the creation and use of drawing as a form of social interaction. This study provides a methodological and theoretical basis for viewing the process of generating a visual artifact in a collaborative context from an interactional sociolinguistic perspective. Findings identify affordances of drawing related to both material object (artifact) and communicative performance (activity). Implications for design are discussed in terms of both refined heuristics and enhanced features for image-enabled collaborative tools.},
booktitle = {Proceedings of the 2013 Conference on Computer Supported Cooperative Work},
pages = {741–752},
numpages = {12},
keywords = {image-enabled discourse, drawing, collaborative visualization},
location = {San Antonio, Texas, USA},
series = {CSCW '13}
}

@article{10.1145/3053408.3053415,
author = {Kotov, Alexander and Treshcheva, Elena and Bessonov, Leonid and Ignatov, Dmitry I. and Volkovich, Yana and Eskevich, Maria and Braslavski, Pavel},
title = {10th Russian Summer School in Information Retrieval (RuSSIR 2016)},
year = {2017},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0163-5840},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3053408.3053415},
doi = {10.1145/3053408.3053415},
journal = {SIGIR Forum},
month = feb,
pages = {28–35},
numpages = {8}
}

@inproceedings{10.1145/1718918.1718921,
author = {Toma, Catalina L. and Hancock, Jeffrey T.},
title = {Reading between the Lines: Linguistic Cues to Deception in Online Dating Profiles},
year = {2010},
isbn = {9781605587950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/1718918.1718921},
doi = {10.1145/1718918.1718921},
abstract = {This study investigates whether deception in online dating profiles is detectable through a linguistic approach, which assumes that liars nonconsciously produce different word patterns than truth-tellers. We objectively measure deception in online dating profiles and analyze the linguistic composition of the open-ended component of the profile (i.e., "about me" section) using computerized text analysis. Results show that profile deceptions correlate with fewer self-references, increased negations, fewer negative emotion words and fewer overall words used in the textual self-description. Results are discussed in terms of (1) practical implications for detecting deception in online profiles; and (2) theoretical implications regarding the impact of media affordances (i.e., asynchronicity and editability) on the occurrence of linguistic cues to deception.},
booktitle = {Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work},
pages = {5–8},
numpages = {4},
keywords = {social networking sites, online dating, linguistic cues to deception, deception},
location = {Savannah, Georgia, USA},
series = {CSCW '10}
}

@inproceedings{10.1145/2663204.2663239,
author = {Marcos-Ramiro, Alvaro and Pizarro-Perez, Daniel and Marron-Romera, Marta and Pizarro-Perez, Daniel and Gatica-Perez, Daniel},
title = {Automatic Blinking Detection towards Stress Discovery},
year = {2014},
isbn = {9781450328852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2663204.2663239},
doi = {10.1145/2663204.2663239},
abstract = {We present a robust method to automatically detect blinks in video sequences of conversations, aimed to discovering stress. Psychological studies have shown a relationship between blink frequency and dopamine levels, which in turn are affected by stress. Task performance correlates through an inverted U shape to both dopamine and stress levels. This shows the importance of automatic blink detection as a way of reducing human coding burden. We use an off-the-shelf face tracker in order to extract the eye region. Then, we perform per-pixel classification of the extracted eye images to later identify blinks through their dynamics. We evaluate the performance of our system with a job interview database with annotations of psychological variables, and show statistically significant correlation between perceived stress resistance and the automatically detected blink patterns.},
booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction},
pages = {307–310},
numpages = {4},
keywords = {random forests, stress discovery, blink detection},
location = {Istanbul, Turkey},
series = {ICMI '14}
}

@inproceedings{10.1145/2740908.2742575,
author = {Appling, Darren Scott and Briscoe, Erica J. and Hutto, Clayton J.},
title = {Discriminative Models for Predicting Deception Strategies},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2740908.2742575},
doi = {10.1145/2740908.2742575},
abstract = {Although a large body of work has previously investigated various cues predicting deceptive communications, especially as demonstrated through written and spoken language (e.g., [30]), little has been done to explore predicting kinds of de- ception. We present novel work to evaluate the use of textual cues to discriminate between deception strategies (such as exaggeration or falsification), concentrating on intention- ally untruthful statements meant to persuade in a social media context. We conduct human subjects experimenta- tion wherein subjects were engaged in a conversational task and then asked to label the kind(s) of deception they employed for each deceptive statement made. We then develop discriminative models to understand the difficulty between choosing between one and several strategies. We evaluate the models using precision and recall for strategy prediction among 4 deception strategies based on the most relevant psycholinguistic, structural, and data-driven cues. Our single strategy model results demonstrate as much as a 58% increase over baseline (random chance) accuracy and we also find that it is more difficult to predict certain kinds of de- ception than others.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {947–952},
numpages = {6},
keywords = {deception strategies, deception strategy prediction, deception, natural language processing, social computing},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3351095.3372852,
author = {Zhang, Yunfeng and Liao, Q. Vera and Bellamy, Rachel K. E.},
title = {Effect of Confidence and Explanation on Accuracy and Trust Calibration in AI-Assisted Decision Making},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3351095.3372852},
doi = {10.1145/3351095.3372852},
abstract = {Today, AI is being increasingly used to help human experts make decisions in high-stakes scenarios. In these scenarios, full automation is often undesirable, not only due to the significance of the outcome, but also because human experts can draw on their domain knowledge complementary to the model's to ensure task success. We refer to these scenarios as AI-assisted decision making, where the individual strengths of the human and the AI come together to optimize the joint decision outcome. A key to their success is to appropriately calibrate human trust in the AI on a case-by-case basis; knowing when to trust or distrust the AI allows the human expert to appropriately apply their knowledge, improving decision outcomes in cases where the model is likely to perform poorly. This research conducts a case study of AI-assisted decision making in which humans and AI have comparable performance alone, and explores whether features that reveal case-specific model information can calibrate trust and improve the joint performance of the human and AI. Specifically, we study the effect of showing confidence score and local explanation for a particular prediction. Through two human experiments, we show that confidence score can help calibrate people's trust in an AI model, but trust calibration alone is not sufficient to improve AI-assisted decision making, which may also depend on whether the human can bring in enough unique knowledge to complement the AI's errors. We also highlight the problems in using local explanation for AI-assisted decision making scenarios and invite the research community to explore new approaches to explainability for calibrating human trust in AI.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {295–305},
numpages = {11},
keywords = {decision support, trust, explainable AI, confidence},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@inproceedings{10.1145/2567948.2579324,
author = {Jaho, Eva and Tzoannos, Efstratios and Papadopoulos, Aris and Sarris, Nikos},
title = {Alethiometer: A Framework for Assessing Trustworthiness and Content Validity in Social Media},
year = {2014},
isbn = {9781450327459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2567948.2579324},
doi = {10.1145/2567948.2579324},
abstract = {There are both positive and negative aspects in the use of social media in news and information dissemination. To deal with the negative aspects, such as the spread of rumours and fake news, the flow of information should implicitly be filtered and marked to specific criteria such as credibility, trustworthiness, reputation, popularity, influence, and authenticity. This paper proposes an approach that can enhance trustworthiness and content validity in the presence of information overload. We introduce Alethiometer, a framework for assessing truthfulness in social media that can be used by professional and general news users alike. We present different measures that delve into the detailed analysis of the content, the contributors of the content and the underlying context. We further propose an approach for deriving a single metric that considers, in a unified manner, the quality of a contributor and of the content provided by that contributor. Finally, we present some preliminary statistical results from the examination of a set of 10 million twitter users, that provide useful insights on the characteristics of social media data.},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
pages = {749–752},
numpages = {4},
keywords = {content validation, web application, news, social media},
location = {Seoul, Korea},
series = {WWW '14 Companion}
}

@inproceedings{10.1145/2523514.2523612,
author = {Almehmadi, Abdulaziz and El-Khatib, Khalil},
title = {Authorized! Access Denied, Unauthorized! Access Granted},
year = {2013},
isbn = {9781450324984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2523514.2523612},
doi = {10.1145/2523514.2523612},
abstract = {Existing access control systems are mostly identity-based. However, such access control systems impose risks because recognized identity is not essentially an interpretation of good intentions of access. On the other hand, an un-identified individual might request access to suppress damage or prevent a catastrophic incident from happening. To address the limitation of current access control systems, we propose an access control method that is based on feelings which relates an access decision to the current detected emotion of the user, and map it to a category of feelings. Feelings categories are either negative resulting in denying access, or positive leading to access being granted. The proposed emotion-based access control (EBAC) mechanism adds the feelings sensation to the access control machines by analyzing the requesters' current brain signals at the time of access request to detect their current emotions, and then grants or denies access.},
booktitle = {Proceedings of the 6th International Conference on Security of Information and Networks},
pages = {363–367},
numpages = {5},
keywords = {authorized, access granted, brain signals, electroencephalogram, emotion detection, unauthorized, EEG, access control, access denied},
location = {Aksaray, Turkey},
series = {SIN '13}
}

@inproceedings{10.1145/1900546.1900563,
author = {Raskin, Victor and Taylor, Julia M. and Hempelmann, Christian F.},
title = {Ontological Semantic Technology for Detecting Insider Threat and Social Engineering},
year = {2010},
isbn = {9781450304153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/1900546.1900563},
doi = {10.1145/1900546.1900563},
abstract = {This paper describes a computational system for detecting unintentional inferences in casual unsolicited and unrestricted verbal output of individuals, potentially responsible for leaked classified information to people with unauthorized access. Uses of the system for cases of insider threat and/or social engineering are discussed. Brief introductions to Ontological Semantic Technology and Natural Language Information Assurance and Security are included.},
booktitle = {Proceedings of the 2010 New Security Paradigms Workshop},
pages = {115–128},
numpages = {14},
keywords = {ontological semantic technology, natural language information assurance and security, unintended inference, social engineering, insider threat, default override},
location = {Concord, Massachusetts, USA},
series = {NSPW '10}
}

@inproceedings{10.1145/2857491.2857543,
author = {Wang, Quan and Boccanfuso, Laura and Li, Beibin and Ahn, Amy Yeo-jin and Foster, Claire E. and Orr, Margaret P. and Scassellati, Brian and Shic, Frederick},
title = {Thermographic Eye Tracking},
year = {2016},
isbn = {9781450341257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2857491.2857543},
doi = {10.1145/2857491.2857543},
abstract = {Far infrared thermography, which can be used to detect thermal radiation emitted by humans, has been used to detect physical disease, physiological changes relating to emotion, and polygraph testing, but has not been used for eye tracking. However, because the surface temperature of the cornea is colder than the limbus, it is theoretically possible to track corneal movements through thermal imaging. To explore the feasibility of thermal eye tracking, we invited 10 adults and tracked their corneal movements with passive thermal imaging at 60 Hz. We combined shape models of eyes with intensity threshold to segment the cornea from other parts of the eye in thermal images. We used an animation sequence as a calibration target for 5 point calibration/validation 5 times. Our results were compared to simultaneously collected data using an SR EyeLink eye tracker at 500 Hz, demonstrating the feasibility of eye tracking with thermal images. Blinking and breathing frequencies, which reflect the psychophysical status of the participants, were also robustly detected during thermal eye tracking.},
booktitle = {Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research &amp; Applications},
pages = {307–310},
numpages = {4},
keywords = {eye movements and cognition, novel systems, image processing},
location = {Charleston, South Carolina},
series = {ETRA '16}
}

@inproceedings{10.1145/2701126.2701130,
author = {Banerjee, Snehasish and Chua, Alton Y. K. and Kim, Jung-Jae},
title = {Using Supervised Learning to Classify Authentic and Fake Online Reviews},
year = {2015},
isbn = {9781450333771},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2701126.2701130},
doi = {10.1145/2701126.2701130},
abstract = {Before making a purchase, users are increasingly inclined to browse online reviews that are posted to share post-purchase experiences of products and services. However, not all reviews are necessarily authentic. Some entries could be fake yet written to appear authentic. Conceivably, authentic and fake reviews are not easy to differentiate. Hence, this paper uses supervised learning algorithms to analyze the extent to which authentic and fake reviews could be distinguished based on four linguistic clues, namely, understandability, level of details, writing style, and cognition indicators. The model performance was compared with two baselines. The results were generally promising.},
booktitle = {Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication},
articleno = {88},
numpages = {7},
keywords = {supervised learning, internet shopping, authentic online reviews, linguistic clues, fake online reviews},
location = {Bali, Indonesia},
series = {IMCOM '15}
}

@inproceedings{10.5555/1860631.1860640,
author = {Pearl, Lisa and Steyvers, Mark},
title = {Identifying Emotions, Intentions, and Attitudes in Text Using a Game with a Purpose},
year = {2010},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Subtle social information is available in text such as a speaker's emotional state, intentions, and attitude, but current information extraction systems are unable to extract this information at the level that humans can. We describe a methodology for creating databases of messages annotated with social information based on interactive games between humans trying to generate and interpret messages for a number of different social information types. We then present some classification results achieved by using a small-scale database created with this methodology.},
booktitle = {Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text},
pages = {71–79},
numpages = {9},
location = {Los Angeles, California},
series = {CAAGET '10}
}

@inproceedings{10.1145/2683483.2683560,
author = {Agarwal, Swapna and Mazumder, Sanjoy and Mukherjee, Dipti Prasad},
title = {Recognizing Facial Expressions in the Orthogonal Complement of Principal Subspace},
year = {2014},
isbn = {9781450330619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2683483.2683560},
doi = {10.1145/2683483.2683560},
abstract = {We present a novel framework for recognition of facial expressions from a given face image. The framework is based on the assumption that expression information lies in the subspace orthogonal to the subspace representing expression-neutral faces. For deriving the principal subspace of the face images showing no expression, PCA is used as a tool. Then we derive a method to find the orthogonal complement (OC) of the subspace defined by the principal components. It is shown using different tools such as dendrogram and Davies-Bouldin cluster index that the OC of the principal subspace better represents the expressions as compared to the principal subspace in PCA analysis. We have done extensive experiments to validate the recognition capability of the proposed OC space. Two well known publicly available facial expression databases are used for the experiments. We also compare the expression discrimination capability of the OC subspace with some well known features for expression representation. The proposed framework exhibits higher (9.66% on average) recognition capability as compared to the present state-of-the-art works.},
booktitle = {Proceedings of the 2014 Indian Conference on Computer Vision Graphics and Image Processing},
articleno = {77},
numpages = {8},
keywords = {facial expression recognition, Orthogonal complement subspace, PCA},
location = {Bangalore, India},
series = {ICVGIP '14}
}

@inbook{10.1145/3015783.3015785,
title = {Introduction: Scope, Trends, and Paradigm Shift in the Field of Computer Interfaces},
year = {2017},
isbn = {9781970001679},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3015783.3015785},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Foundations, User Modeling, and Common Modality Combinations - Volume 1},
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/3340555.3353763,
author = {Hou, Rui and Perez-Rosas, Veronica and Loeb, Stacy and Mihalcea, Rada},
title = {Towards Automatic Detection of Misinformation in Online Medical Videos},
year = {2019},
isbn = {9781450368605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3340555.3353763},
doi = {10.1145/3340555.3353763},
abstract = {Recent years have witnessed a significant increase in the online sharing of medical information, with videos representing a large fraction of such online sources. Previous studies have however shown that more than half of the health-related videos on platforms such as YouTube contain misleading information and biases. Hence, it is crucial to build computational tools that can help evaluate the quality of these videos so that users can obtain accurate information to help inform their decisions. In this study, we focus on the automatic detection of misinformation in YouTube videos. We select prostate cancer videos as our entry point to tackle this problem. The contribution of this paper is twofold. First, we introduce a new dataset consisting of 250 videos related to prostate cancer manually annotated for misinformation. Second, we explore the use of linguistic, acoustic, and user engagement features for the development of classification models to identify misinformation. Using a series of ablation experiments, we show that we can build automatic models with accuracies of up to 74%, corresponding to a 76.5% precision and 73.2% recall for misinformative instances.},
booktitle = {2019 International Conference on Multimodal Interaction},
pages = {235–243},
numpages = {9},
keywords = {YouTube, Prostate Cancer, Multimodal Processing, Misinformation Detection},
location = {Suzhou, China},
series = {ICMI '19}
}

@inproceedings{10.5555/2429759.2429890,
author = {Latek, Maciej M. and Rizi, Seyed M. Mussavi and Geller, Armando},
title = {Using Participatory Elicitation to Identify Population Needs and Power Structures in Conflict Environments},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {A methodological approach is reported to produce a context analysis in South Afghanistan under the banner of Do No Harm (DNH). The difficult work environment for locals, development workers and researchers alike is briefly described; and the problem that is supposed to be solved is derived from it, namely how to elicit the needs and requirements of the population. Step by step the reader is guided through the approach proposed and a selection of results is presented that (arguably) demonstrate the usefulness of our ideas for optimal (DNH) project portfolio design.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {99},
numpages = {13},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.1145/3382507.3418865,
author = {Putze, Felix and K\"{u}ster, Dennis and Urban, Timo and Zastrow, Alexander and Kampen, Marvin},
title = {Attention Sensing through Multimodal User Modeling in an Augmented Reality Guessing Game},
year = {2020},
isbn = {9781450375818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3382507.3418865},
doi = {10.1145/3382507.3418865},
abstract = {We developed an attention-sensitive system that is capable of playing the children's guessing game "I spy with my litte eye" with a human user. In this game, the user selects an object from a given scene and provides the system with a single-sentence clue about it. For each trial, the system tries to guess the target object. Our approach combines top-down and bottom-up machine learning for object and color detection, automatic speech recognition, natural language processing, a semantic database, eye tracking, and augmented reality. Our evaluation demonstrates performance significantly above chance level, and results for most of the individual machine learning components are encouraging. Participants reported very high levels of satisfaction and curiosity about the system. The collected data shows that our guessing game generates a complex and rich data set. We discuss the capabilities and challenges of our system and its components with respect to multimodal attention sensing.},
booktitle = {Proceedings of the 2020 International Conference on Multimodal Interaction},
pages = {33–40},
numpages = {8},
keywords = {attention, augmented reality, gamification, top-down and bottom-up modeling},
location = {Virtual Event, Netherlands},
series = {ICMI '20}
}

@inproceedings{10.5555/2021109.2021120,
author = {Peterson, Kelly and Hohensee, Matt and Xia, Fei},
title = {Email Formality in the Workplace: A Case Study on the Enron Corpus},
year = {2011},
isbn = {9781932432961},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Email is an important way of communication in our daily life and it has become the subject of various NLP and social studies. In this paper, we focus on email formality and explore the factors that could affect the sender's choice of formality. As a case study, we use the Enron email corpus to test how formality is affected by social distance, relative power, and the weight of imposition, as defined in Brown and Levinson's model of politeness (1987). Our experiments show that their model largely holds in the Enron corpus. We believe that the methodology proposed in the paper can be applied to other social media domains and be used to test other linguistic or social theories.},
booktitle = {Proceedings of the Workshop on Languages in Social Media},
pages = {86–95},
numpages = {10},
location = {Portland, Oregon},
series = {LSM '11}
}

@inproceedings{10.1145/2993148.2993175,
author = {Beyan, Cigdem and Carissimi, Nicol\`{o} and Capozzi, Francesca and Vascon, Sebastiano and Bustreo, Matteo and Pierro, Antonio and Becchio, Cristina and Murino, Vittorio},
title = {Detecting Emergent Leader in a Meeting Environment Using Nonverbal Visual Features Only},
year = {2016},
isbn = {9781450345569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2993148.2993175},
doi = {10.1145/2993148.2993175},
abstract = { In this paper, we propose an effective method for emergent leader detection in meeting environments which is based on nonverbal visual features. Identifying emergent leader is an important issue for organizations. It is also a well-investigated topic in social psychology while a relatively new problem in social signal processing (SSP). The effectiveness of nonverbal features have been shown by many previous SSP studies. In general, the nonverbal video-based features were not more effective compared to audio-based features although, their fusion generally improved the overall performance. However, in absence of audio sensors, the accurate detection of social interactions is still crucial. Motivating from that, we propose novel, automatically extracted, nonverbal features to identify the emergent leadership. The extracted nonverbal features were based on automatically estimated visual focus of attention which is based on head pose. The evaluation of the proposed method and the defined features were realized using a new dataset which is firstly introduced in this paper including its design, collection and annotation. The effectiveness of the features and the method were also compared with many state of the art features and methods. },
booktitle = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
pages = {317–324},
numpages = {8},
keywords = {Emergent leadership, visual focus of attention, social signal processing, nonverbal features},
location = {Tokyo, Japan},
series = {ICMI '16}
}

@inproceedings{10.1145/3136755.3136770,
author = {Abouelenien, Mohamed and P\'{e}rez-Rosas, Ver\'{o}nica and Mihalcea, Rada and Burzo, Mihai},
title = {Multimodal Gender Detection},
year = {2017},
isbn = {9781450355438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3136755.3136770},
doi = {10.1145/3136755.3136770},
abstract = { Automatic gender classification is receiving increasing attention in the computer interaction community as the need for personalized, reliable, and ethical systems arises. To date, most gender classification systems have been evaluated on textual and audiovisual sources. This work explores the possibility of enhancing such systems with physiological cues obtained from thermography and physiological sensor readings. Using a multimodal dataset consisting of audiovisual, thermal, and physiological recordings of males and females, we extract features from five different modalities, namely acoustic, linguistic, visual, thermal, and physiological. We then conduct a set of experiments where we explore the gender prediction task using single and combined modalities. Experimental results suggest that physiological and thermal information can be used to recognize gender at reasonable accuracy levels, which are comparable to the accuracy of current gender prediction systems. Furthermore, we show that the use of non-contact physiological measurements, such as thermography readings, can enhance current systems that are based on audio or visual input. This can be particularly useful for scenarios where non-contact approaches are preferred, i.e., when data is captured under noisy audiovisual conditions or when video or speech data are not available due to ethical considerations. },
booktitle = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
pages = {302–311},
numpages = {10},
keywords = {multimodal, visual, gender detection, physiological, vocal, thermal, linguistic},
location = {Glasgow, UK},
series = {ICMI '17}
}

@article{10.1162/COLI_a_00313,
author = {Grosz, Barbara J.},
title = {Smart Enough to Talk with Us? Foundations and Challenges for Dialogue Capable Ai Systems},
year = {2018},
issue_date = {March 2018},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {44},
number = {1},
issn = {0891-2017},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1162/COLI_a_00313},
doi = {10.1162/COLI_a_00313},
journal = {Comput. Linguist.},
month = mar,
pages = {1–15},
numpages = {15}
}

@inproceedings{10.1145/2513166.2513176,
author = {Xu, Chang},
title = {Detecting Collusive Spammers in Online Review Communities},
year = {2013},
isbn = {9781450324229},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2513166.2513176},
doi = {10.1145/2513166.2513176},
abstract = {In this paper, we first define our research problem as to detect collusive spammers in online review communities. Next we present our current progress on this topic, in which we have spotted anomalies by evaluating 15 behavioral features proposed in the state-of-the-art approaches. Then we propose a novel hybrid classification/clustering method to detect colluders in our dataset based on selected informative features. Experimental results show that our method promisingly improve the performance of traditional classifiers by incorporating clustering for the smoothing. Finally, possible extensions of our current work and challenges in achieving them are discussed as our future directions.},
booktitle = {Proceedings of the Sixth Workshop on Ph.D. Students in Information and Knowledge Management},
pages = {33–40},
numpages = {8},
keywords = {spam review detection, smoothing, collusive spammer},
location = {San Francisco, California, USA},
series = {PIKM '13}
}

@article{10.1109/TASLP.2019.2925934,
author = {Xie, Yue and Liang, Ruiyu and Liang, Zhenlin and Huang, Chengwei and Zou, Cairong and Schuller, Bjorn},
title = {Speech Emotion Classification Using Attention-Based LSTM},
year = {2019},
issue_date = {November 2019},
publisher = {IEEE Press},
volume = {27},
number = {11},
issn = {2329-9290},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1109/TASLP.2019.2925934},
doi = {10.1109/TASLP.2019.2925934},
abstract = {Automatic speech emotion recognition has been a research hotspot in the field of human–computer interaction over the past decade. However, due to the lack of research on the inherent temporal relationship of the speech waveform, the current recognition accuracy needs improvement. To make full use of the difference of emotional saturation between time frames, a novel method is proposed for speech recognition using frame-level speech features combined with attention-based long short-term memory LSTM recurrent neural networks. Frame-level speech features were extracted from waveform to replace traditional statistical features, which could preserve the timing relations in the original speech through the sequence of frames. To distinguish emotional saturation in different frames, two improvement strategies are proposed for LSTM based on the attention mechanism: first, the algorithm reduces the computational complexity by modifying the forgetting gate of traditional LSTM without sacrificing performance and second, in the final output of the LSTM, an attention mechanism is applied to both the time and the feature dimension to obtain the information related to the task, rather than using the output from the last iteration of the traditional algorithm. Extensive experiments on the CASIA, eNTERFACE, and GEMEP emotion corpora demonstrate that the performance of the proposed approach is able to outperform the state-of-the-art algorithms reported to date.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = nov,
pages = {1675–1685},
numpages = {11}
}

@inproceedings{10.1145/2487788.2488034,
author = {Halevi, Tzipora and Lewis, James and Memon, Nasir},
title = {A Pilot Study of Cyber Security and Privacy Related Behavior and Personality Traits},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2487788.2488034},
doi = {10.1145/2487788.2488034},
abstract = {Recent research has begun to focus on the factors that cause people to respond to phishing attacks as well as affect user behavior on social networks. This study examines the correlation between the Big Five personality traits and email phishing response. Another aspect examined is how these factors relate to users' tendency to share information and protect their privacy on Facebook (which is one of the most popular social networking sites).This research shows that when using a prize phishing email, neuroticism is the factor most correlated to responding to this email, in addition to a gender-based difference in the response. This study also found that people who score high on the openness factor tend to both post more information on Facebook as well as have less strict privacy settings, which may cause them to be susceptible to privacy attacks. In addition, this work detected no correlation between the participants estimate of being vulnerable to phishing attacks and actually being phished, which suggests susceptibility to phishing is not due to lack of awareness of the phishing risks and that real-time response to phishing is hard to predict in advance by online users.The goal of this study is to better understand the traits that contribute to online vulnerability, for the purpose of developing customized user interfaces and secure awareness education, designed to increase users' privacy and security in the future.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {737–744},
numpages = {8},
keywords = {facebook, personality traits, privacy, phishing},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@proceedings{10.1145/2818346,
title = {ICMI '15: Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
year = {2015},
isbn = {9781450339124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to Seattle and to the 2015 ACM International Conference on Multimodal Interaction. This year's conference continues its tradition of being the premier forum for presenting research results and experience studies on multimodal human-human and human-computer interaction. The conference focuses on theoretical and empirical foundations, component technologies, and combined multimodal processing techniques that define the field of multimodal interaction analysis, interface design, and system development. ICMI 2015 features a single-track main conference which includes: keynote speakers, technical full and short papers (including oral and poster presentations), demonstrations, exhibits, grand challenges, and doctoral symposium papers. It is followed by a day with five workshops.The ICMI 2015 call for long and short papers attracted 127 paper submissions (84 in the long category and 43 in the short category). The papers were reviewed by a program committee led by 3 Program Chairs and composed of 25 Senior Program Committee members and a large number of technical reviewers. In a rebuttal process, the authors had the opportunity to clarify any misunderstandings and respond to questions raised in the reviews and meta-reviews. After the rebuttal phase, the program chairs held several remote meetings to discuss the papers. As a result, 24 papers were accepted for oral presentation and 28 papers were accepted for poster presentation. The acceptance rate is 19% for oral presentations and 41% overall, for short and long papers combined.This year, the conference will host two invited keynote speeches from thought leaders in industry and academia. They are: Sharing Representations for Long Tail Computer Vision Problems, Dr. Samy Bengio, Google (USA),Interaction Studies with Social Robots, Prof. Kerstin Dautenhahn, University of Hertfordshire (UK).In addition, Dr. Eric Horvitz, Microsoft (USA), the recipient of the ICMI 2015 Sustained Accomplishment Award, presented by the ICMI Advisory Board, will give a plenary talk entitled Connections. We encourage attendees to attend the keynote presentations. These valuable and insightful talks can and will guide us to a better understanding of the future of multimodal interaction.The main ICMI conference program includes an exciting Demonstration session co-chaired by Hrvoje Benko (Microsoft, USA) and Stefan Scherer (University of Southern California, USA) that will showcase innovative implementations, systems, and technologies that incorporate multimodal interaction. The demonstration session will include 12 refereed demonstrations (out of 17 submitted), plus 5 demonstrations that accompany accepted main track papers.The Doctoral Consortium is by now a traditional ICMI satellite event which takes place on the first day of the conference and extends our commitment to the next generation of researchers. This year, the event is co-chaired by Carlos Busso (University of Texas at Dallas, USA) and Vidhyasaharan Sethu (University of New South Wales, Australia). In this special session, a highly-accomplishedmentor team and senior PhD students, selected via a rigorous review process by the Doctoral Consortium Program Committee, as well as by peer reviews from other applicants, gather to discuss research plans and progress of each student. From among 30 applications, 14 students were accepted for participation. The accepted students receive a travel grant and registration waiver to attend both the Doctoral Consortium event, and the main conference. The organizers thank the U.S. National Science Foundation (award IIS 1346655 and IIS 1443097) and conference sponsors for the financial support that makes this possible.The Multimodal Grand Challenges were introduced to ICMI in 2012. They are designed to stimulate the community with standardized corpora competitions, and new research questions. This year's challenges are co-chaired by Cosmin Munteanu (University of Toronto, Canada) and Marcelo Worsley (Stanford University, USA), and include: the Fourth Multimodal Learning Analytics Challenge (MLA), the Third Emotion Recognition In The Wild Challenge (EMOTIW), and the Recognition of Social Touch Gestures Challenge. All three Grand Challenges will be presented on Monday, November 9th, and an overview and poster session will take place on Thursday, November 12th, during the main conference.The ICMI workshop program was co-chaired this year by Jean-Marc Odobez (IDIAP, Switzerland)and Hayley Hung (Technical University of Delft, Netherlands). Five workshops will be held after the main conference, on Friday, November 13th. They are: the 1st Workshop on Modeling INTERPERsonal SynchrONy And infLuence (INTERPERSONAL), the ACM Workshop on Multimodal Deception Detection (WMDD), the International Workshop on Emotion Representations and Modelling for Companion Systems (ERM4CT), the 1st International Workshop on Advancements in Social Signal Processing for Multimodal Interaction (ASSP4MI), and the Workshop on Developing Portable &amp; Context-aware Multimodal Applications for Connected Devices using W3C Multimodal Architecture (sponsored workshop).Outstanding paper awards have also been a tradition at ICMI. This year, in addition to the traditional Outstanding Paper award and Outstanding Student Paper award, the ICMI board also established an Honorable Mention award. The Program Chairs considered the top-ranked paper submissions based on the reviews and meta-reviews and identified a set of nominations for the awards. A paper award committee was created with internationally renowned researchers in multimodal interaction. The committee reviewed the nominated papers carefully and selected the recipients of these awards, which will be announced at the banquet.The Sustained Accomplishment Award is presented to a scientist who has made innovative and longlasting contributions to our field. The award acknowledges an individual who has demonstrated vision in shaping the field, with a sustained record of research that has influenced the work of others. This year's award is presented to Dr. Eric Horvitz, Microsoft (USA), for his many contributions to multimodal interaction. The ICMI Community Service Award is given to an individual who has made organizational contributions that have had a major impact on the ICMI community and its annual events. Nominees will have made contributions to build and diversify our community over a period of five years or longer, including the creation of mechanisms to promote intellectual exchange and multidisciplinary or international alliances, and the expansion of opportunities for student training and participation. The 2015 ICMI Community Service award is presented to Dr. Kenji Mase, Nagoya University (Japan). Finally, this year, the ICMI Advisory Board will present two Ten Year Technical Impact paper awards at the banquet.},
location = {Seattle, Washington, USA}
}

@article{10.1162/coli_a_00333,
author = {Benamara, Farah and Inkpen, Diana and Taboada, Maite},
title = {Introduction to the Special Issue on Language in Social Media: Exploiting Discourse and Other Contextual Information},
year = {2018},
issue_date = {December 2018},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {44},
number = {4},
issn = {0891-2017},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1162/coli_a_00333},
doi = {10.1162/coli_a_00333},
abstract = {Social media content is changing the way people interact with each other and share information, personal messages, and opinions about situations, objects, and past experiences. Most social media texts are short online conversational posts or comments that do not contain enough information for natural language processing NLP tools, as they are often accompanied by non-linguistic contextual information, including meta-data e.g., the user's profile, the social network of the user, and their interactions with other users. Exploiting such different types of context and their interactions makes the automatic processing of social media texts a challenging research task. Indeed, simply applying traditional text mining tools is clearly sub-optimal, as, typically, these tools take into account neither the interactive dimension nor the particular nature of this data, which shares properties with both spoken and written language. This special issue contributes to a deeper understanding of the role of these interactions to process social media data from a new perspective in discourse interpretation. This introduction first provides the necessary background to understand what context is from both the linguistic and computational linguistic perspectives, then presents the most recent context-based approaches to NLP for social media. We conclude with an overview of the papers accepted in this special issue, highlighting what we believe are the future directions in processing social media texts.},
journal = {Comput. Linguist.},
month = dec,
pages = {663–681},
numpages = {19}
}

@inproceedings{10.1145/3270101.3270110,
author = {Wang, Ningfei and Ji, Shouling and Wang, Ting},
title = {Integration of Static and Dynamic Code Stylometry Analysis for Programmer De-Anonymization},
year = {2018},
isbn = {9781450360043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3270101.3270110},
doi = {10.1145/3270101.3270110},
abstract = {De-anonymizing the authors of anonymous code (i.e., code stylometry) entails significant privacy and security implications. Most existing code stylometry methods solely rely on static (e.g., lexical, layout, and syntactic) features extracted from source code, while neglecting its key difference from regular text -- it is executable! In this paper, we present Sundae, a novel code de-anonymization framework that integrates both static and dynamic stylometry analysis. Compared with the existing solutions, Sundae departs in significant ways: (i) it requires much less number of static, hand-crafted features; (ii) it requires much less labeled data for training; and (iii) it can be readily extended to new programmers once their stylometry information becomes available Through extensive evaluation on benchmark datasets, we demonstrate that Sundae delivers strong empirical performance. For example, under the setting of 229 programmers and 9 problems, it outperforms the state-of-art method by a margin of 45.65% on Python code de-anonymization. The empirical results highlight the integration of static and dynamic analysis as a promising direction for code stylometry research.},
booktitle = {Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security},
pages = {74–84},
numpages = {11},
keywords = {de-anonymization, dynamic analysis, code stylometry},
location = {Toronto, Canada},
series = {AISec '18}
}

@inproceedings{10.1145/2487575.2487688,
author = {Sun, Huan and Morales, Alex and Yan, Xifeng},
title = {Synthetic Review Spamming and Defense},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2487575.2487688},
doi = {10.1145/2487575.2487688},
abstract = {Online reviews have been popularly adopted in many applications. Since they can either promote or harm the reputation of a product or a service, buying and selling fake reviews becomes a profitable business and a big threat. In this paper, we introduce a very simple, but powerful review spamming technique that could fail the existing feature-based detection algorithms easily. It uses one truthful review as a template, and replaces its sentences with those from other reviews in a repository. Fake reviews generated by this mechanism are extremely hard to detect: Both the state-of-the-art computational approaches and human readers acquire an error rate of 35%-48%, just slightly better than a random guess. While it is challenging to detect such fake reviews, we have made solid progress in suppressing them. A novel defense method that leverages the difference of semantic flows between synthetic and truthful reviews is developed, which is able to reduce the detection error rate to approximately 22%, a significant improvement over the performance of existing approaches. Nevertheless, it is still a challenging research task to further decrease the error rate.Synthetic Review Spamming Demo: www.cs.ucsb.edu/~alex_morales/reviewspam/},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1088–1096},
numpages = {9},
keywords = {review spam, spam detection, classification},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}

@inproceedings{10.1145/2229012.2229035,
author = {Caragiannis, Ioannis and Elkind, Edith and Szegedy, Mario and Yu, Lan},
title = {Mechanism Design: From Partial to Probabilistic Verification},
year = {2012},
isbn = {9781450314152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2229012.2229035},
doi = {10.1145/2229012.2229035},
abstract = {Algorithmic mechanism design is concerned with designing algorithms for settings where inputs are controlled by selfish agents, and the center needs to motivate the agents to report their true values. In this paper, we study scenarios where the center may be able to verify whether the agents report their preferences (types) truthfully. We first consider the standard model of mechanism design with partial verification, where the set of types that an agent can report is a function of his true type. We explore inherent limitations of this model; in particular, we show that the famous Gibbard--Satterthwaite impossibility result holds even if a manipulator can only lie by swapping two adjacent alternatives in his vote. Motivated by these negative results, we then introduce a richer model of verification, which we term mechanism design with probabilistic verification. In our model, an agent may report any type, but will be caught with some probability that may depend on his true type, the reported type, or both; if an agent is caught lying, he will not get his payment and may be fined. We characterize the class of social choice functions that can be truthfully implemented in this model. We then proceed to study the complexity of finding an optimal individually rational implementation, i.e., one that minimizes the center's expected payment while guaranteeing non-negative utility to the agent, both for truthful and for non-truthful implementation. Our hardness result for non-truthful implementation answers an open question recently posed by Auletta et al. [2011].},
booktitle = {Proceedings of the 13th ACM Conference on Electronic Commerce},
pages = {266–283},
numpages = {18},
keywords = {algorithmic mechanism design, verification},
location = {Valencia, Spain},
series = {EC '12}
}

@inproceedings{10.1145/2675133.2675214,
author = {Cheng, Justin and Bernstein, Michael S.},
title = {Flock: Hybrid Crowd-Machine Learning Classifiers},
year = {2015},
isbn = {9781450329224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2675133.2675214},
doi = {10.1145/2675133.2675214},
abstract = {We present hybrid crowd-machine learning classifiers: classification models that start with a written description of a learning goal, use the crowd to suggest predictive features and label data, and then weigh these features using machine learning to produce models that are accurate and use human-understandable features. These hybrid classifiers enable fast prototyping of machine learning models that can improve on both algorithm performance and human judgment, and accomplish tasks where automated feature extraction is not yet feasible. Flock, an interactive machine learning platform, instantiates this approach. To generate informative features, Flock asks the crowd to compare paired examples, an approach inspired by analogical encoding. The crowd's efforts can be focused on specific subsets of the input space where machine-extracted features are not predictive, or instead used to partition the input space and improve algorithm performance in subregions of the space. An evaluation on six prediction tasks, ranging from detecting deception to differentiating impressionist artists, demonstrated that aggregating crowd features improves upon both asking the crowd for a direct prediction and off-the-shelf machine learning features by over 10%. Further, hybrid systems that use both crowd-nominated and machine-extracted features can outperform those that use either in isolation.},
booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing},
pages = {600–611},
numpages = {12},
keywords = {interactive machine learning, crowdsourcing},
location = {Vancouver, BC, Canada},
series = {CSCW '15}
}

@inproceedings{10.1145/3038912.3052582,
author = {Li, Huayi and Fei, Geli and Wang, Shuai and Liu, Bing and Shao, Weixiang and Mukherjee, Arjun and Shao, Jidong},
title = {Bimodal Distribution and Co-Bursting in Review Spam Detection},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3038912.3052582},
doi = {10.1145/3038912.3052582},
abstract = {Online reviews play a crucial role in helping consumers evaluate and compare products and services. This critical importance of reviews also incentivizes fraudsters (or spammers) to write fake or spam reviews to secretly promote or demote some target products and services. Existing approaches to detecting spam reviews and reviewers employed review contents, reviewer behaviors, star rating patterns, and reviewer-product networks for detection. In this research, we further discovered that reviewers' posting rates (number of reviews written in a period of time) also follow an interesting distribution pattern, which has not been reported before. That is, their posting rates are bimodal. Multiple spammers also tend to collectively and actively post reviews to the same set of products within a short time frame, which we call co-bursting. Furthermore, we found some other interesting patterns in individual reviewers' temporal dynamics and their co-bursting behaviors with other reviewers. Inspired by these findings, we first propose a two-mode Labeled Hidden Markov Model to model spamming using only individual reviewers' review posting times. We then extend it to the Coupled Hidden Markov Model to capture both reviewer posting behaviors and co-bursting signals. Our experiments show that the proposed model significantly outperforms state-of-the-art baselines in identifying individual spammers. Furthermore, we propose a co-bursting network based on co-bursting relations, which helps detect groups of spammers more effectively than existing approaches.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {1063–1072},
numpages = {10},
keywords = {hidden markov model, spam groups, review spam},
location = {Perth, Australia},
series = {WWW '17}
}

@inproceedings{10.1145/2783258.2783370,
author = {Rayana, Shebuti and Akoglu, Leman},
title = {Collective Opinion Spam Detection: Bridging Review Networks and Metadata},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2783258.2783370},
doi = {10.1145/2783258.2783370},
abstract = {Online reviews capture the testimonials of "real" people and help shape the decisions of other consumers. Due to the financial gains associated with positive reviews, however, opinion spam has become a widespread problem, with often paid spam reviewers writing fake reviews to unjustly promote or demote certain products or businesses. Existing approaches to opinion spam have successfully but separately utilized linguistic clues of deception, behavioral footprints, or relational ties between agents in a review system.In this work, we propose a new holistic approach called SPEAGLE that utilizes clues from all metadata (text, timestamp, rating) as well as relational data (network), and harness them collectively under a unified framework to spot suspicious users and reviews, as well as products targeted by spam. Moreover, our method can efficiently and seamlessly integrate semi-supervision, i.e., a (small) set of labels if available, without requiring any training or changes in its underlying algorithm. We demonstrate the effectiveness and scalability of SPEAGLE on three real-world review datasets from Yelp.com with filtered (spam) and recommended (non-spam) reviews, where it significantly outperforms several baselines and state-of-the-art methods. To the best of our knowledge, this is the largest scale quantitative evaluation performed to date for the opinion spam problem.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {985–994},
numpages = {10},
keywords = {heterogenous networks, semi-supervised learning, opinion spam, scalable algorithms, metadata},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{10.1145/2998181.2998322,
author = {Lykourentzou, Ioanna and Kraut, Robert E. and Dow, Steven P.},
title = {Team Dating Leads to Better Online Ad Hoc Collaborations},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2998181.2998322},
doi = {10.1145/2998181.2998322},
abstract = {Forming work teams involves matching people with complementary skills and personalities, but requires obtaining such data a priori. We introduce team dating, where people interact on brief tasks before working with a dedicated partner for longer, more complex tasks. We studied team dating through two online experiments. In Experiment 1, workers from a crowd platform independently wrote an ad slogan, discussed it with three consecutive people and evaluated their team date interactions. They then selected preferred teammates from a list showing average ratings for people they had dated and not dated. Results show that participants evaluated their dates based on evidence beyond externally judged slogan quality, and relied heavily on their dyad-specific judgments in selecting teammates. In Experiment 2, we replicated the individual and team dating tasks, and formed teams, either i) by honoring pairwise team dating preferences, ii) randomly from their pool of dates, or iii) randomly from those not dated. Results show that teams formed from preferred dates performed better on a final creative task compared to random dates or non-dates. Team dating provides a dynamic technique for forming ad hoc teams accounting for interpersonal dynamics. The initial interactions provided information that helped people select and work with an appropriate teammate.},
booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {2330–2343},
numpages = {14},
keywords = {team formation, distributed decision-making, thin slicing},
location = {Portland, Oregon, USA},
series = {CSCW '17}
}

@inproceedings{10.1145/3038912.3052677,
author = {Kumar, Srijan and Cheng, Justin and Leskovec, Jure and Subrahmanian, V.S.},
title = {An Army of Me: Sockpuppets in Online Discussion Communities},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3038912.3052677},
doi = {10.1145/3038912.3052677},
abstract = {In online discussion communities, users can interact and share information and opinions on a wide variety of topics. However, some users may create multiple identities, or sockpuppets, and engage in undesired behavior by deceiving others or manipulating discussions. In this work, we study sockpuppetry across nine discussion communities, and show that sockpuppets differ from ordinary users in terms of their posting behavior, linguistic traits, as well as social network structure. Sockpuppets tend to start fewer discussions, write shorter posts, use more personal pronouns such as ``I'', and have more clustered ego-networks. Further, pairs of sockpuppets controlled by the same individual are more likely to interact on the same discussion at the same time than pairs of ordinary users. Our analysis suggests a taxonomy of deceptive behavior in discussion communities. Pairs of sockpuppets can vary in their deceptiveness, i.e., whether they pretend to be different users, or their supportiveness, i.e., if they support arguments of other sockpuppets controlled by the same user. We apply these findings to a series of prediction tasks, notably, to identify whether a pair of accounts belongs to the same underlying user or not. Altogether, this work presents a data-driven view of deception in online discussion communities and paves the way towards the automatic detection of sockpuppets.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {857–866},
numpages = {10},
keywords = {antisocial behavior, malicious users, multiple account use},
location = {Perth, Australia},
series = {WWW '17}
}

@article{10.1145/3372043,
author = {Landau, Ofir and Puzis, Rami and Nissim, Nir},
title = {Mind Your Mind: EEG-Based Brain-Computer Interfaces and Their Security in Cyber Space},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3372043},
doi = {10.1145/3372043},
abstract = {A brain-computer interface (BCI) system is a system that leverages brainwave information acquired by a designated brain monitoring device to interact with a computerized system. Over the past 40 years, many BCI applications have been developed in a variety of domains, from entertainment to medical field and even to computer security mechanisms. Until now, the development of BCI systems has focused on improving their accuracy, functionality, and ease of use, and not enough effort and attention has been invested in securing these systems and the sensitive data they acquire. In this article, we present the principles of brain activity data acquisition, with a special focus on EEG, and we present a taxonomy of BCI applications and domains. We also provide a comprehensive survey that covers eight possible attacks aimed at BCI systems. For each BCI application, we created an ecosystem and data and attack flow-diagram, which comprehensively describes the roles and interactions of the players associated with the BCI application and presents the most vulnerable vectors and components within its ecosystem; we identified gaps between existing security solutions and the presented attacks and vulnerabilities. Finally, we provide several concrete suggestions for improving the security of BCI systems in cyber-space.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {17},
numpages = {38},
keywords = {detection, Brain-computer interface, privacy, EEG, attack, security, cyber space}
}

@article{10.1162/COLI_r_00282,
author = {Lee, Yoong Keok},
title = {Book Review: Morgan &amp; Claypool Synthesis Lectures on Human Language Technologies, Edited by Graeme Hirst, Volume 29, 2015, Xvii+101 Pp; Paperback, Isbn 978-1-62705-337-2; Ebook, Isbn 978-1-62705-338-9; Doi: 10.2200/S00656ed1v01y201507hlt029},
year = {2017},
issue_date = {April 2017},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {43},
number = {1},
issn = {0891-2017},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1162/COLI_r_00282},
doi = {10.1162/COLI_r_00282},
journal = {Comput. Linguist.},
month = apr,
pages = {269–271},
numpages = {3}
}

@inproceedings{10.1145/3267305.3274139,
author = {Canavan, Shaun and Andujar, Marvin and Yin, Lijun and Nijholt, Anton and Schotter, Elizabeth},
title = {Ubiquitous Emotion Recognition with Multimodal Mobile Interfaces},
year = {2018},
isbn = {9781450359665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3267305.3274139},
doi = {10.1145/3267305.3274139},
abstract = {In 1997 Rosalind Picard introduced fundamental concepts of affect recognition [1]. Since this time, multimodal interfaces such as Brain-computer interfaces (BCIs), RGB and depth cameras, physiological wearables, multimodal facial data and physiological data have been used to study human emotion. Much of the work in this field focuses on a single modality to recognize emotion. However, there is a wealth of information that is available for recognizing emotions when incorporating multimodal data. Considering this, the aim of this workshop is to look at current and future research activities and trends for ubiquitous emotion recognition through the fusion of data from various multimodal, mobile devices.},
booktitle = {Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers},
pages = {937–941},
numpages = {5},
location = {Singapore, Singapore},
series = {UbiComp '18}
}

@inproceedings{10.1145/2984511.2984517,
author = {Orts-Escolano, Sergio and Rhemann, Christoph and Fanello, Sean and Chang, Wayne and Kowdle, Adarsh and Degtyarev, Yury and Kim, David and Davidson, Philip L. and Khamis, Sameh and Dou, Mingsong and Tankovich, Vladimir and Loop, Charles and Cai, Qin and Chou, Philip A. and Mennicken, Sarah and Valentin, Julien and Pradeep, Vivek and Wang, Shenlong and Kang, Sing Bing and Kohli, Pushmeet and Lutchyn, Yuliya and Keskin, Cem and Izadi, Shahram},
title = {Holoportation: Virtual 3D Teleportation in Real-Time},
year = {2016},
isbn = {9781450341899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2984511.2984517},
doi = {10.1145/2984511.2984517},
abstract = {We present an end-to-end system for augmented and virtual reality telepresence, called Holoportation. Our system demonstrates high-quality, real-time 3D reconstructions of an entire space, including people, furniture and objects, using a set of new depth cameras. These 3D models can also be transmitted in real-time to remote users. This allows users wearing virtual or augmented reality displays to see, hear and interact with remote participants in 3D, almost as if they were present in the same physical space. From an audio-visual perspective, communicating and interacting with remote users edges closer to face-to-face communication. This paper describes the Holoportation technical system in full, its key interactive capabilities, the application scenarios it enables, and an initial qualitative study of using this new communication medium.},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
pages = {741–754},
numpages = {14},
keywords = {telepresence, mixed reality, real-time, gpu, depth cameras, 3d capture, non-rigid reconstruction},
location = {Tokyo, Japan},
series = {UIST '16}
}

@inproceedings{10.1145/2974804.2974815,
author = {Serras Pereira, Mariana and de Lange, Jolanda and Shahid, Suleman and Swerts, Marc},
title = {Children's Facial Expressions in Truthful and Deceptive Interactions with a Virtual Agent},
year = {2016},
isbn = {9781450345088},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2974804.2974815},
doi = {10.1145/2974804.2974815},
abstract = {The present study focused on the facial expressions that children exhibit while they try to deceive a virtual agent. An interactive lie elicitation game was developed to record children's facial expressions during deceptive and truthful utterances, when doing the task alone or in the presence of peers. Based on manual annotations of their facial expressions, we found that children, while communicating with a virtual agent, produce different facial expressions in deceptive and truthful contexts. It seems that deceptive children try to cover their lie as they smile significantly more than truthful children. Moreover, co-presence enhances children's facial expressive behaviour and the amount of cues to deceit. Deceivers, especially when being together with a friend, more often press their lips, smile, blink and avert their gaze than truth-tellers.},
booktitle = {Proceedings of the Fourth International Conference on Human Agent Interaction},
pages = {289–296},
numpages = {8},
keywords = {facial expressions, nonverbal communication, children, child-virtual agent interaction, lying behaviour},
location = {Biopolis, Singapore},
series = {HAI '16}
}

@article{10.1145/1839676.1839683,
author = {Anthes, Gary},
title = {Security in the Cloud},
year = {2010},
issue_date = {November 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {11},
issn = {0001-0782},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/1839676.1839683},
doi = {10.1145/1839676.1839683},
abstract = {Cloud computing offers many advantages, but also involves security risks. Fortunately, researchers are devising some ingenious solutions.},
journal = {Commun. ACM},
month = nov,
pages = {16–18},
numpages = {3}
}

@inproceedings{10.1145/2184751.2184863,
author = {Viswanathan, Murlikrishna and Zhang, Zhen-Xing and Tian, Xue-Wei and Lim, Joon S.},
title = {Emotional-Speech Recognition Using the Neuro-Fuzzy Network},
year = {2012},
isbn = {9781450311724},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2184751.2184863},
doi = {10.1145/2184751.2184863},
abstract = {Emotion recognition based on a speech signal is one of the intensively studied research topics in the domains of human-computer interaction and affective computing. The presented paper is concerned with emotional-speech recognition based on the neuro-fuzzy network with a weighted fuzzy membership function (NEWFM). NEWFM has a feature selection method and makes fuzzy classifiers. In this paper, NEWFM was utilized for classifying four kinds of emotional-speech signals. This NEWFM classification method achieves as high as 86% overall classification accuracy. Significantly, the NEWFM classifier efficiently detects sadness, with a 97.5% recognition rate.},
booktitle = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication},
articleno = {96},
numpages = {5},
keywords = {feature selection, neuro-fuzzy network, emotional-speech recognition, fuzzy classifier},
location = {Kuala Lumpur, Malaysia},
series = {ICUIMC '12}
}

@inproceedings{10.1145/2559206.2581370,
author = {Lee, Myungho and Kim, Kangsoo and Rho, Hyunghwan and Kim, Si Jung},
title = {Empa Talk: A Physiological Data Incorporated Human-Computer Interactions},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2559206.2581370},
doi = {10.1145/2559206.2581370},
abstract = {We present a novel approach that allows the user to feel the other's emotional status while communicating with each other in a video chat. The video chat is composed of physiological sensors and multimodal displays. In our first prototype, we employed a Galvanic Skin Response (GSR) sensor and a Blood Volume Pulse (BVP) sensor as they were crucial indications to human emotions. A vibrotactile motor and a RGB LED were also used in order to convey and display the other's emotion on one's wrist. Along with the hardware part, we implemented intuitive software for processing, transmitting, and displaying bio feedback data.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {1897–1902},
numpages = {6},
keywords = {hci, bio feedback, human emotion, video chat, human senses, physiology},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}

@article{10.1145/3349536,
author = {Siagian, Al Hafiz Akbar Maulana and Aritsugi, Masayoshi},
title = {Robustness of Word and Character N-Gram Combinations in Detecting Deceptive and Truthful Opinions},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1936-1955},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3349536},
doi = {10.1145/3349536},
abstract = {Opinions in reviews about the quality of products or services can be important information for readers. Unfortunately, such opinions may include deceptive ones posted for some business reasons. To keep the opinions as a valuable and trusted source of information, we propose an approach to detecting deceptive and truthful opinions. Specifically, we explore the use of word and character n-gram combinations, function words, and word syntactic n-grams (word sn-grams) as features for classifiers to deal with this task. We also consider applying word correction to our utilized dataset. Our experiments show that classification results of using the word and character n-gram combination features could perform better than those of employing other features. Although the experiments indicate that applying the word correction might be insignificant, we note that the deceptive opinions tend to have a smaller number of error words than the truthful ones. To examine robustness of our features, we then perform cross-classification tests. Our latter experiments results suggest that using the word and character n-gram combination features could work well in detecting deceptive and truthful opinions. Interestingly, the latter experimental results also indicate that using the word sn-grams as combination features could give good performance.},
journal = {J. Data and Information Quality},
month = jan,
articleno = {5},
numpages = {24},
keywords = {fake reviews, Deceptive opinions, spell correction, word and character combinations, robustness, sn-grams}
}

@inproceedings{10.1145/3173574.3173835,
author = {Newn, Joshua and Allison, Fraser and Velloso, Eduardo and Vetere, Frank},
title = {Looks Can Be Deceiving: Using Gaze Visualisation to Predict and Mislead Opponents in Strategic Gameplay},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3173574.3173835},
doi = {10.1145/3173574.3173835},
abstract = {In competitive co-located gameplay, players use their opponents' gaze to make predictions about their plans while simultaneously managing their own gaze to avoid giving away their plans. This socially competitive dimension is lacking in most online games, where players are out of sight of each other. We conducted a lab study using a strategic online game; finding that (1) players are better at discerning their opponent's plans when shown a live visualisation of the opponent's gaze, and (2) players who are aware that their gaze is tracked will manipulate their gaze to keep their intentions hidden. We describe the strategies that players employed, to various degrees of success, to deceive their opponent through their gaze behaviour. This gaze-based deception adds an effortful and challenging aspect to the competition. Lastly, we discuss the various implications of our findings and its applicability for future game design.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {plan recognition, competitive gameplay, gaze visualisation, deception, intent recognition, nonverbal leakage},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3052973.3053037,
author = {Baki, Shahryar and Verma, Rakesh and Mukherjee, Arjun and Gnawali, Omprakash},
title = {Scaling and Effectiveness of Email Masquerade Attacks: Exploiting Natural Language Generation},
year = {2017},
isbn = {9781450349444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3052973.3053037},
doi = {10.1145/3052973.3053037},
abstract = {We focus on email-based attacks, a rich field with well-publicized consequences. We show how current Natural Language Generation (NLG) technology allows an attacker to generate masquerade attacks on scale, and study their effectiveness with a within-subjects study. We also gather insights on what parts of an email do users focus on and how users identify attacks in this realm, by planting signals and also by asking them for their reasoning. We find that: (i) 17% of participants could not identify any of the signals that were inserted in emails, and (ii) Participants were unable to perform better than random guessing on these attacks. The insights gathered and the tools and techniques employed could help defenders in: (i) implementing new, customized anti-phishing solutions for Internet users including training next-generation email filters that go beyond vanilla spam filters and capable of addressing masquerade, (ii) more effectively training and upgrading the skills of email users, and (iii) understanding the dynamics of this novel attack and its ability of tricking humans.},
booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
pages = {469–482},
numpages = {14},
keywords = {social engineering, within-subject study, phishing email, experimental study},
location = {Abu Dhabi, United Arab Emirates},
series = {ASIA CCS '17}
}

@inproceedings{10.1145/2461466.2461529,
author = {Dhall, Abhinav},
title = {Expression Analysis in the Wild: From Individual to Groups},
year = {2013},
isbn = {9781450320337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2461466.2461529},
doi = {10.1145/2461466.2461529},
abstract = {With the advances in the computer vision in the past few years, analysis of human facial expressions has gained attention. Facial expression analysis is now an active field of research for over two decades now. However, still there are a lot of questions unanswered. This project will explore and devise algorithms and techniques for facial expression analysis in practical environments. Methods will also be developed for inferring the emotion of a group of people. The central hypothesis of the project is that close to real-world data can be extracted from movies and facial expression analysis on movies is a stepping stone for moving to analysis in the real-world. For the analysis of groups of people various attributes effect the perception of mood. A system which can classify the mood of a group of people in videos will be developed and will be used to solve the problem of efficient image browsing and retrieval based on emotion.},
booktitle = {Proceedings of the 3rd ACM Conference on International Conference on Multimedia Retrieval},
pages = {325–328},
numpages = {4},
keywords = {expression analysis in the wild, group mood analysis},
location = {Dallas, Texas, USA},
series = {ICMR '13}
}

@inproceedings{10.1145/2212776.2223744,
author = {Pietrowicz, Mary and Karahalios, Karrie},
title = {Phonetic Shapes: An Interactive, Sonic Guest Book},
year = {2012},
isbn = {9781450310161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2212776.2223744},
doi = {10.1145/2212776.2223744},
abstract = {Sound exists only in the moment, and cannot be referenced or searched, except in the mutable memories of people. Because of this, it has been an overlooked modality and social information channel, particularly where nonverbal communication cues and identity are concerned. Yet, it encapsulates a person's identity as effectively as a fingerprint or signature. Sound is even more useful when combined with other modalities, like the visual and gestural. In order to use the modality of sound effectively, however, we need tools that simultaneously analyze, persist, and present the important information in sound. What if you could capture identity and meaning in sound, and give it additional affordances, that go beyond those of written communication? In this paper, we explore the voice as identity and as the carrier of nonverbal information in the context of a sonic guest book.},
booktitle = {CHI '12 Extended Abstracts on Human Factors in Computing Systems},
pages = {2009–2014},
numpages = {6},
keywords = {guest book, machine learning, social identity, phonetics, persistence, audio, social visualization, signal processing},
location = {Austin, Texas, USA},
series = {CHI EA '12}
}

@inproceedings{10.1145/3177404.3177444,
author = {Pratiwi, Nunik and Widyanto, M. Rahmat and Basaruddin, T. and Liliana, Dewi Yanti},
title = {Nonlinear Fuzzy Robust PCA on Shape Modelling of Active Appearance Model for Facial Expression Recognition},
year = {2017},
isbn = {9781450353830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3177404.3177444},
doi = {10.1145/3177404.3177444},
abstract = {Automatic facial expression recognition is one of the potential research area in the field of computer vison. It aims to improve the ability of machine to capture social signals in human. Automatic facial expression recognition is still a challenge. We proposed method using contrast limited adaptive histogram equalization (CLAHE) for pre-processing stage then performed feature extraction using active appearance model (AAM) based on nonlinear fuzzy robust principal component analysis (NFRPCA). The feature extraction results will be classified with support vector machine (SVM). Feature points generated AAM based on NFRPCA more adaptive compared to AAM based PCA. Our proposed method's the average accuracy rate reached 96,87% and 93,94% for six and seven basic emotions respectively.},
booktitle = {Proceedings of the International Conference on Video and Image Processing},
pages = {68–72},
numpages = {5},
keywords = {nonlinear fuzzy robust PCA, AAM, contrast limited adaptive histogram equalization, SVM, Facial expression},
location = {Singapore, Singapore},
series = {ICVIP 2017}
}

@inproceedings{10.1145/3354031.3354032,
author = {Niu, Weikun and Jiang, Yuying and Zhang, Yujin and Zhang, Xin and Yu, Shan},
title = {Application of Granger Causality in Decoding Covert Selective Attention with Human EEG},
year = {2019},
isbn = {9781450372244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3354031.3354032},
doi = {10.1145/3354031.3354032},
abstract = {Electroencephalography (EEG)-based BCIs have experienced a significant growth in recent years, especially the passive Brain Computer Interfaces (BCIs) with a wide application in the detection of cognitive and emotional states. But it is still unclear whether more subtle states, e.g., covert selective attention can be decoded with EEG signals. Here we used a behavioral paradigm to introduce the shift of selective attention between the visual and auditory domain. With EEG signals, we extracted features based on Grange Causality (GC) and successfully decoded the attentional shift through a support vector machine (SVM) based classifier. The decoding accuracy was significantly above the chance level for all 8 subjects tested. The features based on GC were further analyzed with tree-based feature importance analysis and recursive feature elimination (RFE) method to search for the optimal features for classification. Our work demonstrate that specific patterns of brain activities reflected by GC can be used to decode subtle state changes of the brain related to cross-modal selective attention, which opens new possibility of using passive BCIs in sophisticated perceptual and cognitive tasks.},
booktitle = {Proceedings of the 2019 4th International Conference on Biomedical Signal and Image Processing (ICBIP 2019)},
pages = {13–18},
numpages = {6},
keywords = {Passive BCI, Pattern classification, EEG, Selective attention, Granger causality},
location = {Chengdu, China},
series = {ICBIP '19}
}

@inproceedings{10.1145/3424978.3425013,
author = {Dai, Fan and Li, Weihua},
title = {Feature Acquisition for Facial Expression Recognition Using Deep Convolutional Neural Network},
year = {2020},
isbn = {9781450377720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3424978.3425013},
doi = {10.1145/3424978.3425013},
abstract = {We present a convolutional neural network for facial expression recognition based on feature acquisition. The proposed method adopts the structure of dual-channel convolution neural network, the network structure of each channel is designed according to the input sets, the extracted face and the extracted mouth are used as input to two channels simultaneously. Experiments are carried out on two different data sets include JEFFA and FER-2013 to determine the recognition accuracy, and we build a set to test our model, and we compare the generalization performance by using the confusion matrix, then we compared and analyzed the experiment results of recognition accuracy under different facial expressions. Finally, our facial expression recognition system got an accuracy of 82% and 78% respectively, and learning meta face recognition in unseen domains should be researched in the future.},
booktitle = {Proceedings of the 4th International Conference on Computer Science and Application Engineering},
articleno = {35},
numpages = {5},
keywords = {Facial expression recognition, Convolutional neural network, Feature extraction, Deep Learning},
location = {Sanya, China},
series = {CSAE 2020}
}

@inproceedings{10.1145/2910674.2910686,
author = {Joshi, Ajjen and Tickle-Degnen, Linda and Gunnery, Sarah and Ellis, Terry and Betke, Margrit},
title = {Predicting Active Facial Expressivity in People with Parkinson's Disease},
year = {2016},
isbn = {9781450343374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2910674.2910686},
doi = {10.1145/2910674.2910686},
abstract = {Our capacity to engage in meaningful conversations depends on a multitude of communication signals, including verbal delivery of speech, tone and modulation of voice, execution of body gestures, and exhibition of a range of facial expressions. Among these cues, the expressivity of the face strongly indicates the level of one's engagement during a social interaction. It also significantly influences how others perceive one's personality and mood. Individuals with Parkinson's disease whose facial muscles have become rigid have difficulty exhibiting facial expressions. In this work, we investigate how to computationally predict an accurate and objective score for facial expressivity of a person. We present a method that computes geometric shape features of the face and predicts a score for facial expressivity. Our method trains a random forest regressor based on features extracted from a set of training videos of interviews of people suffering from Parkinson's disease. We evaluated our formulation on a dataset of 727 20-second video clips using 9-fold cross validation. We also provide insight on the geometric features that are important in this prediction task by computing variable importance scores for our features. Our results suggest that the dynamics of the eyes and eyebrows are better predictors of facial expressivity than dynamics of the mouth.},
booktitle = {Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {13},
numpages = {4},
keywords = {Geometric facial features, Feature importance, Facial expressivity prediction, Random Forest regression},
location = {Corfu, Island, Greece},
series = {PETRA '16}
}

@inproceedings{10.1145/3321454.3321462,
author = {Llanda, Christopher John R.},
title = {Video Tutoring System with Automatic Facial Expression Recognition: An Enhancing Approach to E-Learning Environment},
year = {2019},
isbn = {9781450366335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3321454.3321462},
doi = {10.1145/3321454.3321462},
abstract = {In the past decades, new technologies were introduced and adopted in the e-learning environment to facilitate the learning process. It is commonly acknowledged that emotions are significant factor in gaining cognition which influences information processing, memory and performance. Up until now, affective computing and computer vision are hot research topics in the industries and especially in the field of education. This paper presents the level of performances for two group of students at the same class enrolled in programming course. A Video Tutoring System with Facial Expression Recognition (VTSFER) was developed as teaching tool to facilitate instructions in programming course. The system is intelligent enough to identify emotions through face recognition and was used by BSIT 3rd year students. The students was group into two in which second half of students utilized the VTSFER. An assessment was conducted and determined the level of performances to both group of students. A statistical tool t-test was used to determine the significant difference. The t-value showed a highly significant with a value of 2.1827 and a probability of 0.0382. The result presented that the second half of the students gain more knowledge in using the video tutoring system with facial expression recognition compare to the first half of students who uses a traditional video tutorial. With the intervention of face expression recognition embedded in video tutorial, students were engaged and gained more knowledge in learning.},
booktitle = {Proceedings of the 2019 4th International Conference on Intelligent Information Technology},
pages = {5–9},
numpages = {5},
keywords = {Video tutoring system, facial expression recognition, e-learning, emotion},
location = {Da, Nang, Viet Nam},
series = {ICIIT '19}
}

@inproceedings{10.1145/3345336.3345343,
author = {Xia, Zhaoqiang and Liang, Huan and Hong, Xiaopeng and Feng, Xiaoyi},
title = {Cross-Database Micro-Expression Recognition with Deep Convolutional Networks},
year = {2019},
isbn = {9781450363051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3345336.3345343},
doi = {10.1145/3345336.3345343},
abstract = {Micro-expression recognition (MER) is attracting more and more interests as it has important applications for analyzing human behaviors. Since the recognition ability for individual datasets has been improved greatly, few works have been devoted to the cross database task of MER, which is more challenging for capturing the subtle changes of micro-expressions from different environments. In this paper, we employ an end-to-end deep model for learning the representation and classifier automatically. In the deep model, the recurrent convolutional layers are utilized to exploit the learning ability with the optical flow fields of micro-expression sequences, which are enhanced by a motion magnification procedure. To ease the influence of samples from different datasets (environments), we present three normalization methods (i.e., sample-wise, subject-wise and dataset-wise methods) to restrain the variations of samples. The experiments are performed on the cross database of MERC2019 challenge, and achieve comparative performance than the baseline method.},
booktitle = {Proceedings of the 2019 3rd International Conference on Biometric Engineering and Applications},
pages = {56–60},
numpages = {5},
keywords = {Micro-expression Recognition, Data Normalization, Recurrent Convolutional Networks},
location = {Stockholm, Sweden},
series = {ICBEA 2019}
}

@inproceedings{10.1145/3265639.3265664,
author = {Shima, Yoshihiro and Omori, Yuki},
title = {Image Augmentation for Classifying Facial Expression Images by Using Deep Neural Network Pre-Trained with Object Image Database},
year = {2018},
isbn = {9781450365307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3265639.3265664},
doi = {10.1145/3265639.3265664},
abstract = {Image augmentation of automatic facial expression classification is proposed on the basis of a combination of a deep neural network and a support vector machine. A neural network pre-trained with a large-scale object image database is used as a feature extractor for facial images. The accuracy of system performance is evaluated using the database "ATR Facial Expression Image Database (DB99)." By using image augmentation, an average recognition rate of 97.92% was obtained, which was a 9.84 percentage point improvement compared with that without augmentation. The experimental results showed the effectiveness of our scheme.},
booktitle = {Proceedings of the 3rd International Conference on Robotics, Control and Automation},
pages = {140–146},
numpages = {7},
keywords = {support vector machine, deep learning, Computer vision, neural networks, facial expression, feature extraction},
location = {Chengdu, China},
series = {ICRCA '18}
}

@inproceedings{10.1145/3197768.3203181,
author = {Bieber, Gerald and Antony, Niklas and Haescher, Marian},
title = {Touchless Heart Rate Recognition by Robots to Support Natural Human-Robot Communication},
year = {2018},
isbn = {9781450363907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3197768.3203181},
doi = {10.1145/3197768.3203181},
abstract = {With the proliferation of robotic assistants, such as robot vacuum cleaners, telepresence robots, or shopping assistance robots, human-robot interaction becomes increasingly more natural. The capabilities of robots are expanding, which leads to an increasing need for a natural human-robot communication and interaction. Therefore, the modalities of text- or speech-based communication have to be extended by body language and a direct feedback such as emotion or non-verbal communication.In this paper, we present a camera-based, non-body contact optical heart rate recognition method that can be used in robots in order to identify humans' reactions during a robot-human communication or interaction. For the purpose of heart rate and heart rate variability detection, we used standard cameras (webcams) that are located inside the robot's eye. Although camera-based vital sign identification has been discussed in previous research, we noticed that certain limitations with regard to real-world applications do still exist. We identified artificial light sources as one of the main influencing factors. Therefore, we propose strategies with the aim Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from of improving natural communication between social robots and humans.},
booktitle = {Proceedings of the 11th PErvasive Technologies Related to Assistive Environments Conference},
pages = {415–420},
numpages = {6},
keywords = {Camera, Wearable Computing, Social Robots, Assistive Technology, Vital data, Recognition, Webcam, Optical, Activity, Autonomous Computing},
location = {Corfu, Greece},
series = {PETRA '18}
}

@inproceedings{10.1145/3324033.3324051,
author = {Saengpetch, Piyawat and Pipanmemekaporn, Luepol and Kamolsantiroj, Suwatchai},
title = {Visual Representation Model for FMRI-Based Brain Decoding},
year = {2019},
isbn = {9781450362634},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3324033.3324051},
doi = {10.1145/3324033.3324051},
abstract = {Classification of brain activity patterns has enabled to infer what a person in mind. Among brain activity signals, functional Magnetic Resonance Imaging (fMRI) is considered as the most reliable source to decode the neural activity patterns. While fMRI-based brain decoders exist, the accuracy is often limited by lacking of training samples. Most of the existing fMRI-based brain decoders overcome the limitation by designing semantic features for encoding numerous classes and training a model to predict these encoded features from fMRI patterns. However, what kind of features for accurately decoding the fMRI patterns remain unclear. In this work, a novel fMRI-based brain decoding model is present. Unlike traditional approaches that use text-derived features, we show that visual features derived from images can be well predicted for decoding fMRI patterns. Moreover, we propose a multi-task method that effectively learns a compact but discriminative model for characterizing neural coding. Experimental results conducted on fMRI datasets demonstrated that our proposed models achieve encouraging performance compared to state-of-the-art fMRI-based brain decoders.},
booktitle = {Proceedings of the 2019 2nd International Conference on Electronics, Communications and Control Engineering},
pages = {58–63},
numpages = {6},
keywords = {Machine Learning, Brain decoding, Multi-task learning, fMRI},
location = {Phuket, Thailand},
series = {ICECC 2019}
}

@inproceedings{10.1145/3374587.3374616,
author = {Fu, Xiaofeng and Wu, Jun and Fu, Xiaojuan},
title = {Local Binary Patterns of Spatial Plane and Temporal Linear for Spotting Spontaneous Expression Frames},
year = {2019},
isbn = {9781450376273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3374587.3374616},
doi = {10.1145/3374587.3374616},
abstract = {Spontaneous expression can reveal people's true emotions as comparing with traditional expression. Spotting spontaneous expression frames in the video is prerequisite for studying its characteristics. This paper proposes the local binary patterns feature extraction algorithm based on spatial plane and temporal line. Firstly, the improved normalized cross-correlation algorithm is used to finely match the eye region and the mouth region respectively. Then, fusing two kinds of features, one is the mean local binary patterns features of linear region which are extracted from the temporal linear, the other is the local binary patterns features of the sector region which are extracted from the spatial plane. Finally, the feature is converted into the frame feature by feature correlation function, and frame feature of the spontaneous expression frame is larger than threshold. The experimental results show that our algorithm performs well on the CAS(ME)2 database. The hitting rate of negative spontaneous expression segments increases by 27% than the ULBP algorithm. Simultaneously, the AUC value of the ROC curve increases by 1% as comparing to the LBP-TOP algorithm.},
booktitle = {Proceedings of the 2019 3rd International Conference on Computer Science and Artificial Intelligence},
pages = {347–353},
numpages = {7},
keywords = {Local binary patterns, Spatial plane, Temporal linear, Spotting, Spontaneous expression videos},
location = {Normal, IL, USA},
series = {CSAI2019}
}

@inproceedings{10.1145/3372394.3372395,
author = {Said, Sarah and Kalms, Lester and G\"{o}hringer, Diana and El Ghany, Mohamed A. Abd},
title = {Hardware/Software-Codesign for Hand Gestures Recognition Using a Convolutional Neural Network},
year = {2019},
isbn = {9781450376525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3372394.3372395},
doi = {10.1145/3372394.3372395},
abstract = {Hand Gesture (HG) recognition has been an interesting and challenging scientific problem in computer vision and machine learning. However, achieving high performance and high accuracy is a challenging task in gesture recognition. The intensive computation, the complex backgrounds, conditions of lights and positions are the most remarkable challenges regarding performance and accuracy. Those two aspects are taken into consideration in this paper. It proposes a convolutional neural network (CNN) model that can recognize three static HGs using a simpler architecture and fewer weights than previously proposed networks. The proposed CNN is completely implemented and several optimizations are performed to reduce runtime for frames with 28x28 pixels. The total runtime is 42 ms. Moreover, one of the layers is implemented on hardware(HW) level on ARM-FPGA SoC and it is faster than the software(SW) by 39.8x speedup. The total run time is 23.75 ms in C++/ VHDL. A comparison of the proposed model is made between our accelerated implementation and Caffe, which achieves a speedup of 1.17. The proposed model has an accuracy of 94%.},
booktitle = {Proceedings of the INTelligent Embedded Systems Architectures and Applications Workshop 2019},
pages = {23–28},
numpages = {6},
keywords = {Human hand gestures recognition, speed-up, convolutional neural network, accuracy},
location = {New York, NY, USA},
series = {INTESA2019}
}

@inproceedings{10.5555/2390916.2390918,
author = {Maney, Tucker and Sibert, Linda and Perzanowski, Dennis and Gupta, Kalyan and Schmidt-Nielsen, Astrid},
title = {Toward Determining the Comprehensibility of Machine Translations},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Economic globalization and the needs of the intelligence community have brought machine translation into the forefront. There are not enough skilled human translators to meet the growing demand for high quality translations or "good enough" translations that suffice only to enable understanding. Much research has been done in creating translation systems to aid human translators and to evaluate the output of these systems. Metrics for the latter have primarily focused on improving the overall quality of entire test sets but not on gauging the understanding of individual sentences or paragraphs. Therefore, we have focused on developing a theory of translation effectiveness by isolating a set of translation variables and measuring their effects on the comprehension of translations. In the following study, we focus on investigating how certain linguistic permutations, omissions, and insertions affect the understanding of translated texts.},
booktitle = {Proceedings of the First Workshop on Predicting and Improving Text Readability for Target Reader Populations},
pages = {1–7},
numpages = {7},
location = {Montreal, Canada},
series = {PITR '12}
}

@inproceedings{10.1145/3290607.3310425,
author = {Spiel, Katta and Keyes, Os and Barlas, P\i{}nar},
title = {Patching Gender: Non-Binary Utopias in HCI},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3290607.3310425},
doi = {10.1145/3290607.3310425},
abstract = {Non-binary people are rarely considered by technologies or technologists, and often subsumed under binary trans experiences on the rare occasions when we are discussed. In this paper we share our own experiences and explore potential alternatives - utopias, impossible places, as our lived experience of technologies' obsessive gender binarism seems near-insurmountable. Our suggestions on how to patch these gender bugs appear trivial while at the same time revealing seemingly insurmountable barriers. We illustrate the casual violence technologies present to non-binary people, as well as the on-going marginalisations we experience as HCI researchers. We write this paper primarily as an expression of self-empowerment that can function as a first step towards raising awareness towards the complexities at stake.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {non-binary, utopia, bugfixes, gender},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{10.1145/3271553.3271574,
author = {Chengeta, Kennedy},
title = {Comparative Analysis of Emotion Detection from Facial Expressions and Voice Using Local Binary Patterns and Markov Models: Computer Vision and Facial Recognition},
year = {2018},
isbn = {9781450365291},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3271553.3271574},
doi = {10.1145/3271553.3271574},
abstract = {Emotion detection has been achieved widely in facial and voice recognition separately with considerable success. The 6 emotional categories coming out of the classification include anger, fear, disgust, happiness and surprise. These can be infered from one's facial expressions both in the form of micro and macro expressions. In facial expressions the emotions are derived by feature extracting the facial expressions in different facial poses and classifying the expression feature vectors derived. Similarly automatic classification of a person's speech's affective state has also been used in signal processing to give insights into the nature of emotions. Speech being a critical tool for communication has been used to derive the emotional state of a human being. Different approaches have been successfully used to derive emotional states either in the form of facial expression recognition or speech emotional recognition being used. Less work has looked at fusing the two approaches to see if this improves emotional recognition accuracy. The study analyses the strengths of both and also limitations of either. The study reveals that emotional derivation based on facial expression recognition and acoustic information complement each other and a fusion of the two leads to better performance and results compared to the audio or acoustic recognition alone.},
booktitle = {Proceedings of the 2nd International Conference on Vision, Image and Signal Processing},
articleno = {27},
numpages = {6},
keywords = {Local Binary Patterns, Facial Recognition, Berlin Emotional Database},
location = {Las Vegas, NV, USA},
series = {ICVISP 2018}
}

@article{10.1145/3070645,
author = {Kaushal, Vishal and Patwardhan, Manasi},
title = {Emerging Trends in Personality Identification Using Online Social Networks—A Literature Survey},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1556-4681},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3070645},
doi = {10.1145/3070645},
abstract = {Personality is a combination of all the attributes—behavioral, temperamental, emotional, and mental—that characterizes a unique individual. Ability to identify personalities of people has always been of great interest to the researchers due to its importance. It continues to find highly useful applications in many domains. Owing to the increasing popularity of online social networks, researchers have started looking into the possibility of predicting a user's personality from his online social networking profile, which serves as a rich source of textual as well as non-textual content published by users. In the process of creating social networking profiles, users reveal a lot about themselves both in what they share and how they say it. Studies suggest that the online social networking websites are, in fact, a relevant and valid means of communicating personality. In this article, we review these various studies reported in literature toward identification of personality using online social networks. To the best of our knowledge, this is the first reported survey of its kind at the time of submission. We hope that our contribution, especially in summarizing the previous findings and in identifying the directions for future research in this area, would encourage researchers to do more work in this budding area.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jan,
articleno = {15},
numpages = {30},
keywords = {Facebook, personality prediction, Personality, Twitter, mining social network, online social network}
}

@inproceedings{10.1145/3003733.3003785,
author = {Markopoulos, K. and Mavrokefalidis, C. and Berberidis, K. and Daskalopoulou, E.},
title = {BCI-Based Approaches for Real-Time Applications},
year = {2016},
isbn = {9781450347891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3003733.3003785},
doi = {10.1145/3003733.3003785},
abstract = {In recent years, the growth of low-cost, non-invasive and portable electrophysiological systems that record and process brain signals, has increased. As a result, Brain Computer Interface (BCI) systems are becoming more and more accessible to the research community, serving various applications and needs, in contrast to earlier times, when these systems were more expensive, a lot more complex in their use, while their utilization focused particularly on health and medical applications. In this paper, information, on BCI systems, is provided and then, the overall procedure that has been followed, is described for the analysis and classification of signals acquired from an ElectroEncephaloGram (EEG). More specifically, there is a detailed description of the procedure of acquiring the data (i.e., EEG signals) from the brain as well as the steps for pre-processing and enhancing the recorded signals. Furthermore, some of the most common feature extraction techniques, along with associated classification algorithms, are combined and their performance is evaluated in terms of accuracy. The best combination is used for demonstrating the control of a flying drone both in simulated and real-world scenarios.},
booktitle = {Proceedings of the 20th Pan-Hellenic Conference on Informatics},
articleno = {25},
numpages = {6},
keywords = {Brain Computer Interface, Pre-processing, Machine Learning, Feature Extraction, Drone, Classification},
location = {Patras, Greece},
series = {PCI '16}
}

@inproceedings{10.1145/3022227.3022247,
author = {Yin, Delina Beh Mei and Omar, Shariman and Talip, Bazilah A. and Muklas, Amalia and Norain, Nur Afiqah Mohd and Othman, Abu Talib},
title = {Fusion of Face Recognition and Facial Expression Detection for Authentication: A Proposed Model},
year = {2017},
isbn = {9781450348881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3022227.3022247},
doi = {10.1145/3022227.3022247},
abstract = {The paper presents a novel model of hybrid biometric-based authentication. Currently, the recognition accuracy of a single biometric verification system is often much reduced due to many factors such as the environment, user mode and physiological defects of an individual. Apparently, the enrolment of static biometric is highly vulnerable to impersonation attack. Due to the fact of single biometric authentication only offers one factor of verification, we proposed to hybrid two biometric attributes that consist of physiological and behavioural trait. In this study, we utilise the static and dynamic features of a human face. In order to extract the important features from a face, the primary steps taken are image pre-processing and face detection. Apparently, to distinguish between a genuine user or an imposter, the first authentication is to verify the user's identity through face recognition. Solely depending on a single modal biometric is possible to lead to false acceptance when two or more similar face features may result in a relatively high match score. However, it is found the False Acceptance Rate is 0.55% whereas the False Rejection Rate is 7%. By reason of the security discrepancies in the mentioned condition, therefore we proposed a fusion method whereby a genuine user will select a facial expression from the seven universal expression (i.e. happy, sad, anger, disgust, surprise, fear and neutral) as enrolled earlier in the database. For the proof of concept, it is proven in our results that even there are two or more users coincidently have the same face features, the selected facial expression will act as a password to be prominently distinguished a genuine or impostor user.},
booktitle = {Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication},
articleno = {21},
numpages = {8},
keywords = {identity verification, biometric, facial expression, face recognition, authentication},
location = {Beppu, Japan},
series = {IMCOM '17}
}

@inproceedings{10.1145/2346676.2346677,
author = {He, Yulan},
title = {A Bayesian Modeling Approach to Multi-Dimensional Sentiment Distributions Prediction},
year = {2012},
isbn = {9781450315432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2346676.2346677},
doi = {10.1145/2346676.2346677},
abstract = {Sentiment analysis has long focused on binary classification of text as either positive or negative. There has been few work on mapping sentiments or emotions into multiple dimensions. This paper studies a Bayesian modeling approach to multi-class sentiment classification and multidimensional sentiment distributions prediction. It proposes effective mechanisms to incorporate supervised information such as labeled feature constraints and document-level sentiment distributions derived from the training data into model learning. We have evaluated our approach on the datasets collected from the confession section of the Experience Project website where people share their life experiences and personal stories. Our results show that using the latent representation of the training documents derived from our approach as features to build a maximum entropy classifier outperforms other approaches on multi-class sentiment classification. In the more difficult task of multi-dimensional sentiment distributions prediction, our approach gives superior performance compared to a few competitive baselines.},
booktitle = {Proceedings of the First International Workshop on Issues of Sentiment Discovery and Opinion Mining},
articleno = {1},
numpages = {8},
keywords = {sentiment analysis, latent dirichlet allocation (LDA), opinion mining, joint sentiment/topic model (JST)},
location = {Beijing, China},
series = {WISDOM '12}
}

@article{10.1145/3317604,
author = {Li, Wenjuan and Cao, Jian and Qian, Shiyou and Buyya, Rajkumar},
title = {TSLAM: A Trust-Enabled Self-Learning Agent Model for Service Matching in the Cloud Market},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1556-4665},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3317604},
doi = {10.1145/3317604},
abstract = {With the rapid development of cloud computing, various types of cloud services are available in the marketplace. However, it remains a significant challenge for cloud users to find suitable services for two major reasons: (1) Providers are unable to offer services in complete accordance with their declared Service Level Agreements, and (2) it is difficult for customers to describe their requirements accurately. To help users select cloud services efficiently, this article presents a Trust enabled Self-Learning Agent Model for service Matching (TSLAM). TSLAM is a multi-agent-based three-layered cloud service market model, in which different categories of agents represent the corresponding cloud entities to perform market behaviors. The unique feature of brokers is that they are not only the service recommenders but also the participants of market competition. We equip brokers with a learning module enabling them to capture implicit service demands and find user preferences. Moreover, a distributed and lightweight trust model is designed to help cloud entities make service decisions. Extensive experiments prove that TSLAM is able to optimize the cloud service matching process and compared to the state-of-the-art studies, TSLAM improves user satisfaction and the transaction success rate by at least 10%.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = jul,
articleno = {16},
numpages = {41},
keywords = {Cloud market model, trust management, service preference learning mechanism, multi-agent platform}
}

@inproceedings{10.1145/2912845.2912868,
author = {Lee, Kyungyup Daniel and Han, Kyungah and Myaeng, Sung-Hyon},
title = {Capturing Word Choice Patterns with LDA for Fake Review Detection in Sentiment Analysis},
year = {2016},
isbn = {9781450340564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2912845.2912868},
doi = {10.1145/2912845.2912868},
abstract = {The usefulness of user-generated online reviews is hampered by fake reviews, often produced by clandestinely sponsored reviewers. Detecting fake reviews is a difficult task even for laypeople, and this has also been the case for previous automatic detection approaches, which have only had a limited success. Earlier studies showed that people who tell lies or write deceptive reviews tend to select words unnaturally. We propose a novel approach to detecting fake reviews by applying a topic modeling method based on Latent Dirichlet Allocation (LDA). A unique contribution of this paper is to explicate some latent aspects of fake and truthful reviews by means of "topics" that are not necessarily subject areas but related to the word choice patterns reflecting behavioral and linguistic characteristics of the fake review writers. We constructed a labeled dataset based on Yelp and demonstrated that the proposed approach helps identifying unique aspects of fake and truthful reviews, which has a potential to improving the performance of the fake review detection task. The experimental result shows that our proposed method yields better performance than that of state-of-the-art methods for small size categories in our dataset.},
booktitle = {Proceedings of the 6th International Conference on Web Intelligence, Mining and Semantics},
articleno = {9},
numpages = {7},
keywords = {topic modeling, LDA, Sentiment analysis, fake review detection, word choice patterns},
location = {N\^{\i}mes, France},
series = {WIMS '16}
}

@inproceedings{10.1145/2492517.2492638,
author = {Wu, Meng Qi Yelena and Faris, Robert and Ma, Kwan-Liu},
title = {Visual Exploration of Academic Career Paths},
year = {2013},
isbn = {9781450322409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2492517.2492638},
doi = {10.1145/2492517.2492638},
abstract = {Online bibliographic databases have become widely available and are important resources to scientific researchers. These databases store rich information and many evolve into digital libraries. Using a bibliographic database of a specific discipline, we can extract a co-authorship and citation network of individual professionals. This allows for the study of patterns in scholarly contributions as well as for the exploration of scientific disputes associated with an individuals career. We have designed a visualization tool, which we call PathWay, to discover and understand patterns and trends in the bibliographic data over a selected period of time. With PathWay, we conducted case studies on a bibliography of approximately 400,000 scientists in physics over a 26 year time period. In this paper, we show how PathWay can be used to characterize one's academic career path in terms of the publication record, conduct comparative studies that would be difficult to do with conventional search methods, and also provide a way to gain insight into the emergence and the career implications of the scientific disputes associated with publications.},
booktitle = {Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {779–786},
numpages = {8},
keywords = {social network analysis, coauthor network, dispute network, trend discovery and analysis, bibliographic database, information visualization, citation network},
location = {Niagara, Ontario, Canada},
series = {ASONAM '13}
}

@inproceedings{10.1145/3404663.3404664,
author = {Steinhagen, Dustin and Kettani, Houssain},
title = {An Inventory of Existing Neuroprivacy Controls},
year = {2020},
isbn = {9781450377652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3404663.3404664},
doi = {10.1145/3404663.3404664},
abstract = {Brain-Computer Interfaces (BCIs) facilitate communication between brains and computers. As these devices become increasingly popular outside of the medical context, research interest in brain privacy risks and countermeasures has bloomed. Several neuroprivacy threats have been identified in the literature, including brain malware, personal data being contained in collected brainwaves and the inadequacy of legal regimes with regards to neural data protection. Dozens of controls have been proposed or implemented for protecting neuroprivacy, although it has not been immediately apparent what the landscape of neuroprivacy controls consists of. This paper inventories the implemented and proposed neuroprivacy risk mitigation techniques from open source repositories, BCI providers and the academic literature. These controls are mapped to the Hoepman privacy strategies and their implementation status is described. Several research directions for ensuring the protection of neuroprivacy are identified.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Information System and Data Mining},
pages = {77–83},
numpages = {7},
keywords = {Brain-Computer Interfaces, Brain Hacking, Privacy Controls, Neural Data Protection, Neurosecurity, Neuroprivacy},
location = {Hawaii, HI, USA},
series = {ICISDM 2020}
}

@inproceedings{10.1145/3345252.3345278,
author = {Alexiev, Kiril and Toshkov, Teodor and Dojnow, Peter},
title = {Enhancing Accuracy and Precision of Eye Tracker by Head Movement Compensation and Calibration},
year = {2019},
isbn = {9781450371490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3345252.3345278},
doi = {10.1145/3345252.3345278},
abstract = {The deep analysis of eyes movement and fixation according to a particular scenario assists to gain profound insights into the process of information acquisition, mood and mental states of the test subject. Eye tracking technology enables to determine where the eyes of the tested person are focused and how the visual information is attended to. Nowadays, the eye tracking technology is in its mature stage, often realized in glasses or other wearable devices, allowing non-obtrusive recording of individual's eye gazing in wide spectrum of dynamic scenarios. Sometimes, these last generation eye trackers are not equipped with synchronous head mounted forward-looking camera. In order to regard head movement for these eye trackers, the designers outfit them with inertial sensors. This paper deals with head movement compensation based on the data from inertial sensors. The implementation of accelerometers and gyros in eye tracking system is commented.},
booktitle = {Proceedings of the 20th International Conference on Computer Systems and Technologies},
pages = {226–233},
numpages = {8},
keywords = {orientation and positioning, inertial measurement unit, Eye tracker},
location = {Ruse, Bulgaria},
series = {CompSysTech '19}
}

@inproceedings{10.1145/3126686.3126735,
author = {Marczewski, Alison and Veloso, Adriano and Ziviani, Nivio},
title = {Learning Transferable Features for Speech Emotion Recognition},
year = {2017},
isbn = {9781450354165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3126686.3126735},
doi = {10.1145/3126686.3126735},
abstract = {Emotion recognition from speech is one of the key steps towards emotional intelligence in advanced human-machine interaction. Identifying emotions in human speech requires learning features that are robust and discriminative across diverse domains that differ in terms of language, spontaneity of speech, recording conditions, and types of emotions. This corresponds to a learning scenario in which the joint distributions of features and labels may change substantially across domains. In this paper, we propose a deep architecture that jointly exploits a convolutional network for extracting domain-shared features and a long short-term memory network for classifying emotions using domain-specific features. We use transferable features to enable model adaptation from multiple source domains, given the sparseness of speech emotion data and the fact that target domains are short of labeled data. A comprehensive cross-corpora experiment with diverse speech emotion domains reveals that transferable features provide gains ranging from 4.3% to 18.4% in speech emotion recognition. We evaluate several domain adaptation approaches, and we perform an ablation study to understand which source domains add the most to the overall recognition effectiveness for a given target domain.},
booktitle = {Proceedings of the on Thematic Workshops of ACM Multimedia 2017},
pages = {529–536},
numpages = {8},
keywords = {affective computing, deep learning, emotion recognition},
location = {Mountain View, California, USA},
series = {Thematic Workshops '17}
}

@inproceedings{10.1145/2069216.2069241,
author = {Nguyen, Thi Thanh Mai and Pham, Ngoc Hai and Dong, Van Thai and Nguyen, Viet Son and Tran, Thi Thanh Hai},
title = {A Fully Automatic Hand Gesture Recognition System for Human-Robot Interaction},
year = {2011},
isbn = {9781450308809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2069216.2069241},
doi = {10.1145/2069216.2069241},
abstract = {Recently, human - machine interaction (HMI) becomes a hot research topic because of its wide applications, ranging from automatic device control to designing and development of assistant robot or even smart building at sparser scale. One of the most important questions in this research field is finding out an efficient and natural method of HMI. Among several channels of communication, hand gestures have been shown to be an intuitive and efficient mean to express an idea or to control something. For a successful hand gesture based interaction between human and robot, a vocabulary of hand gestures needs to be defined. To resolve this problem, in this paper, we propose a framework to study the behavior of Vietnamese in using of hand gesture in communication with robot. This study allows designing a hand gesture vocabulary for human - robot interaction (HRI) applications. In the literature, there are no works similar to ours. This makes our twofold contributions: (1) a proposed framework for hand gesture recognition: hand gesture vocabulary design, feature extraction for hand posture representation, hand posture classification, and hand gesture database construction; (2) some experimentations are realized to evaluate the defined hand gesture set that can be used in general situation of HRI. The experiment results show that the defined hand gesture set satisfies the both criteria: intuitiveness and recognisability.},
booktitle = {Proceedings of the Second Symposium on Information and Communication Technology},
pages = {112–119},
numpages = {8},
keywords = {visual recognition, hand gesture, cascaded adaboost classifier, Wizard of Oz technique, Haar like feature, image processing and computer vision},
location = {Hanoi, Vietnam},
series = {SoICT '11}
}

@article{10.1145/3297713,
author = {Bablani, Annushree and Edla, Damodar Reddy and Tripathi, Diwakar and Cheruku, Ramalingaswamy},
title = {Survey on Brain-Computer Interface: An Emerging Computational Intelligence Paradigm},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0360-0300},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3297713},
doi = {10.1145/3297713},
abstract = {A brain-computer interface (BCI) provides a way to develop interaction between a brain and a computer. The communication is developed as a result of neural responses generated in the brain because of motor movements or cognitive activities. The means of communication here includes muscular and non-muscular actions. These actions generate brain activities or brain waves that are directed to a hardware device to perform a specific task. BCI initially was developed as the communication device for patients suffering from neuromuscular disorders. Owing to recent advancements in BCI devices—such as passive electrodes, wireless headsets, adaptive software, and decreased costs—it is also being used for developing communication between the general public. The BCI device records brain responses using various invasive and non-invasive acquisition techniques such as electrocorticography (ECoG), electroencephalography (EEG), magnetoencephalography (MEG), and magnetic resonance imaging (MRI). In this article, a survey on these techniques has been provided. The brain response needs to be translated using machine learning and pattern recognition methods to control any application. A brief review of various existing feature extraction techniques and classification algorithms applied on data recorded from the brain has been included in this article. A significant comparative analysis of popular existing BCI techniques is presented and possible future directives are provided.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {20},
numpages = {32},
keywords = {Brain-computer interface, classification, electroencephalogram, feature extraction, fuzzy inference system}
}

@article{10.1145/3178582,
author = {Resende, Paulo Angelo Alves and Drummond, Andr\'{e} Costa},
title = {A Survey of Random Forest Based Methods for Intrusion Detection Systems},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0360-0300},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3178582},
doi = {10.1145/3178582},
abstract = {Over the past decades, researchers have been proposing different Intrusion Detection approaches to deal with the increasing number and complexity of threats for computer systems. In this context, Random Forest models have been providing a notable performance on their applications in the realm of the behaviour-based Intrusion Detection Systems. Specificities of the Random Forest model are used to provide classification, feature selection, and proximity metrics. This work provides a comprehensive review of the general basic concepts related to Intrusion Detection Systems, including taxonomies, attacks, data collection, modelling, evaluation metrics, and commonly used methods. It also provides a survey of Random Forest based methods applied in this context, considering the particularities involved in these models. Finally, some open questions and challenges are posed combined with possible directions to deal with them, which may guide future works on the area.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {48},
numpages = {36},
keywords = {behavioural methods, Random Forest methods, Intrusion Detection Systems, anomaly detection, Machine Learning}
}

@inproceedings{10.1145/3340531.3412879,
author = {Li, Jiazheng and Yang, Linyi and Smyth, Barry and Dong, Ruihai},
title = {MAEC: A Multimodal Aligned Earnings Conference Call Dataset for Financial Risk Prediction},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3340531.3412879},
doi = {10.1145/3340531.3412879},
abstract = {In the area of natural language processing, various financial datasets have informed recent research and analysis including financial news, financial reports, social media, and audio data from earnings calls. We introduce a new, large-scale multi-modal, text-audio paired, earnings-call dataset named MAEC, based on S&amp;P 1500 companies. We describe the main features of MAEC, how it was collected and assembled, paying particular attention to the text-audio alignment process used. We present the approach used in this work as providing a suitable framework for processing similar forms of data in the future. The resulting dataset is more than six times larger than those currently available to the research community and we discuss its potential in terms of current and future research challenges and opportunities. All resources of this work are available at https://github.com/Earnings-Call-Dataset/},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {3063–3070},
numpages = {8},
keywords = {financial risk prediction, multimodal aligned datasets, earnings conference calls},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@inproceedings{10.1145/2702123.2702489,
author = {Klouche, Khalil and Ruotsalo, Tuukka and Cabral, Diogo and Andolina, Salvatore and Bellucci, Andrea and Jacucci, Giulio},
title = {Designing for Exploratory Search on Touch Devices},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2702123.2702489},
doi = {10.1145/2702123.2702489},
abstract = {Exploratory search confront users with challenges in expressing search intents as the current search interfaces require investigating result listings to identify search directions, iterative typing, and reformulating queries. We present the design of Exploration Wall, a touch-based search user interface that allows incremental exploration and sense-making of large information spaces by combining entity search, flexible use of result entities as query parameters, and spatial configuration of search streams that are visualized for interaction. Entities can be flexibly reused to modify and create new search streams, and manipulated to inspect their relationships with other entities. Data comprising of task-based experiments comparing Exploration Wall with conventional search user interface indicate that Exploration Wall achieves significantly improved recall for exploratory search tasks while preserving precision. Subjective feedback supports our design choices and indicates improved user satisfaction and engagement. Our findings can help to design user interfaces that can effectively support exploratory search on touch devices.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {4189–4198},
numpages = {10},
keywords = {touch devices, exploratory search, user interfaces},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@article{10.1145/2580723.2580730,
author = {Roesner, Franziska and Kohno, Tadayoshi and Molnar, David},
title = {Security and Privacy for Augmented Reality Systems},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0001-0782},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2580723.2580730},
doi = {10.1145/2580723.2580730},
abstract = {AR systems pose potential security concerns that should be addressed before the systems become widespread.},
journal = {Commun. ACM},
month = apr,
pages = {88–96},
numpages = {9}
}

@inproceedings{10.1145/3290605.3300451,
author = {Berkovsky, Shlomo and Taib, Ronnie and Koprinska, Irena and Wang, Eileen and Zeng, Yucheng and Li, Jingjie and Kleitman, Sabina},
title = {Detecting Personality Traits Using Eye-Tracking Data},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3290605.3300451},
doi = {10.1145/3290605.3300451},
abstract = {Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans' physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {eye tracking, field study, framework, personality detection},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3323873.3326590,
author = {Zong, Yuan and Zheng, Wenming and Hong, Xiaopeng and Tang, Chuangao and Cui, Zhen and Zhao, Guoying},
title = {Cross-Database Micro-Expression Recognition: A Benchmark},
year = {2019},
isbn = {9781450367653},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3323873.3326590},
doi = {10.1145/3323873.3326590},
abstract = {Cross-database micro-expression recognition (CDMER) is one of recently emerging and interesting problems in micro-expression analysis. CDMER is more challenging than the conventional micro-expression recognition (MER), because the training and testing samples in CDMER come from different micro-expression databases, resulting in inconsistency of the feature distributions between the training and testing sets. In this paper, we contribute to this topic from two aspects. First, we establish a CDMER experimental evaluation protocol and provide a standard platform for evaluating their proposed methods. Second, we conduct extensive benchmark experiments by using NINE state-of-the-art domain adaptation (DA) methods and SIX popular spatiotemporal descriptors for investigating the CDMER problem from two different perspectives and deeply analyze and discuss the experimental results. In addition, all the data and codes involving CDMER in this paper are released on our project website: http://aip.seu.edu.cn/cdmer.},
booktitle = {Proceedings of the 2019 on International Conference on Multimedia Retrieval},
pages = {354–363},
numpages = {10},
keywords = {domain adaptation, transfer learning, cross-database micro-expression recognition, spatio temporal descriptors, micro-expression recognition},
location = {Ottawa ON, Canada},
series = {ICMR '19}
}

@inproceedings{10.1145/1978942.1979210,
author = {Latulipe, Celine and Carroll, Erin A. and Lottridge, Danielle},
title = {Love, Hate, Arousal and Engagement: Exploring Audience Responses to Performing Arts},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/1978942.1979210},
doi = {10.1145/1978942.1979210},
abstract = {Understanding audience responses to art and performance is a challenge. New sensors are promising for measurement of implicit and explicit audience engagement. However, the meaning of biometric data, and its relationship to engagement, is unclear. We conceptually explore the audience engagement domain to uncover opportunities and challenges in the assessment and interpretation of audience engagement data. We developed a display that linked performance videos with audience biometric data and presented it to 7 performing arts experts, to explore the measurement, interpretation and application of biometric data. Experts were intrigued by the response data and reflective in interpreting it. We deepened our inquiry with an empirical study with 49 participants who watched a video of a dance performance. We related temporal galvanic skin response (GSR) data to two self-report scales, which provided insights on interpreting this measure. Our findings, which include strong correlations, support the interpretation of GSR as a valid representation of audience engagement.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1845–1854},
numpages = {10},
keywords = {galvanic skin response, audience engagement, arousal, performing arts, audience interaction},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@article{10.1145/3342227,
author = {Hong, Xiaopeng and Peng, Wei and Harandi, Mehrtash and Zhou, Ziheng and Pietik\"{a}inen, Matti and Zhao, Guoying},
title = {Characterizing Subtle Facial Movements via Riemannian Manifold},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3s},
issn = {1551-6857},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3342227},
doi = {10.1145/3342227},
abstract = {Characterizing subtle facial movements from videos is one of the most intensive topics in computer vision research. It is, however, challenging, since (1) the intensity of subtle facial muscle movement is usually low, (2) the duration may be transient, and (3) datasets containing spontaneous subtle movements with reliable annotations are painful to obtain and often of small sizes.This article is targeted at addressing these problems for characterizing subtle facial movements from both the aspects of motion elucidation and description. First, we propose an efficient method for elucidating hidden and repressed movements to make them easier to get noticed. We explore the feasibility of linearizing motion magnification and temporal interpolation, which is obscured by the architecture of existing methods. On this basis, we propose a consolidated framework, termed MOTEL, to expand temporal duration and amplify subtle facial movements simultaneously. Second, we make our contribution to dynamic description. One major challenge is to capture the intrinsic temporal variations caused by movements and omit extrinsic ones caused by different individuals and various environments. To diminish the influences of such extrinsic diversity, we propose the tangent delta descriptor to characterize the dynamics of short-term movements using the differences between points on the tangent spaces to the manifolds, rather than the points themselves. We then relax the trajectory-smooth assumption of the conventional manifold-based trajectory modeling methods and incorporate the tangent delta descriptor with the sequential inference approaches to cover the period of facial movements. The proposed motion modeling approach is validated by a series of experiments on publicly available datasets in the tasks of micro-expression recognition and visual speech recognition.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = dec,
articleno = {94},
numpages = {24},
keywords = {motion magnification, motion description, Micro-expression recognition, visual speech recognition, video representation}
}

@article{10.1145/2811403,
author = {Edwards, Matthew and Rashid, Awais and Rayson, Paul},
title = {A Systematic Survey of Online Data Mining Technology Intended for Law Enforcement},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0360-0300},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/2811403},
doi = {10.1145/2811403},
abstract = {As an increasing amount of crime takes on a digital aspect, law enforcement bodies must tackle an online environment generating huge volumes of data. With manual inspections becoming increasingly infeasible, law enforcement bodies are optimising online investigations through data-mining technologies. Such technologies must be well designed and rigorously grounded, yet no survey of the online data-mining literature exists which examines their techniques, applications and rigour. This article remedies this gap through a systematic mapping study describing online data-mining literature which visibly targets law enforcement applications, using evidence-based practices in survey making to produce a replicable analysis which can be methodologically examined for deficiencies.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {15},
numpages = {54},
keywords = {open-source intelligence, Systematic survey, literature review, law enforcement, cybercrime, online data mining, OSINT}
}

@article{10.1145/3357459,
author = {Taib, Ronnie and Berkovsky, Shlomo and Koprinska, Irena and Wang, Eileen and Zeng, Yucheng and Li, Jingjie},
title = {Personality Sensing: Detection of Personality Traits Using Physiological Responses to Image and Video Stimuli},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {2160-6455},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3357459},
doi = {10.1145/3357459},
abstract = {Personality detection is an important task in psychology, as different personality traits are linked to different behaviours and real-life outcomes. Traditionally it involves filling out lengthy questionnaires, which is time-consuming, and may also be unreliable if respondents do not fully understand the questions or are not willing to honestly answer them. In this article, we propose a framework for objective personality detection that leverages humans’ physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using non-invasive commercial-grade eye-tracking and skin conductivity sensors. These responses are then processed and used to build a machine learning classifier capable of accurately predicting a wide range of personality traits. We investigate and discuss the performance of various machine learning methods, the most and least accurately predicted traits, and also assess the importance of the different stimuli, features, and physiological signals. Our work demonstrates that personality traits can be accurately detected, suggesting the applicability of the proposed framework for robust personality detection and use by psychology practitioners and researchers, as well as designers of personalised interactive systems.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = oct,
articleno = {18},
numpages = {32},
keywords = {GSR, Personality detection, eye tracking, field study, framework}
}

@proceedings{10.1145/2993148,
title = {ICMI '16: Proceedings of the 18th ACM International Conference on Multimodal Interaction},
year = {2016},
isbn = {9781450345569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@article{10.1145/3377404,
author = {Belman, Amith K. and Phoha, Vir V.},
title = {Discriminative Power of Typing Features on Desktops, Tablets, and Phones for User Identification},
year = {2020},
issue_date = {February 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {2471-2566},
url = {https://doi-org.ez22.periodicos.capes.gov.br/10.1145/3377404},
doi = {10.1145/3377404},
abstract = {Research in Keystroke-Dynamics (KD) has customarily focused on temporal features without considering context to generate user templates that are used in authentication. Additionally, work on KD in hand-held devices such as smart-phones and tablets have shown that these features alone do not perform satisfactorily for authentication. In this work, we analyze the discriminatory power of the most-used conventional features found in the literature, propose a set of context-sensitive or word-specific features, and analyze the discriminatory power of proposed features using their classification results. To perform these tasks, we use the keystroke data consisting of over 650K keystrokes, collected from 20 unique users during different activities on desktops, tablets, and phones, over a span of two months. On an average, each user made 12.5K, 9K, and 10K keystrokes on desktop, tablet, and phone, respectively.We find that the conventional features are not highly discriminatory on desktops and are only marginally better on hand-held devices for user identification. By using information of the context, a subset (derived after analysis) of our proposed word-specific features offers superior discrimination among users on all devices. We find that a majority of the classifiers, built using these features, perform user identification well with accuracies in the range of 90% to 97%, average precision and recall values of 0.914 and 0.901, respectively, on balanced test samples in 10-fold cross validation. We also find that proposed features work best on hand-held devices. This work calls for a shift from using conventional KD features to a set of context-sensitive or word-specific KD features that take advantage of known information such as context.},
journal = {ACM Trans. Priv. Secur.},
month = feb,
articleno = {4},
numpages = {36},
keywords = {discriminative power, desktop, tablet, Keystroke dynamics, phone, typing, context-sensitive features}
}

@proceedings{10.1145/3308560,
title = {WWW '19: Companion Proceedings of The 2019 World Wide Web Conference},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to <i>The Web Conference 2019</i>. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, USA}
}

@book{10.1145/3015783,
editor = {Oviatt, Sharon and Schuller, Bj\"{o}rn and Cohen, Philip R. and Sonntag, Daniel and Potamianos, Gerasimos and Kr\"{u}ger, Antonio},
title = {The Handbook of Multimodal-Multisensor Interfaces: Foundations, User Modeling, and Common Modality Combinations - Volume 1},
year = {2017},
isbn = {9781970001679},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
volume = {14},
abstract = { The Handbook of Multimodal-Multisensor Interfaces provides the first authoritative resource on what has become the dominant paradigm for new computer interfaces-user input involving new media (speech, multi-touch, gestures, writing) embedded in multimodal-multisensor interfaces. These interfaces support smartphones, wearables, in-vehicle, robotic, and many other applications that are now highly competitive commercially.   This edited collection is written by international experts and pioneers in the field. It provides a textbook for students, and a reference and technology roadmap for professionals working in this rapidly emerging area.    Volume 1 of the handbook presents relevant theory and neuroscience foundations for guiding the development of high-performance systems. Additional chapters discuss approaches to user modeling, interface design that supports user choice, synergistic combination of modalities with sensors, and blending of multimodal input and output. They also highlight an in-depth look at the most common multimodal-multisensor combinations- for example, touch and pen input, haptic and non-speech audio output, and speech co-processed with visible lip movements, gaze, gestures, or pen input. A common theme throughout is support for mobility and individual differences among users-including the world's rapidly growing population of seniors.    These handbook chapters provide walk-through examples and video illustrations of different system designs and their interactive use. Common terms are defined, and information on practical resources is provided (e.g., software tools, data resources) for hands-on project work to develop and evaluate multimodal-multisensor systems. In the final chapter, experts exchange views on a timely and controversial challenge topic, and how they believe multimodal-multisensor interfaces should be designed in the future to most effectively advance human performance. }
}

@proceedings{10.1145/2998181,
title = {CSCW '17: Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
year = {2017},
isbn = {9781450343350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to CSCW 2017, the ACM 2017 Conference on Computer Supported Cooperative Work and Social Computing! We are excited to welcome the CSCW community back to Portland, Oregon, where the second CSCW conference was held in 1988. Both Portland and CSCW have matured a great deal during the intervening 29 years. We hope that you will find that Portland provides a stimulating environment for our conference.CSCW is the premier venue for presenting research in the design and use of technologies that affect groups, organizations, communities, and networks. Bringing together top researchers and practitioners from academia and industry, CSCW explores the technical, social, material, and theoretical challenges of designing technology to support collaborative work and life activities. CSCW welcomes a diverse range of topics and research methodologies. Studies often involve the development and application of novel technologies and/or ethnographic studies that inform design practice or theory. The mission of the conference is to share research that advances the state of human knowledge and improves both the design of systems and the ways they are used. The diversity of work in our conference program reflects the diversity of technology use in people's work, social, and civic lives as well as the geographic and cultural diversity of contributors.As many of you know, CSCW follows a rigorous "revise and resubmit" review process that uses peer review to improve submitted papers while maintaining a high-quality threshold for final acceptance. We also help prepare the next generation of reviewers with a mentorship program in which students review papers under the guidance of an experienced reviewer. This year we have the largest CSCW program ever. We had 530 submitted papers and 183 were accepted for presentation at the conference. The program also includes 4 papers published in ACM Transactions on Human- Computer Interaction (TOCHI). In addition, we will feature 14 workshops, 56 posters, 12 demos, and 3 panels.Lili Cheng of Microsoft Research will open the conference, speaking on "Conversational AI &amp; Lessons Learned." Our closing plenary will feature Jorge Cham, the creator of PhD Comics, who will talk about, "The Science Gap." We also welcome Paul Luff and Christian Heath from King's College as the recipients of this year's CSCW Lasting Impact award for their influential 1998 paper, "Mobility in Collaboration."},
location = {Portland, Oregon, USA}
}

